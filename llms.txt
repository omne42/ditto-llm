Ditto-LLM (Rust)
================

One-liner
---------
Ditto-LLM is a Rust-first project that aims to be a superset of:
- LiteLLM Proxy (OpenAI-compatible gateway + control-plane), and
- Vercel AI SDK (unified provider/model abstractions + helpers),
while keeping the default build small via Cargo feature-gating.

Primary entry points
--------------------
1) Rust SDK (AI SDK Core-like)
   - Unified traits/types for multiple providers.
   - Text helpers: generate_text / stream_text.
   - Structured outputs: generate_object_json / stream_object (best-effort).
   - Tool calling returns tool calls; optional tool-loop agent behind a feature.

2) HTTP Gateway (LiteLLM-like)
   - Optional OpenAI-compatible /v1/* proxy surface.
   - Control-plane: virtual keys, limits, budgets/costing, caching, routing, audit, metrics/OTel.
   - Supports passthrough proxy; optional translation proxy (OpenAI in/out -> native providers).

3) JS/React clients (AI SDK UI-like, minimal)
   - Parse Ditto Stream Protocol v1 over SSE/NDJSON.
   - A lightweight React hook for streaming UI state.

Quickstart (repo-local)
-----------------------
Docs (mdBook):
- mdbook serve docs
- Source markdown lives in docs/src

Rust examples:
- cargo run --example basic
- cargo run --example streaming
- cargo run --example tool_calling

Gateway (local):
- cargo run --features gateway --bin ditto-gateway -- ./gateway.json --listen 0.0.0.0:8080
- curl -sS http://127.0.0.1:8080/health
- curl -sS http://127.0.0.1:8080/v1/models | head

Core concepts (Ditto terminology)
---------------------------------
- Provider: an LLM service backend (OpenAI / Anthropic / Google / OpenAI-compatible / ...)
- Model: a specific model within a provider (e.g. gpt-4o-mini, claude-3-5-sonnet-...)
- Request/Response: Ditto's unified request/response types.
- Streaming: Ditto emits a sequence of StreamChunk values.
- Warnings: provider incompatibilities and best-effort downgrades are explicit, not silent.
- Passthrough vs Translation (Gateway): forward OpenAI-compatible traffic as-is vs translate to native providers.

Code + file map
---------------
- src/: the main Rust crate implementation.
- examples/: runnable Rust examples.
- deploy/: docker-compose/k8s/helm templates for ditto-gateway.
- docs/: mdBook docs (see docs/src/SUMMARY.md).
- packages/ditto-client: minimal JS client (Stream Protocol v1 parsing + admin client).
- packages/ditto-react: React hook (useStreamV1).
- apps/admin-ui: minimal React admin console for ditto-gateway.

Repo conventions (important for changes)
----------------------------------------
- Update CHANGELOG.md under [Unreleased] in the same commit as the code/doc change.
- Conventional Commits are enforced for commit messages.
- Pre-commit runs: cargo fmt --check and cargo check for the ditto-llm package.
- Avoid huge Rust files: staged .rs files over 1000 lines are rejected by pre-commit.

Auto-generated docs bundle
--------------------------
- This file appends a concatenated snapshot of repo docs under the marker below.
- Regenerate via: `cargo run --bin ditto-llms-txt`
- A copy is also kept at `docs/src/llms.txt` so `mdbook build docs` publishes it as `/llms.txt`.

----- BEGIN AUTO-GENERATED DOCS (ditto-llms-txt) -----
================================================================================
FILE: README.md
================================================================================

# ditto-llm

Ditto-LLM is a small Rust SDK that provides a unified interface for calling multiple LLM providers.

Goal: become a superset of LiteLLM Proxy + Vercel AI SDK Core via layering + Cargo feature gating.
See `COMPARED_TO_LITELLM_AI_SDK.md` and `TODO.md` for the parity notes and roadmap.

Current scope:

- Unified types + traits: `LanguageModel` / `EmbeddingModel`, `Message`/`ContentPart`, `Tool`, `StreamChunk`, `Warning`.
- Text helpers: `generate_text` / `stream_text` (AI SDK-style `generateText` / `streamText`).
- Structured outputs: `generate_object_json` / `stream_object` (AI SDK-style `generateObject` / `streamObject`).
- Multi-modal inputs: images + PDF documents via `ContentPart::Image` / `ContentPart::File` (provider support varies; unsupported parts emit `Warning`).
- Parameter hygiene: `temperature`/`top_p` are clamped to provider ranges; non-finite values are dropped (with warnings).
- Providers:
  - OpenAI Responses API (generate + SSE streaming) and embeddings
  - OpenAI-compatible Chat Completions (LiteLLM / DeepSeek / Qwen / etc.) and embeddings
  - Anthropic Messages API (generate + SSE streaming)
  - Google GenAI (generate + SSE streaming) and embeddings
  - Cohere Chat API (generate + SSE streaming), embeddings, and rerank (feature-gated)
- Batches: `BatchClient` for OpenAI/OpenAI-compatible `/batches` (feature `batches`).
- Provider profile config and model discovery (`ProviderConfig` / `GET /models`) for routing use-cases.

Optional feature-gated modules:

- Agent tool loop: `ToolLoopAgent` + `ToolExecutor` (feature `agent`).
- Auth adapters: SigV4 signer + OAuth client-credentials flow (feature `auth`).
- Providers: Bedrock (SigV4) and Vertex (OAuth) adapters with generate + SSE streaming + tools (features `bedrock`, `vertex`).
- SDK utilities: stream protocol v1, HTTP adapters (SSE/NDJSON), telemetry sink, devtools JSONL logger, MCP tool adapter, cache middleware with streaming replay (feature `sdk`).
- SDK HTTP helpers: optional `axum` response builders for stream adapters (feature `sdk-axum`).
- Gateway control-plane: virtual keys, limits, cache, budget, routing, guardrails, passthrough, plus a `ditto-gateway` HTTP server (feature `gateway`). Includes LiteLLM-like conveniences such as `/key/*` endpoints, `/a2a/*` agent proxy, and `/mcp*` MCP tool gateway.
- Gateway token counting: tiktoken-based input token estimation for proxy budgets/guardrails/costing (feature `gateway-tokenizer`).
- Gateway translation proxy: OpenAI-compatible `GET /v1/models`, `GET /v1/models/*`, `POST /v1/chat/completions`, `POST /v1/completions`, `POST /v1/responses`, `POST /v1/responses/compact`, `POST /v1/embeddings`, `POST /v1/moderations`, `POST /v1/images/generations`, `POST /v1/audio/transcriptions`, `POST /v1/audio/translations`, `POST /v1/audio/speech`, `/v1/files*`, `POST /v1/rerank`, and `/v1/batches` backed by Ditto providers (feature `gateway-translation`).
- Gateway proxy caching: in-memory cache for non-streaming OpenAI-compatible responses (feature `gateway-proxy-cache`).
- Gateway OpenTelemetry: OTLP tracing exporter + structured logs for gateway HTTP requests (feature `gateway-otel`).

Non-goals (for now):

- The default build is not an API gateway/proxy; the `gateway` feature adds a lightweight control-plane + HTTP service. The `gateway-translation` feature adds translation for `GET /v1/models`, `GET /v1/models/*`, `POST /v1/chat/completions`, `POST /v1/completions`, `POST /v1/responses`, `POST /v1/responses/compact`, `POST /v1/embeddings`, `POST /v1/moderations`, `POST /v1/images/generations`, `POST /v1/audio/transcriptions`, `POST /v1/audio/translations`, `POST /v1/audio/speech`, `/v1/files*`, `POST /v1/rerank`, and `/v1/batches`. Full OpenAI surface translation (etc) is tracked in `TODO.md`.
- Core helpers are single-step and return tool calls to the caller; the `agent` feature offers an opt-in tool loop, but it is not enabled by default.
- It is not a full UI SDK (no frontend hooks or middleware ecosystem); the `sdk` feature only provides protocol/telemetry/devtools/MCP utilities.
- Bedrock support targets Anthropic Messages-on-Bedrock; other Bedrock model families and Vertex service-account JWT flows are not covered yet.

See `PROVIDERS.md` for a pragmatic provider/capability matrix (native adapters + OpenAI-compatible
gateway coverage).

## Docs

This repo includes an `mdBook` under `docs/`.

```bash
cargo install mdbook
mdbook serve docs
```

If you don’t want to install mdBook, you can still read the Markdown directly in `docs/src`.

## Tool Schemas

For Google function calling, Ditto-LLM converts tool parameter JSON Schema into an OpenAPI-style
schema.

Contract:

- Conversion is best-effort and lossy: unsupported keywords are ignored (dropped), not errors.
- Unsupported keywords may emit `Warning::Compatibility(tool.parameters.unsupported_keywords)` to avoid silent data loss.
- `$ref` is best-effort: local refs (`#/...`) are resolved; unresolvable refs are ignored and a `Warning::Compatibility(tool.parameters.$ref)` is emitted.
- Root empty-object schemas (no properties + `additionalProperties` missing/false) are treated as
  "no parameters" and omitted.
- Boolean schemas (`true`/`false`) are treated as unconstrained schemas; at the root they are
  omitted.
- Nullable unions:
  - `type: ["string", "null"]` becomes `anyOf: [{ "type": "string" }]` + `nullable: true`
  - `anyOf: [{...}, {"type":"null"}]` becomes the same shape (single branch is flattened)
- `const` becomes `enum: [<const>]`.
- `additionalProperties` supports boolean and nested schemas.

Supported keywords (subset): `type`, `title`, `description`, `properties`, `required`, `items`,
`additionalProperties`, `enum`, `const`, `format`, `allOf`, `anyOf`, `oneOf`, `default`,
`minLength`/`maxLength`/`pattern`, `minItems`/`maxItems`/`uniqueItems`,
`minProperties`/`maxProperties`, `minimum`/`maximum`/`multipleOf`,
and `exclusiveMinimum`/`exclusiveMaximum` (number form → `minimum`/`maximum` + `exclusive* = true`).

## Examples

Examples expect provider API keys in environment variables.

```bash
cargo run --example basic
cargo run --example streaming
cargo run --example tool_calling
cargo run --example embeddings
cargo run --example openai_compatible
cargo run --example openai_compatible_embeddings
cargo run --example multimodal --features base64 -- ./image.png ./doc.pdf
cargo run --example batches --features batches -- ./requests.jsonl
```

## Gateway (optional)

Run the HTTP gateway (feature `gateway`):

```bash
cargo run --features gateway --bin ditto-gateway -- ./gateway.json --listen 0.0.0.0:8080
```

YAML config is optional (feature `gateway-config-yaml`):

```bash
cargo run --features gateway-config-yaml --bin ditto-gateway -- ./gateway.yaml --listen 0.0.0.0:8080
```

Minimal admin UI (React):

```bash
pnpm install
pnpm dev
```

Minimal multi-language gateway clients:

- Node (SSE streaming): `examples/clients/node/stream_chat_completions.mjs`
- Python: `examples/clients/python/chat_completions.py`
- Go: `examples/clients/go/chat_completions.go`

Backends are configured in `gateway.json` (OpenAI-compatible upstreams + injected headers/query params, e.g. `Authorization` and Azure-style `api-version`):

```json
{
  "backends": [
    {
      "name": "primary",
      "base_url": "https://api.openai.com/v1",
      "max_in_flight": 64,
      "timeout_seconds": 60,
      "headers": { "authorization": "Bearer ${OPENAI_API_KEY}" },
      "query_params": {}
    }
  ],
  "virtual_keys": [],
  "router": { "default_backends": [{ "backend": "primary", "weight": 1.0 }], "rules": [] }
}
```

`backends[].max_in_flight` optionally caps concurrent in-flight proxy requests per backend (rejects with HTTP 429 + OpenAI-style error code `inflight_limit_backend`).
`backends[].timeout_seconds` optionally overrides the backend request timeout in seconds (default: 300s).

Gateway config supports `${ENV_VAR}` interpolation in backend `base_url`/`headers`/`query_params`, backend `provider_config` fields (e.g. `base_url`/`http_headers`/`http_query_params`), `virtual_keys[].token`, `a2a_agents[]` (agent url/headers/query), and `mcp_servers[]` (server url/headers/query) (expanded at startup via the process env or `--dotenv`).

Translation backends (feature `gateway-translation`) can be configured with `provider` + `provider_config` (same shape as `ProviderConfig`):

```json
{
  "backends": [
    {
      "name": "anthropic",
      "provider": "anthropic",
      "provider_config": {
        "auth": { "type": "api_key_env", "keys": ["ANTHROPIC_API_KEY"] },
        "default_model": "claude-3-5-sonnet-20241022"
      }
    }
  ],
  "virtual_keys": [],
  "router": { "default_backends": [{ "backend": "anthropic", "weight": 1.0 }], "rules": [] }
}
```

For OpenAI-compatible upstreams, `provider` can be `openai-compatible`/`openai_compatible` or a LiteLLM-style alias (e.g. `groq`, `mistral`, `deepseek`, `qwen`, `together`, `fireworks`, `xai`, `perplexity`, `openrouter`, `ollama`, `azure`).

Routing (optional):

- `router.default_backends`: weighted primary selection (seeded by `x-request-id` when proxying)
- `router.rules[].backends`: per-model-prefix weighted backends (falls back to `router.default_backends` when empty)
- If multiple backends are selected, the OpenAI-compatible proxy will fall back to the next backend on network errors.
- With `--features gateway-routing-advanced`, proxying can also use retry/circuit breaker/active health checks (`--proxy-retry*` / `--proxy-circuit-breaker*` / `--proxy-health-check*`).

Endpoints:

- OpenAI-compatible proxy (passthrough): `ANY /v1/*` (e.g. `POST /v1/responses`, `POST /v1/chat/completions`, `GET /v1/models`).
  - LiteLLM-style aliases without a `/v1` prefix are accepted (e.g. `/chat/completions`, `/embeddings`, `/moderations`, `/files/*`, `/batches/*`, `/models/*`, `/responses/*`).
  - If `virtual_keys` is non-empty, requests must include `Authorization: Bearer <virtual_key>` (or `x-ditto-virtual-key` / `x-api-key`).
  - If `virtual_keys` is non-empty, the client `Authorization` header is treated as a virtual key and is not forwarded upstream; the backend `headers` are applied instead.
  - If the upstream does **not** implement `POST /v1/responses` (returns 404/405/501), Ditto will fall back to `POST /v1/chat/completions` and return a best-effort Responses-like response/stream (adds `x-ditto-shim: responses_via_chat_completions`).
- OpenAI-compatible translation (feature `gateway-translation`): `GET /v1/models`, `GET /v1/models/*`, `POST /v1/chat/completions`, `POST /v1/completions`, `POST /v1/responses`, `POST /v1/responses/compact`, `POST /v1/embeddings`, `POST /v1/moderations`, `POST /v1/images/generations`, `POST /v1/audio/transcriptions`, `POST /v1/audio/translations`, `POST /v1/audio/speech`, `/v1/files*`, `POST /v1/rerank`, and `/v1/batches` can be served by a backend with `provider` configured (adds `x-ditto-translation: <provider>`).
- Control-plane demo endpoint: `POST /v1/gateway` (JSON `GatewayRequest`; accepts `Authorization: Bearer <virtual_key>`).
- `GET /health`
- `GET /metrics`
- `GET /admin/keys` (admin token via `Authorization` or `x-admin-token` if configured). Redacts tokens unless `?include_tokens=true`.
- MCP tool gateway: `ANY /mcp*` (JSON-RPC `tools/list` / `tools/call` + convenience endpoints), and MCP tool integration for `POST /v1/chat/completions` and `POST /v1/responses` via `tools: [{"type":"mcp", ...}]`.
- A2A agent gateway: `GET /a2a/:agent_id/.well-known/agent-card.json` and `POST /a2a/*` JSON-RPC proxying (requires `a2a_agents` configured).
- `POST /admin/keys` and `PUT|DELETE /admin/keys/:id` (requires the write admin token).
- LiteLLM-style key management (requires admin auth): `/key/generate`, `/key/update`, `/key/regenerate` (or `/key/:key/regenerate`), `/key/delete`, `/key/info`, `/key/list`.
  - `/key/info` accepts `?key=...` (admin query) or defaults to the `Authorization: Bearer <virtual_key>` token when `?key` is omitted (self lookup).
- `POST /admin/proxy_cache/purge` (requires the write admin token and `--proxy-cache`; body can be `{ \"cache_key\": \"...\" }` or `{ \"all\": true }`).
- `GET /admin/backends` and `POST /admin/backends/:name/reset` (reset requires the write admin token and `--features gateway-routing-advanced`).

CLI options:

- `--listen HOST:PORT` (or `--addr HOST:PORT`) sets the bind address (default: `127.0.0.1:8080`).
- `--dotenv PATH` loads a dotenv file (KEY=VALUE) for `${ENV_VAR}` interpolation and provider auth env lookups.
- `--admin-token TOKEN` enables `/admin/*` endpoints (write admin token).
- `--admin-token-env ENV` loads the write admin token from env (works with `--dotenv`).
- `--admin-read-token TOKEN` enables `/admin/*` read-only endpoints.
- `--admin-read-token-env ENV` loads the read-only admin token from env (works with `--dotenv`).
- `--backend name=url` adds/overrides a backend for `POST /v1/gateway` (the backend is a URL that accepts `GatewayRequest` JSON and returns `GatewayResponse` JSON).
- `--upstream name=base_url` adds/overrides an OpenAI-compatible upstream backend (in addition to `gateway.json`).
- `--state PATH` enables persistence for admin virtual-key mutations (writes a `GatewayStateFile` JSON with `virtual_keys`; if the file exists it is loaded on startup, otherwise it is created from `gateway.json`).
- `--sqlite PATH` enables persistence for admin virtual-key mutations in a sqlite file (requires `--features gateway-store-sqlite`; loaded on startup; cannot be combined with `--state`).
- `--redis URL` enables redis persistence (requires `--features gateway-store-redis`).
- `--redis-env ENV` loads the redis URL from env (works with `--dotenv`; requires `--features gateway-store-redis`).
- `--redis-prefix PREFIX` sets the redis key prefix (requires `--features gateway-store-redis` and `--redis`/`--redis-env`).
- `--json-logs` emits JSON log records to stderr.
- `--proxy-max-in-flight N` limits concurrent in-flight proxy requests (rejects with 429 when exceeded). If omitted, default is `256`.
- `--proxy-cache` enables a best-effort cache for non-streaming OpenAI-compatible responses (requires `--features gateway-proxy-cache`). When combined with `--redis`, responses are also cached in Redis (shared across instances).
- `--proxy-cache-ttl SECS` sets the proxy cache TTL (implies `--proxy-cache`).
- `--proxy-cache-max-entries N` sets the in-memory proxy cache capacity (implies `--proxy-cache`).
- `--proxy-cache-max-body-bytes N` sets the maximum cached body size per entry (implies `--proxy-cache`).
- `--proxy-cache-max-total-body-bytes N` sets the in-memory total cached body budget (implies `--proxy-cache`).
- `--proxy-retry` enables retry on retryable statuses (requires `--features gateway-routing-advanced`).
- `--proxy-retry-status-codes CODES` overrides retry status codes (comma-separated; implies `--proxy-retry`).
- `--proxy-retry-max-attempts N` sets max retry attempts (implies `--proxy-retry`).
- `--proxy-circuit-breaker` enables a simple circuit breaker (requires `--features gateway-routing-advanced`).
- `--proxy-cb-failure-threshold N` sets circuit breaker failure threshold (implies `--proxy-circuit-breaker`).
- `--proxy-cb-cooldown-secs SECS` sets circuit breaker cooldown seconds (implies `--proxy-circuit-breaker`).
- `--proxy-health-checks` enables active health checks (requires `--features gateway-routing-advanced`).
- `--proxy-health-check-path PATH` overrides the health check request path (implies `--proxy-health-checks`; default: `/v1/models`).
- `--proxy-health-check-interval-secs SECS` sets health check interval seconds (implies `--proxy-health-checks`).
- `--proxy-health-check-timeout-secs SECS` sets health check timeout seconds (implies `--proxy-health-checks`).
- `--pricing-litellm PATH` loads LiteLLM-style pricing JSON for cost budgets (requires `--features gateway-costing`).
- `--prometheus-metrics` enables a Prometheus metrics endpoint (requires `--features gateway-metrics-prometheus`).
- `--prometheus-max-key-series N` limits per-key series cardinality (implies `--prometheus-metrics`).
- `--prometheus-max-model-series N` limits per-model series cardinality (implies `--prometheus-metrics`).
- `--prometheus-max-backend-series N` limits per-backend series cardinality (implies `--prometheus-metrics`).
- `--prometheus-max-path-series N` limits per-path series cardinality (implies `--prometheus-metrics`).
- `--devtools PATH` enables JSONL request/response logging (requires `--features gateway-devtools`).
- `--otel` enables OpenTelemetry tracing export via OTLP (requires `--features gateway-otel`).
- `--otel-endpoint URL` overrides the OTLP endpoint (implies `--otel`).
- `--otel-json` enables JSON formatted tracing logs (implies `--otel`).

Response headers:

- `x-ditto-backend`: which backend handled the request
- `x-ditto-request-id`: request id (uses incoming `x-request-id` or generates one)
- `x-ditto-cache`: `hit` when served from the optional proxy cache
- `x-ditto-cache-key`: cache key for the optional proxy cache (when enabled and cacheable)
- `x-ditto-cache-source`: `memory` or `redis` when `x-ditto-cache=hit`
- `x-ditto-shim`: present when `POST /v1/responses` is shimmed via `POST /v1/chat/completions`
- `x-ditto-translation`: present when a translation backend handled the request

## Stream Collection

If you want to consume a streaming response but still produce a final unified `GenerateResponse`,
use `collect_stream`:

```rust
use ditto_llm::{collect_stream, GenerateRequest, LanguageModel};

let stream = llm.stream(GenerateRequest::from(messages)).await?;
let collected = collect_stream(stream).await?;
println!("{}", collected.response.text());
```

## Text (generateText / streamText)

Single-step text helpers (no tool execution loop):

```rust
use ditto_llm::{GenerateRequest, LanguageModelTextExt};

let out = llm.generate_text(GenerateRequest::from(messages)).await?;
println!("{}", out.text);
```

Streaming:

```rust
use futures_util::StreamExt;
use ditto_llm::{GenerateRequest, LanguageModelTextExt};

let (handle, mut text_stream) = llm
    .stream_text(GenerateRequest::from(messages))
    .await?
    .into_text_stream();
while let Some(delta) = text_stream.next().await {
    print!("{}", delta?);
}
let final_text = handle.final_text()?.unwrap();
println!("\nfinal={final_text}");
```

## Structured Output (generateObject / streamObject)

Use `LanguageModelObjectExt` to request structured output (AI SDK-style `generateObject` / `streamObject`).

Defaults (`ObjectOptions::default()`):

- `strategy = Auto`:
  - `openai` → JSON Schema via `response_format` (native)
  - other providers (incl. `openai-compatible`) → tool-call enforced JSON (wraps output under `{"value": ...}`)
  - always falls back to extracting JSON from text if needed
- `output = Object` (top-level object)

```rust
use ditto_llm::{GenerateRequest, JsonSchemaFormat, LanguageModelObjectExt, Message};
use serde_json::json;

let schema = JsonSchemaFormat {
    name: "recipe".to_string(),
    schema: json!({ "type": "object" }),
    strict: None,
};

let out = llm
    .generate_object_json(GenerateRequest::from(vec![Message::user("hi")]), schema)
    .await?;

println!("{}", out.object);
```

Streaming (partial objects):

```rust
use futures_util::StreamExt;

let (handle, mut partial_object_stream) = llm
    .stream_object(GenerateRequest::from(messages), schema)
    .await?
    .into_partial_stream();
while let Some(partial) = partial_object_stream.next().await {
    println!("{:?}", partial?);
}
let final_obj = handle.final_json()?.unwrap();
println!("{final_obj}");
```

Streaming arrays (AI SDK `elementStream`):

```rust
use ditto_llm::{ObjectOptions, ObjectOutput};
use futures_util::StreamExt;

let mut result = llm
    .stream_object_with(
        GenerateRequest::from(messages),
        schema, // schema for a single element; ditto wraps it as {type:"array", items: ...}
        ObjectOptions {
            output: ObjectOutput::Array,
            ..ObjectOptions::default()
        },
    )
    .await?;

while let Some(element) = result.element_stream.next().await {
    println!("element = {}", element?);
}
```

## Streaming Cancellation

If you need an explicit abort handle (instead of relying on drop semantics), wrap the stream:

```rust
use ditto_llm::{abortable_stream, GenerateRequest, LanguageModel};

let stream = llm.stream(GenerateRequest::from(messages)).await?;
let abortable = abortable_stream(stream);
abortable.handle.abort();
```

## Embeddings

`EmbeddingModelExt` provides AI SDK-style aliases:

```rust
use ditto_llm::EmbeddingModelExt;

let vectors = embeddings.embed_many(vec!["hello".to_string(), "world".to_string()]).await?;
let one = embeddings.embed_one("hi".to_string()).await?;
```

## Custom HTTP Client

Providers accept a custom `reqwest::Client` so you can configure timeouts, proxies, and default
headers (e.g. enterprise gateways):

```rust
let http = reqwest::Client::builder().build()?;
let llm = ditto_llm::OpenAI::new(api_key).with_http_client(http);
```

When building providers from config, you can also set default headers via
`ProviderConfig.http_headers`.

## Provider Auth (Custom Headers / Query Params)

Providers apply their standard auth headers by default (OpenAI/OpenAI-compatible: bearer token;
Anthropic: `x-api-key`; Google: `x-goog-api-key`).

If you need a non-standard auth header (e.g. Azure / enterprise gateways), use:

```toml
auth = { type = "http_header_env", header = "api-key", keys = ["AZURE_OPENAI_API_KEY"] }
```

If your gateway expects auth in a query param (e.g. `...?api_key=...`), use:

```toml
auth = { type = "query_param_env", param = "api_key", keys = ["GATEWAY_API_KEY"] }
```

If you need to fetch a token dynamically (e.g. `gcloud auth print-access-token`, `aws-vault`, Vault CLI), use:

```toml
auth = { type = "command", command = ["gcloud", "auth", "print-access-token"] }
```

The command stdout may be a plain token, a JSON string (`"sk-..."`), or a JSON object with
`api_key`/`token`/`access_token`. Ditto enforces a 15s timeout (configurable via
`DITTO_AUTH_COMMAND_TIMEOUT_MS/SECS`) and a 64KiB stdout/stderr cap.

## Provider Query Params (Optional)

If your provider requires additional fixed query params on every request (e.g. Azure OpenAI
`api-version`), set `ProviderConfig.http_query_params`:

```toml
base_url = "https://{resource}.openai.azure.com/openai/deployments/{deployment}"
http_query_params = { "api-version" = "2024-02-01" }
auth = { type = "http_header_env", header = "api-key", keys = ["AZURE_OPENAI_API_KEY"] }
```

## Provider Options (Per Provider)

Requests that support `provider_options` accept either:

- **Legacy (flat)**: a single JSON object applied to the current provider.
- **Bucketed**: a JSON object keyed by provider id (optionally with a `"*"` default bucket).

Bucketed example:

```json
{
  "provider_options": {
    "*": { "parallel_tool_calls": false },
    "openai": { "reasoning_effort": "high" },
    "openai-compatible": { "response_format": { "type": "json_schema", "json_schema": { "name": "answer", "schema": { "type": "object" } } } }
  }
}
```

Precedence is `"*"` (base) → provider bucket (override). Provider ids are: `openai`,
`openai-compatible` (also accepts `openai_compatible` as an alias key), `anthropic`, `google`,
`cohere`, `bedrock`, `vertex`.

## File Upload (Optional)

If you want to send PDFs via `file_id` (instead of inlining base64), OpenAI and OpenAI-compatible
providers expose a small upload helper:

```rust
let file_id = llm.upload_file("doc.pdf", pdf_bytes).await?;
```

## Development

Enable repo-local git hooks:

```bash
git config core.hooksPath githooks
```

This enforces Conventional Commits and requires each commit to include `CHANGELOG.md`.

### Integration Tests (Optional)

Enable the `integration` feature and set real credentials:

- OpenAI Responses: `OPENAI_API_KEY` + `OPENAI_MODEL`
- OpenAI-compatible: `OPENAI_COMPAT_BASE_URL` + `OPENAI_COMPAT_MODEL` (+ `OPENAI_COMPAT_API_KEY` optional)

Then run:

```bash
cargo test --all-features
```

================================================================================
FILE: PROVIDERS.md
================================================================================

# Provider Coverage (Ditto-LLM vs AI SDK)

Ditto-LLM’s design mirrors the AI SDK approach: unify **semantics** (generate/stream/tools/etc.),
not HTTP endpoints.

This file tracks coverage using two paths:

1. **Native adapters**: direct provider APIs (best UX + full-fidelity behavior).
2. **OpenAI-compatible adapters**: any provider reachable via OpenAI-compatible gateways (e.g.
   LiteLLM) or native OpenAI-compatible APIs.

## Capability Matrix (high level)

| Capability | Unified Trait/Type | Native Providers | OpenAI-compatible Providers |
| --- | --- | --- | --- |
| Chat generation | `LanguageModel::{generate,stream}` | OpenAI `/responses`, Anthropic `/messages`, Google `generateContent`, Cohere `/v2/chat` | `/chat/completions` |
| Tools | `Tool` / `ToolChoice` / `ContentPart::ToolCall` | OpenAI/Anthropic/Google/Cohere | yes (depends on upstream) |
| JSON Schema output | `ProviderOptions.response_format` | OpenAI `/responses` | pass-through (depends on upstream) |
| Embeddings | `EmbeddingModel::embed` | OpenAI, Google, Cohere | `/embeddings` |
| Images | `ImageGenerationModel::generate` | OpenAI | `/images/generations` |
| Audio | `AudioTranscriptionModel` / `AudioTranslationModel` / `SpeechModel` | OpenAI | `/audio/*` |
| Moderations | `ModerationModel::moderate` | OpenAI | `/moderations` |
| Rerank | `RerankModel::rerank` | Cohere | (gateway-dependent) |
| Batches | `BatchClient::{create,retrieve,cancel,list}` | OpenAI | `/batches` |

## Provider Coverage (pragmatic)

| Provider (AI SDK) | Ditto-LLM path | Notes |
| --- | --- | --- |
| OpenAI | Native | `/responses` + streaming/tools; also embeddings/images/audio/moderations (feature-gated) |
| OpenAI-compatible | Native adapter | Use for LiteLLM / DeepSeek / Qwen / Groq / Mistral / Together / Fireworks / xAI / Perplexity, etc. |
| Anthropic | Native | `/messages` + streaming/tools |
| Google | Native | `generateContent` + streaming/tools; embeddings (feature-gated) |
| Cohere | Native | chat + embeddings + rerank |
| Azure OpenAI | OpenAI-compatible | Needs `http_query_params = { \"api-version\" = \"...\" }` + `api-key` header |
| Amazon Bedrock | Native | Anthropic Messages-on-Bedrock generate + streaming/tools via SigV4 (feature `bedrock`) |
| Google Vertex | Native | GenAI generateContent + streamGenerateContent (SSE) + tools via OAuth client-credentials (feature `vertex`) |

## Feature Bundles

- `--features all`: all providers + all optional endpoint traits
- `--features all-providers`: all provider adapters
- `--features all-capabilities`: all optional endpoint traits

================================================================================
FILE: COMPARED_TO_LITELLM_AI_SDK.md
================================================================================

# Ditto-LLM vs LiteLLM Proxy vs Vercel AI SDK（相同点/不同点/缺口）

目标口径：`ditto-llm` 要成为 **LiteLLM Proxy + Vercel AI SDK 的能力超集**，但通过“分层 + feature gating”保证默认构建保持小而清晰：

- **SDK（AI SDK-like）**：Rust 里直接调用 providers（统一类型、warnings、严格错误边界）
- **Gateway（LiteLLM-like）**：OpenAI-compatible HTTP surface + control-plane（virtual keys/limits/budget/cache/routing/logs）
- **Passthrough（不变形）**：OpenAI `/responses` raw passthrough（items round-trip + `/responses/compact`）
- **Translation（超集项）**：OpenAI in/out → native providers（减少必须先上 LiteLLM 的依赖）

本文件是“对比 + 缺口”的口径，具体 Roadmap 见 `TODO.md`。

---

## 1) SDK 侧（对标 Vercel AI SDK）

### 已对齐

- 统一抽象：`LanguageModel` / `EmbeddingModel` + `Message`/`ContentPart`/`Tool`/`Warning`
- `generate_text` / `stream_text`（AI SDK `generateText`/`streamText`）
- 结构化输出：`generate_object_json` / `stream_object`（JSON schema / tool-call enforced）
- 多模态输入（images/PDF）：统一为 `ContentPart`
- 可选 agent loop：`feature=agent`
- Stream protocol v1 HTTP 适配层：以 SSE/NDJSON 输出（feature `sdk`）
- 内存安全：stream fan-out 有界缓冲 + 聚合/缓冲区 max-bytes 上限（超限发出 `Warning`，避免 OOM）

### 主要差异

- AI SDK 的优势在于 JS/TS 生态 + UI hooks（React 等）；Ditto 的定位是 Rust 侧“可测试/可审计/可控依赖”的 SDK，并不复刻前端 hooks。
- Ditto 将 provider 差异通过 `Warning` 暴露，而不是静默降级。

### 可选超集项（部分已实现）

- 常用工具 wrappers（shell/fs/http 等）作为可选模块（✅ 已提供 `http_fetch` + `shell_exec` + `safe-fs-tools` 驱动的 `fs_read_file`/`fs_find`/`fs_grep`/`fs_write_file`/`fs_delete_file`/`fs_list_dir`/`fs_stat`/`fs_mkdir`/`fs_move`/`fs_copy_file`）
- “模板/脚手架”生态：AI SDK 的强项是大量可复制模板；Ditto 以 docs/工程化补齐（✅ `deploy/docker-compose.yml`、`deploy/k8s/*`、`deploy/helm/*` + Node/Python/Go 调用示例；仍可继续扩展更多模板）。
- AI SDK UI/RSC 生态：Ditto 不复刻 hooks/RSC，但提供基于 stream protocol v1 的最小 JS/TS client + React hooks（✅ `packages/ditto-client`、`packages/ditto-react`）。
- 应用侧缓存范式：基于 `LanguageModelLayer` 的缓存 middleware + 流式回放（✅ `CacheLayer`）。
- 生态适配器：LangChain/LlamaIndex 等协议级桥接（可选附加）

---

## 2) Gateway 侧（对标 LiteLLM Proxy）

### 已对齐（MVP）

- OpenAI-compatible proxy：`ANY /v1/*`（含 SSE streaming）+ per-backend header/query-param injection
- LiteLLM-style conveniences：`/key/*` key management endpoints（可选启用）+ 常用 OpenAI 路由无 `/v1` 前缀别名（例如 `/chat/completions`）
- virtual keys（可选启用）+ rpm/tpm limits + token/USD budget + guardrails
- OpenAI `/v1/responses` shim：当 upstream 不支持 `/v1/responses` 时，自动 fallback 到 `/v1/chat/completions` 并返回“Responses-like”（含 streaming + tool_calls）
- Translation proxy：OpenAI in/out 的 `GET /v1/models` + `GET /v1/models/*` + `POST /v1/chat/completions` + `POST /v1/completions` + `POST /v1/responses` + `POST /v1/responses/compact` + `POST /v1/embeddings` + `POST /v1/moderations` + `POST /v1/images/generations` + `POST /v1/audio/transcriptions` + `POST /v1/audio/translations` + `POST /v1/audio/speech` + `/v1/files*` + `POST /v1/rerank` + `/v1/batches`（backend 配置 `provider`；feature `gateway-translation`）
- admin key 管理端点（可选启用）+ state/sqlite/redis 持久化 virtual keys + budgets/audit logs
- 可选 devtools JSONL 事件日志（`--features gateway-devtools`）+ 可选 JSON logs（`--json-logs`）
- 可选 proxy cache（`--features gateway-proxy-cache`）+ 可选 Prometheus metrics（`--features gateway-metrics-prometheus`）
- 默认内存安全：proxy 对非 SSE 响应默认流式转发；仅在体积可控时才有界缓冲用于 proxy cache 或 `usage` 结算；`usage` 缓冲上限由 `--proxy-usage-max-body-bytes` 控制并与 cache 上限解耦
- 可选 proxy retry/circuit breaker（`--features gateway-routing-advanced`）
- 可选 pricing table + USD budgets（`--features gateway-costing`）
- 可选 OpenTelemetry（`--features gateway-otel`）
- request id 贯穿：响应包含 `x-ditto-request-id`（复用/生成 `x-request-id`）

### 主要差异/缺口（P0：达到“可替换 LiteLLM”）

- 路由：已支持“主动健康检查/探活”（feature `gateway-routing-advanced`），仍缺更丰富的策略（更细粒度熔断、分级 fallback、更细粒度 backpressure）
- 成本：支持 **tiktoken-based token 计数**（best-effort；feature `gateway-tokenizer`）+ **usage-based settle**（非 streaming 响应优先按 `usage` 结算；否则回退预估）+ LiteLLM prompt cache 成本（read: `cache_read_input_token_cost` + `cached_tokens`；write: `cache_creation_input_token_cost` + `cache_creation_input_tokens`；tiered: `*_above_*_tokens`）+ LiteLLM service tier 成本（`*_priority`/`*_flex` + request `service_tier`）+ proxy `model_map` 计费对齐（按 backend 映射后的 model 选价）；支持按 tenant/project/user 归因与共享预算（`virtual_keys[].tenant_id/project_id/user_id` + `tenant_budget/project_budget/user_budget` + `/admin/budgets/tenants|projects|users` + `/admin/costs/tenants|projects|users`）
- 观测：Prometheus/OTel/JSON logs 已有，并提供 per-path/per-backend latency histograms 与状态码计数；仍缺更细粒度的指标维度（例如按 model/provider 聚合、streaming 特有指标）以及可配置的采样/脱敏策略
- 代理缓存：已有 best-effort in-memory cache（非流式）；支持在 `--redis` 场景下把 proxy cache 写入 Redis 以跨实例复用，并提供 admin purge（按 cache key 或全量）；仍缺 streaming cache 与更细粒度的 invalidation 策略
- Translation：当前覆盖 `GET /v1/models`/`GET /v1/models/*`/`POST /v1/chat/completions`/`POST /v1/completions`/`POST /v1/responses`/`POST /v1/responses/compact`/`POST /v1/embeddings`/`POST /v1/moderations`/`POST /v1/images/generations`/`POST /v1/audio/transcriptions`/`POST /v1/audio/translations`/`POST /v1/audio/speech`/`/v1/files*`/`POST /v1/rerank`/`/v1/batches`；其余 OpenAI 端点的 translation 仍需扩面
- 企业平台能力：仍缺完整 RBAC/SSO/SCIM 与更复杂的组织/审批流；但已具备可用的“平台 MVP”（✅ RBAC-lite：read-only/write admin token + tenant-scoped admin token；✅ tenant 维度归因与 shared budgets/limits；✅ per-route Redis 分布式限流（加权滑窗 60s）；✅ 审计保留期 + HTTP 导出（JSONL/CSV）+ hash-chain + verifier；✅ 审计导出到对象存储（S3/GCS）+ manifest（sha256/chain hash；可配 S3 Object Lock 参数）；✅ Docker Compose / K8s / Helm + Grafana dashboard + PrometheusRule）。仍缺：IP-based/令牌桶限流、配置版本化/灰度/回滚等更完整平台能力。
- 平台化生态：✅ Secret Manager 集成（`secret://...`）+ ✅ 最小 Admin UI；仍缺：更多 guardrails/alerting/logging destinations 的官方 adapters（可先做通用扩展点 + 少量官方适配）
- 平台扩展项：✅ A2A agent gateway（LiteLLM-like `/a2a/*` JSON-RPC 代理）+ ✅ MCP gateway（LiteLLM-like `/mcp*` + OpenAI-compatible `POST /v1/chat/completions` 与 `POST /v1/responses` 的 `tools: [{\"type\":\"mcp\", ...}]`）已支持；仍缺 LiteLLM 那种更细粒度的 MCP 权限/参数白名单等企业策略（可先用 `allowed_tools` + 多实例隔离承接）

---

## 3) “基础功能 vs 可选附加（默认不安装）”口径

以 Cargo features 表达：

- **默认构建（不含 Gateway）**：providers + streaming/tools/embeddings（面向 SDK/库调用）
- **可选：`gateway`**：HTTP server + control-plane + OpenAI-compatible proxy
- **可选：`gateway-devtools`**：在 `gateway` 基础上启用 JSONL devtools logging（依赖 `sdk`）
- **可选（默认不装）**：`gateway-proxy-cache`、`gateway-store-sqlite`、`gateway-store-redis`、`gateway-devtools`、`gateway-otel`、`gateway-metrics-prometheus`、`gateway-routing-advanced`、`gateway-costing`、`gateway-tokenizer`
- **后续可选（规划）**：`gateway-proxy-cache-redis`、translation proxy（OpenAI in/out → native providers）等

---

## 4) Codex CLI 对齐约束（为什么 Ditto 需要“不变形”模式）

对 OpenAI Responses 场景，Ditto 需要与 Codex CLI 对齐：`/responses` 原样 items 回放（含 encrypted compaction）+ `/responses/compact`。

因此 Ditto 需要同时支持两类路径：

1. **不变形 passthrough**：OpenAI `/responses` raw 直通（用于“完全对齐 Codex CLI”）
2. **统一抽象 SDK**：为非 OpenAI 或 OpenAI-compatible 服务提供 Ditto 的统一类型体验

这两者并行存在，是“超集”而不是二选一。

================================================================================
FILE: docs/src/index.md
================================================================================

# Ditto-LLM Docs

Ditto-LLM 的目标是成为 **LiteLLM Proxy + Vercel AI SDK 的能力超集**，但以 Rust-first 的方式交付：

- **Rust SDK（AI SDK Core-like）**：在 Rust 中以统一类型调用多个大模型提供方（providers），并显式暴露兼容性差异（Warnings）。
- **Gateway（LiteLLM-like）**：可选启用的 OpenAI-compatible HTTP gateway，支持路由/限流/预算/缓存/审计/观测等控制面能力，并可选启用 MCP（`/mcp*`）/ A2A（`/a2a/*`）等协议端点。
- **JS/React Clients（AI SDK UI-like）**：面向前端/JS 侧的最小 stream 协议解析与 hook（不试图复刻完整 AI SDK UI 生态）。
- **Passthrough vs Translation**：既支持 OpenAI `/v1/*` passthrough（不变形），也支持将 OpenAI 输入/输出翻译到 native providers（translation）。

本 docs 目录定位为“可复制落地”的工程手册：你可以从快速开始直接跑起来，然后按需深入 SDK / Clients / Gateway 的各个主题。

## 为什么用 Ditto-LLM？

LLM 集成的复杂度通常来自三件事：

1) **Provider 差异**：请求字段/返回字段/流式协议/tool calling/多模态的支持程度都不同。  
2) **工程化落地**：需要可测试、可审计、可观测、可控依赖的代码与接口边界。  
3) **平台能力**：当调用方变多时，网关侧需要 keys/limits/budgets/routing/audit/metrics。

Ditto-LLM 的取舍是：

- Rust 侧以统一 traits/types 提供 AI SDK 风格的“语义一致性”，并用 `Warning` 显式暴露降级与忽略字段（避免 silent fallback）。
- 网关侧以 LiteLLM 风格的 OpenAI-compatible surface 做“平台化控制面”，并保留 passthrough 与 translation 两条路径。

## 3 个入口（按你的使用方式选）

### 入口 1：Rust SDK（AI SDK Core-like）

最小示例（文本生成）：

```rust
use ditto_llm::{LanguageModelTextExt, Message, OpenAI};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("OPENAI_API_KEY").expect("missing OPENAI_API_KEY");
    let llm = OpenAI::new(api_key).with_model("gpt-4o-mini");
    let req = vec![Message::user("Say hello in one sentence.")].into();
    let out = llm.generate_text(req).await?;
    println!("{}", out.text);
    Ok(())
}
```

下一步：

- 「快速开始 → 方式 1：作为 Rust SDK」跑通第一个请求。
- 「SDK → 安装与最小用法」进入 SDK 主线。

### 入口 2：Gateway（LiteLLM-like）

启动本地网关：

```bash
cargo run --features gateway --bin ditto-gateway -- ./gateway.json --listen 0.0.0.0:8080
```

验证：

```bash
curl -sS http://127.0.0.1:8080/health
curl -sS http://127.0.0.1:8080/v1/models | head
```

下一步：

- 「Gateway → 运行网关」与「Gateway → 配置文件」。
- 如果你想直接复制一套可跑配置：看「Gateway → Gateway Recipes」与「模板与示例」。

### 入口 3：客户端（JS/React，AI SDK UI-like）

Ditto 提供最小 JS/React 客户端用于解析 **Stream Protocol v1**（SSE/NDJSON）并快速接入 UI。

下一步：

- 「客户端（JS/React）→ JS：Stream Protocol v1 解析」
- 「客户端（JS/React）→ React：useStreamV1」

## Provider 支持与兼容性

- 「参考 → Providers 能力矩阵」
- 如果你更关心“对标差异/缺口”：看仓库根目录 `COMPARED_TO_LITELLM_AI_SDK.md` 与 docs 的「迁移」章节。

## 模板与示例（像 AI SDK 的 templates 一样可复制）

如果你想要“拿来就跑”的参考：

- 「模板与示例」：Rust examples、Gateway docker-compose/k8s/helm、以及多语言客户端示例。

## LLM-friendly：llms.txt

如果你在用 LLM 辅助理解 Ditto（例如让它帮你改配置/写集成代码），可以直接把仓库根目录的 `llms.txt` 丢给它作为上下文入口。

`llms.txt` 包含一段“手写入口 + 约定”，并在末尾追加 **自动聚合的文档全文**（来自 `docs/src/SUMMARY.md`）。

为了便于部署文档站点时也能直接访问到它，仓库还会同步维护一份 `docs/src/llms.txt`（`mdbook build docs` 后会出现在站点根路径的 `/llms.txt`）。

如需刷新：

```bash
cargo run --bin ditto-llms-txt
```

## 本地构建（推荐）

本目录采用 `mdBook`（Rust 生态、零前端依赖）组织导航。

```bash
cargo install mdbook
mdbook serve docs
```

> 不想安装 mdBook 也没关系：`docs/src` 下的 Markdown 直接在 GitHub 上阅读同样可用。

## 读者路径

- 只想把模型调用集成到 Rust：从「SDK → 安装与最小用法」开始。
- 需要一个 LiteLLM 风格的 HTTP 网关：从「Gateway → 运行网关」开始。
- 关心“到底比 LiteLLM / AI SDK 多什么”：看 `COMPARED_TO_LITELLM_AI_SDK.md` 与本 docs 的「迁移」章节。

================================================================================
FILE: docs/src/getting-started.md
================================================================================

# 快速开始

Ditto-LLM 有三种常见使用方式：

1) **作为 Rust SDK**：在你的服务里直接调用 providers（OpenAI/Anthropic/Google/OpenAI-compatible/...）。  
2) **作为 HTTP Gateway（可选 feature）**：对外提供 OpenAI-compatible 的 `/v1/*` API，并在内部做路由/缓存/预算/审计等控制面逻辑。
3) **作为 JS/React 客户端（可选）**：解析 Ditto 的 Stream Protocol v1（SSE/NDJSON）并快速接入 UI（对标 AI SDK UI 的最小能力子集）。

## 方式 1：作为 Rust SDK

添加依赖（示例）：

```toml
[dependencies]
ditto-llm = "0.1"
tokio = { version = "1", features = ["rt-multi-thread", "macros"] }
```

最小用法（以 OpenAI 为例）：

```rust
use ditto_llm::{LanguageModelTextExt, Message, OpenAI};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("OPENAI_API_KEY").map_err(|_| {
        ditto_llm::DittoError::InvalidResponse("missing OPENAI_API_KEY".into())
    })?;
    let llm = OpenAI::new(api_key);
    let req = vec![
        Message::system("You are a helpful assistant."),
        Message::user("Say hello in one sentence."),
    ]
    .into();
    let out = llm.generate_text(req).await?;
    println!("{}", out.text);
    Ok(())
}
```

## 方式 2：作为 HTTP Gateway（LiteLLM-like）

启动一个本地 gateway：

```bash
cargo run --features gateway --bin ditto-gateway -- ./gateway.json --listen 0.0.0.0:8080
```

然后你可以用 OpenAI-compatible 的方式调用：

```bash
curl -sS http://127.0.0.1:8080/v1/models
```

## 方式 3：作为 JS/React 客户端（Stream Protocol v1）

如果你在前端/Node 侧需要消费 Ditto 的 streaming（SSE/NDJSON），仓库内提供了最小 JS/React 客户端：

- `@ditto-llm/client`：解析 Stream Protocol v1（SSE/NDJSON）+ 可选的 Admin API client
- `@ditto-llm/react`：`useStreamV1` hook（把 stream 聚合为 `text/chunks/warnings/done` 状态）

下一步建议阅读：

- 「客户端（JS/React）→ JS：Stream Protocol v1 解析」与「React：useStreamV1」。
- 「Gateway → 配置文件（gateway.json / gateway.yaml）」了解如何配置 upstream backends / virtual keys / router。
- 「Gateway → 运行网关」了解常用 CLI 选项与部署建议。
- 「SDK → 安装与最小用法」与「核心概念」了解 Ditto 的统一类型与 warnings 设计。

================================================================================
FILE: docs/src/templates/index.md
================================================================================

# 模板与示例

本页给你一组“可复制落地”的入口（对标 AI SDK docs 的 templates 思路）：你可以直接从仓库里的现成代码/配置开始，然后再回到 docs 深入理解原理与边界。

## Rust（SDK）示例

仓库根目录 `examples/` 下提供了覆盖主线能力的最小示例：

```bash
# 文本生成 / 流式 / tools / embeddings
cargo run --example basic
cargo run --example streaming
cargo run --example tool_calling
cargo run --example embeddings

# OpenAI-compatible（用于对接 LiteLLM / 其他兼容服务）
cargo run --example openai_compatible
cargo run --example openai_compatible_embeddings
```

多模态示例（需要本地文件输入）：

```bash
cargo run --example multimodal --features base64 -- ./image.png ./doc.pdf
```

下一步：

- 「SDK → 安装与最小用法」与「核心概念」。

## Gateway（部署/模板）

如果你想快速把 `ditto-gateway` 跑起来并具备“平台化控制面”：

- `deploy/docker-compose.yml`：本地可用的 docker-compose 模板（配套 `.env.example` / `gateway.example.json`）。
- `deploy/k8s/*`：Kubernetes 多副本模板。
- `deploy/helm/ditto-gateway`：Helm chart（包含 Grafana/Prometheus 辅助资源示例）。

对应 docs 页面：

- 「Gateway → Docker Compose（本地模板）」
- 「Gateway → Kubernetes（多副本模板）」
- 「Gateway → 部署：多副本与分布式」

## 多语言客户端示例（调用 Gateway 的 OpenAI-compatible `/v1/*`）

如果你只是想验证“对外兼容 OpenAI API”的调用方式：

- Node：`examples/clients/node/stream_chat_completions.mjs`（SSE streaming）
- Python：`examples/clients/python/chat_completions.py`
- Go：`examples/clients/go/chat_completions.go`

> 这些示例默认从环境变量读取 `DITTO_BASE_URL` 与（可选的）`DITTO_VK_TOKEN`，详见各目录的 `README.md`。

## Admin UI（可选）

仓库包含一个最小的 React 管理台：`apps/admin-ui`，用于：

- virtual keys 的增删改查
- 审计日志查看与导出（JSONL/CSV）

启动方式见：`apps/admin-ui/README.md`。


================================================================================
FILE: docs/src/concepts/index.md
================================================================================

# 核心概念

Ditto-LLM 的设计目标是：在 **不隐藏差异** 的前提下，让多 provider 的调用体验尽可能一致。

你需要先理解几个贯穿 SDK 与 Gateway 的概念：

- **Provider**：一个具体的大模型服务提供方（OpenAI / Anthropic / Google / OpenAI-compatible / Bedrock / Vertex / ...）。
- **Model**：provider 里的具体模型（例如 `gpt-4.1` / `claude-3-5-sonnet-20241022`）。
- **Request/Response**：Ditto 的统一请求/响应类型（`GenerateRequest` / `GenerateResponse` 等）。
- **Streaming**：以 `StreamChunk` 的形式把生成过程增量输出，并允许上层决定如何消费。
- **Warnings**：显式记录“兼容性降级”与“字段被忽略/被钳制”的原因，避免 silent fallback。

建议按顺序阅读本章的其他页面。

================================================================================
FILE: docs/src/concepts/features.md
================================================================================

# Feature Flags

Ditto-LLM 通过 Cargo features 控制体积与依赖：默认构建偏 SDK，Gateway 相关能力需要显式开启。

## 常用组合

- 只当 SDK 用（默认）：`openai` / `anthropic` / `openai-compatible` / `streaming` / `tools` / `embeddings`
- 全 provider：`--features all-providers`
- 全能力：`--features all-capabilities`
- 全部：`--features all`

## Gateway 相关

- `gateway`：启用 `ditto-gateway` HTTP 服务与控制面
- `gateway-translation`：启用 OpenAI in/out → native providers 的 translation endpoints
- `gateway-proxy-cache`：启用非 streaming 的 proxy cache（内存；可选写入 Redis）
- `gateway-devtools`：启用 `--devtools` JSONL 日志（等价于 `gateway` + `sdk`）
- `gateway-store-redis` / `gateway-store-sqlite`：启用持久化（分布式部署推荐 Redis）
- `gateway-routing-advanced`：启用 retry / circuit breaker / active health checks
- `gateway-metrics-prometheus`：启用 Prometheus metrics endpoint
- `gateway-otel`：启用 OpenTelemetry OTLP export

## Agent/SDK 工具

- `sdk`：stream protocol v1（NDJSON/SSE）与 devtools/telemetry/MCP 等工具适配；以及 SDK cache middleware（含 streaming replay）
- `agent`：ToolLoopAgent + tool executors（含 `safe-fs-tools`）

> 小提示：生产环境建议按需开启 features，避免把不必要依赖带进最终镜像。

================================================================================
FILE: docs/src/concepts/provider-model-request.md
================================================================================

# Provider / Model / Request

## Provider

Ditto 里“provider”是一个字符串标识，用于选择适配器与默认行为。

常见值：

- `openai`
- `anthropic`
- `google`
- `openai-compatible`（以及 LiteLLM-style aliases：`azure` / `deepseek` / `qwen` / `groq` / `mistral` / `openrouter` / ...）

## Model

`model` 通常是 provider 内部的模型 id。Ditto 会尽量把它原样传递，但在 Gateway 场景可能会被 `model_map` 重写。

## Request / Response

SDK 的核心请求/响应类型：

- `GenerateRequest` / `GenerateResponse`
- `StreamResult` / `StreamChunk`
- `Tool` / `ToolChoice` / `ContentPart`
- `Usage` / `Warning`

建议结合「SDK」章节的示例阅读。

================================================================================
FILE: docs/src/concepts/streaming.md
================================================================================

# Streaming

## 为什么 Ditto 使用 StreamChunk

不同 provider 的 streaming 协议差异很大：

- OpenAI：SSE events（Responses / Chat Completions）
- Anthropic：SSE events（Messages）
- Google：SSE events（GenAI）
- OpenAI-compatible：兼容但存在细微差异

Ditto 的策略是把这些协议统一为 `StreamChunk` 序列，然后由上层决定如何：

- 显示给用户（SSE/NDJSON/WebSocket/CLI）
- 聚合成最终 `GenerateResponse`（`collect_stream` / `StreamCollector`）
- 记录审计与指标

## Stream protocol v1（可选）

如果你需要把 Ditto 的 `StreamChunk` 接入你自己的 HTTP API（例如输出 NDJSON 或 SSE），可以启用 feature `sdk` 并使用 Ditto 的 stream protocol v1：

- `StreamEventV1`：`chunk` / `error` / `done`（带版本号 envelope）
- `stream_v1_ndjson` / `stream_v1_sse`：把 `StreamResult` 转成 HTTP 友好的字节流

详见「SDK → Stream Protocol v1（NDJSON / SSE）」。

## 常见坑

- **长输出会占用内存**：如果你选择“收集所有 chunk”，内存会随输出增长；Ditto 对部分内部聚合器/缓冲区设置了上限，超限会发出 `Warning` 并截断最终聚合结果。
- **慢消费会影响吞吐**：`stream_text` / `stream_object` 的 fan-out 使用有界缓冲；当你同时启用多条 stream 但其中一条消费很慢时，会对上游施加 backpressure（表现为等待/吞吐降低），而不是无界占用内存。
- **异常/恶意 SSE 会打爆内存**：Ditto 会对 SSE 单行与单事件设置上限；超限会以可控错误终止 stream。

本仓库倾向于把风险暴露给调用方，而不是静默丢数据。

================================================================================
FILE: docs/src/concepts/warnings.md
================================================================================

# Warnings 与兼容性

Ditto 的一个核心原则是：**差异要可见**。

当某个 provider 不支持某个字段/能力，或者 Ditto 为了保证稳定性对输入做了处理（例如 clamp 温度/丢弃非有限值），Ditto 会尽量：

- 把字段做 best-effort 映射/降级
- 同时通过 `Warning` 把“发生了什么”告诉调用方

这样做的好处：

- 你可以在日志/观测里定位“为什么某个模型没按预期工作”
- 你可以在 Gateway 侧按 Warning 做策略（例如拒绝不兼容请求）

在 SDK 示例里你会频繁看到 `response.warnings`，建议在生产环境把它打到日志（并注意脱敏）。

================================================================================
FILE: docs/src/sdk/index.md
================================================================================

# SDK（AI SDK-like）

Ditto-LLM 的 SDK 侧对标 Vercel AI SDK 的 “Core” 部分：提供统一的模型接口与常用高层 helper，但不复刻前端 UI hooks。

你会反复遇到三个关键词：

- **统一类型**：`GenerateRequest` / `GenerateResponse` / `ContentPart` / `Tool` / `Usage`
- **Streaming primitives**：`StreamChunk`，以及 `stream_text` / `stream_object` 等 fan-out helpers
- **Warnings**：把 provider 差异显式暴露给调用方（避免 silent fallback）

本章结构建议按顺序阅读：

1) 先看「安装与最小用法」把第一个请求跑通。  
2) 再看 text/stream/structured outputs/tool calling，理解 Ditto 的主线能力。  
3) 再看 Agents/Middleware，把多步 tool calling 与可组合扩展补齐。  
4) 最后再看 ProviderConfig、错误处理与测试策略，把工程化收尾。  

如果你来自 AI SDK，可以先读「迁移 → 从 Vercel AI SDK 迁移（概念对照）」。

================================================================================
FILE: docs/src/sdk/quickstart.md
================================================================================

# 安装与最小用法

## Rust 版本要求

`ditto-llm` 使用 Rust 2024 edition，并声明 `rust-version = 1.85`（见 `Cargo.toml`）。

## 依赖引入

最简单的方式是直接使用默认 features（覆盖常见 provider + streaming/tools/embeddings）：

```toml
[dependencies]
ditto-llm = "0.1"
tokio = { version = "1", features = ["rt-multi-thread", "macros"] }
```

如果你希望最小化依赖（适合生产镜像瘦身），可以关闭默认 features 并按需开启。

例如：只用 OpenAI + streaming：

```toml
[dependencies]
ditto-llm = { version = "0.1", default-features = false, features = ["openai", "streaming"] }
tokio = { version = "1", features = ["rt-multi-thread", "macros"] }
```

例如：只用 OpenAI-compatible + streaming：

```toml
[dependencies]
ditto-llm = { version = "0.1", default-features = false, features = ["openai-compatible", "streaming"] }
tokio = { version = "1", features = ["rt-multi-thread", "macros"] }
```

> 提示：更多 feature flags 见「核心概念 → Feature Flags」。

## 最小用法：OpenAI

```rust
use ditto_llm::{LanguageModelTextExt, Message, OpenAI};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("OPENAI_API_KEY")
        .map_err(|_| ditto_llm::DittoError::InvalidResponse("missing OPENAI_API_KEY".into()))?;

    let llm = OpenAI::new(api_key).with_model("gpt-4o-mini");

    let messages = vec![
        Message::system("You are a helpful assistant."),
        Message::user("What is 2+2?"),
    ];

    let resp = llm.generate_text(messages.into()).await?;
    println!("{}", resp.text);
    Ok(())
}
```

## 最小用法：OpenAI-compatible（LiteLLM / Azure / DeepSeek / Qwen / …）

需要 features：`openai-compatible`（以及你是否需要 streaming/tools/embeddings 等能力）。

OpenAI-compatible 适配器的关键在于：

- `base_url` 指向兼容 OpenAI API 的 upstream（例如 LiteLLM proxy 的 `/v1`）
- 通过 `ProviderConfig.auth` 或环境变量传入 token
- 选择一个 upstream 支持的 `model`

示例（从 `ProviderConfig` 构建）：

```rust
use ditto_llm::{Env, OpenAICompatible, ProviderAuth, ProviderConfig};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let env = Env::default();
    let config = ProviderConfig {
        base_url: Some("http://127.0.0.1:4000/v1".to_string()),
        default_model: Some("gpt-4o-mini".to_string()),
        auth: Some(ProviderAuth::ApiKeyEnv {
            keys: vec!["OPENAI_COMPAT_API_KEY".to_string()],
        }),
        ..Default::default()
    };

    let llm = OpenAICompatible::from_config(&config, &env).await?;
    let out = llm
        .generate(vec![ditto_llm::Message::user("Say hi.")] .into())
        .await?;
    println!("{}", out.text());
    Ok(())
}
```

## 用 ProviderConfig 统一管理配置

Ditto 提供 `ProviderConfig` + `Env` 的组合，让你可以：

- 把 provider 的 base_url/headers/query/auth 统一放进配置
- 在 Gateway/路由场景复用同一份配置结构
- 在本地用 dotenv 内容（或网关 `--dotenv`）注入敏感信息

常见模式：

- SDK：`OpenAI::from_config(&ProviderConfig, &Env)`（或其他 provider 的 `from_config`）
- 模型发现：`list_available_models(&ProviderConfig, &Env)`

详细字段解释见「SDK → ProviderConfig 与 Profile」。

================================================================================
FILE: docs/src/sdk/generate-text.md
================================================================================

# 文本生成：generate_text

`generate_text` 是一个高层 helper，对标 AI SDK 的 `generateText`：

- 输入：`GenerateRequest`
- 输出：`GenerateTextResponse { text, response }`
- 语义：单次请求（不会自动执行工具循环）

## 最小示例

```rust
use ditto_llm::{GenerateRequest, LanguageModelTextExt, Message, OpenAI};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("OPENAI_API_KEY").map_err(|_| {
        ditto_llm::DittoError::InvalidResponse("missing OPENAI_API_KEY".into())
    })?;
    let llm = OpenAI::new(api_key).with_model("gpt-4o-mini");

    let req = GenerateRequest::from(vec![
        Message::system("You are a helpful assistant."),
        Message::user("Say hello in one sentence."),
    ]);

    let out = llm.generate_text(req).await?;
    println!("text: {}", out.text);
    println!("finish_reason: {:?}", out.response.finish_reason);
    println!("usage: {:?}", out.response.usage);
    println!("warnings: {:?}", out.response.warnings);
    Ok(())
}
```

## 何时用 `generate_text`，何时用 `generate`

- 用 `generate_text`：你只关心最终文本（同时保留完整 `GenerateResponse` 以获取 usage/warnings）。
- 用 `generate`：你需要处理多模态 `ContentPart`、tool calls、reasoning、或更细粒度的 output 结构。

`GenerateResponse.content` 是一个 `Vec<ContentPart>`，可能包含：

- `ContentPart::Text`
- `ContentPart::ToolCall` / `ContentPart::ToolResult`
- `ContentPart::Reasoning`
- `ContentPart::Image` / `ContentPart::File`

## 常用请求字段（GenerateRequest）

`GenerateRequest` 兼容 OpenAI-style 字段（不同 provider 支持度不同；不支持会产生 `Warning`）：

- `model`：请求级覆盖模型
- `temperature` / `top_p`
- `max_tokens`
- `seed`
- `presence_penalty` / `frequency_penalty`
- `logprobs` / `top_logprobs`
- `user`
- `stop_sequences`
- `tools` / `tool_choice`
- `provider_options`：细化到某个 provider 的额外能力（见「SDK → ProviderConfig 与 Profile」与「SDK → 工具调用」）

## Warnings 是“契约的一部分”

Ditto 的默认策略是 best-effort 映射，并通过 `Warning` 明确告诉你：

- 哪些字段被忽略/降级
- 哪些参数被 clamp 或被丢弃（例如非有限值）
- provider 的能力差异（tool calling / streaming / json schema）

生产建议：

- 将 `warnings` 写入日志（注意脱敏），用于定位“行为不一致”的根因。
- 在 CI 里对关键路径做断言（例如：不允许出现某类 Warning）。

================================================================================
FILE: docs/src/sdk/stream-text.md
================================================================================

# 文本流式：stream_text

`stream_text` 对标 AI SDK 的 `streamText`：它把底层 provider 的 streaming 统一成两个可消费的 stream：

- `text_stream`: `Stream<Item = Result<String>>`（只输出文本增量）
- `full_stream`: `Stream<Item = Result<StreamChunk>>`（完整 chunk，包括 warnings/usage/tool deltas 等）

并在内部使用 `StreamCollector` 维护最终 `GenerateResponse`，供你在 stream 结束后读取 `final_text()` / `final_summary()`。

## 最小示例：消费 text deltas

```rust
use futures_util::StreamExt;
use ditto_llm::{GenerateRequest, LanguageModelTextExt, Message, OpenAI};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("OPENAI_API_KEY").map_err(|_| {
        ditto_llm::DittoError::InvalidResponse("missing OPENAI_API_KEY".into())
    })?;
    let llm = OpenAI::new(api_key).with_model("gpt-4o-mini");

    let req = GenerateRequest::from(vec![
        Message::system("You are a helpful assistant."),
        Message::user("Stream a short poem about Rust."),
    ]);

    let (handle, mut text_stream) = llm.stream_text(req).await?.into_text_stream();

    while let Some(delta) = text_stream.next().await {
        print!("{}", delta?);
    }

    let final_text = handle.final_text()?.unwrap_or_default();
    println!("\nfinal={final_text}");
    Ok(())
}
```

## 进阶：消费 full stream（StreamChunk）

当你需要：

- 观察 `Warning` 的出现时机
- 统计 usage（某些 provider 会在 stream 末尾给出）
- 处理 tool calling（streaming tool deltas）

可以消费 `full_stream`：

```rust
use futures_util::StreamExt;
use ditto_llm::{GenerateRequest, LanguageModelTextExt, Message, OpenAI, StreamChunk};

let (handle, mut full_stream) =
    llm.stream_text(GenerateRequest::from(vec![Message::user("hi")])).await?.into_full_stream();

while let Some(chunk) = full_stream.next().await {
    match chunk? {
        StreamChunk::TextDelta { text } => print!("{text}"),
        StreamChunk::Warnings { warnings } => eprintln!("warnings: {warnings:?}"),
        StreamChunk::Usage(usage) => eprintln!("usage: {usage:?}"),
        StreamChunk::FinishReason(_) => break,
        _ => {}
    }
}

let _final = handle.final_summary()?;
```

## 取消与资源释放

- **默认行为**：丢弃/Drop `StreamTextResult` 或其中任一 stream，会触发内部 task abort（通过 `AbortOnDrop`）。
- **显式 abort**：如果你想拿到一个可调用的 handle，请使用 `abortable_stream` 包装底层 `llm.stream(...)`（见 README 的 “Streaming Cancellation”）。

## 注意：有界 fan-out 与背压

`stream_text` 内部使用**有界** `mpsc::channel` fan-out 到 `text_stream` / `full_stream`，避免“未消费的 stream 导致无界缓冲”的 OOM 风险。

含义：

- 建议使用 `into_text_stream()` / `into_full_stream()` / `into_streams()` 明确你要消费哪条/哪些 stream（只启用被消费的 fan-out）。
- 如果你启用了两条 stream（`into_streams()`），请确保两者都被持续消费（例如分别 `tokio::spawn`），否则慢的一侧会通过有界缓冲对上游施加 backpressure（表现为吞吐降低/等待），而不是内存持续增长。
- 只想拿最终 `GenerateResponse` 时，优先用 `collect_stream()` / `generate_text()`。
- `final_text()` / `final_summary()` 依赖内部 `StreamCollector` 聚合；当输出异常巨大时，聚合器可能触发体积上限并发出 `Warning`，最终聚合结果会被截断（但流式输出仍按实际返回继续产出）。

================================================================================
FILE: docs/src/sdk/structured-outputs.md
================================================================================

# 结构化输出：generate_object_json

Ditto 的结构化输出对标 AI SDK 的 `generateObject` / `streamObject`，但把“不同 provider 的能力差异”显式暴露出来。

核心 API 来自 `LanguageModelObjectExt`：

- `generate_object_json(request, schema) -> GenerateObjectResponse<Value>`
- `generate_object<T>(request, schema) -> GenerateObjectResponse<T>`
- `stream_object(request, schema) -> StreamObjectResult`
- `stream_object_with(request, schema, options) -> StreamObjectResult`

## 最小示例：生成 JSON object

```rust
use ditto_llm::{GenerateRequest, JsonSchemaFormat, LanguageModelObjectExt, Message};
use serde_json::json;

let schema = JsonSchemaFormat {
    name: "recipe".to_string(),
    schema: json!({
        "type": "object",
        "properties": {
            "title": { "type": "string" },
            "steps": { "type": "array", "items": { "type": "string" } }
        },
        "required": ["title", "steps"]
    }),
    strict: None,
};

let out = llm
    .generate_object_json(GenerateRequest::from(vec![Message::user("Give me a recipe.")]), schema)
    .await?;

println!("{}", out.object);
println!("warnings={:?}", out.response.warnings);
```

## Strategy：Ditto 如何让不同 provider“尽量”产出结构化结果

Ditto 通过 `ObjectOptions.strategy` 控制策略（默认 `Auto`）：

- `Auto`（默认）
  - `provider == "openai"` → `NativeSchema`
  - 其他 provider：
    - 若启用了 feature `tools` → `ToolCall`（用工具调用强约束输出）
    - 否则 → `TextJson`（从文本里解析 JSON）
- `NativeSchema`
  - 通过 `ResponseFormat::JsonSchema` 注入到 `provider_options`（native 支持时最稳）
- `ToolCall`
  - 注入一个“内部工具”，让模型通过 tool call 返回 JSON（更可控，但需要 tools 支持）
- `TextJson`
  - 不强约束，只在最后从输出文本里 parse JSON（best-effort，风险最大）

无论哪种策略，Ditto 都可能在必要时回退到文本 JSON 解析，并用 `Warning` 标记发生了降级。

## Object vs Array（AI SDK elementStream 对齐）

`ObjectOptions.output` 决定顶层形状：

- `ObjectOutput::Object`（默认）
- `ObjectOutput::Array`

当你选择 `Array` 时，Ditto 会把 schema 包装为：

```json
{ "type": "array", "items": <your_schema> }
```

并在 streaming 场景提供 `element_stream`（对齐 AI SDK 的 `elementStream`）。

## Streaming：partial objects 与 element stream

```rust
use futures_util::StreamExt;
use ditto_llm::{GenerateRequest, LanguageModelObjectExt, Message};

let (handle, mut partial_object_stream) = llm
    .stream_object(GenerateRequest::from(vec![Message::user("Generate JSON.")]), schema)
    .await?
    .into_partial_stream();

while let Some(partial) = partial_object_stream.next().await {
    println!("partial={}", partial?);
}

let final_json = handle.final_json()?.unwrap();
println!("final={final_json}");
```

Streaming arrays：

```rust
use futures_util::StreamExt;
use ditto_llm::{GenerateRequest, LanguageModelObjectExt, Message, ObjectOptions, ObjectOutput};

let (handle, mut element_stream) = llm
    .stream_object_with(
        GenerateRequest::from(vec![Message::user("List items as JSON array.")]),
        schema, // schema for a single element
        ObjectOptions {
            output: ObjectOutput::Array,
            ..ObjectOptions::default()
        },
    )
    .await?
    .into_element_stream();

while let Some(element) = element_stream.next().await {
    println!("element={}", element?);
}

let _final = handle.final_summary()?;
```

## 建议与坑

- **Schema 越明确越好**：尤其是 `required` 与 `type`，可以显著降低解析失败率。
- **对错误要敏感**：`final_json()` / `final_object()` 只有在 stream 完成后才会返回结果；若解析失败会返回 `DittoError::InvalidResponse(...)`。
- **把 warnings 当成信号**：比如 “fallback to text json parsing” 的 Warning，通常意味着 provider 不支持你期望的能力或模型没遵守约束。
- **超大输出要做容量预期**：Ditto 在部分内部缓冲区设置了体积上限（防止 OOM）；一旦触发会发出 `Warning`，并可能导致最终解析失败或结果被截断。

================================================================================
FILE: docs/src/sdk/tool-calling.md
================================================================================

# 工具调用（Tool Calling）

Ditto 的工具调用是 “AI SDK Core” 常见用法的 Rust 化：把工具描述为 `Tool`（JSON Schema 参数），把模型输出的 tool calls 暴露为 `ContentPart::ToolCall`，由调用方决定是否、以及如何执行工具。

> 重要：Ditto 的默认 helper（`generate_text` / `generate_object_json`）都是单次请求，不会自动执行工具循环。  
> 如果你需要自动 loop（多步工具调用），请看「SDK → Agents（Tool Loop）」：它提供 `ToolLoopAgent`（max_steps / stop_when / approval hook），语义上对标 AI SDK 的 `maxSteps` / `stopWhen`。

## 定义 Tool

`Tool.parameters` 使用 JSON Schema（以 `serde_json::Value` 表示）：

```rust
use ditto_llm::Tool;
use serde_json::json;

let tools = vec![Tool {
    name: "add".to_string(),
    description: Some("Add two integers.".to_string()),
    parameters: json!({
        "type": "object",
        "properties": {
            "a": { "type": "integer" },
            "b": { "type": "integer" }
        },
        "required": ["a", "b"]
    }),
    strict: Some(true),
}];
```

## 发起带 tools 的请求

```rust
use ditto_llm::{ContentPart, GenerateRequest, LanguageModel, Message, ToolChoice};

let request = GenerateRequest {
    messages: vec![
        Message::system("You are a helpful assistant. Use tools when appropriate."),
        Message::user("Compute 40 + 2 using the add tool."),
    ],
    tools: Some(tools),
    tool_choice: Some(ToolChoice::Required),
    ..GenerateRequest::from(Vec::new())
};

let response = llm.generate(request).await?;

for part in &response.content {
    if let ContentPart::ToolCall { id, name, arguments } = part {
        eprintln!("tool_call id={id} name={name} args={arguments}");
    }
}
```

### ToolChoice 的含义

- `Auto`：模型自行决定是否调用工具
- `None`：禁止工具调用（即使你提供了 tools）
- `Required`：强制模型必须调用工具（常用于 “tool-call enforced JSON”）
- `Tool { name }`：强制调用某个工具

不同 provider 对 `tool_choice` 的支持程度可能不同；不支持时 Ditto 会尽量降级并给出 `Warning`。

## 手写一个最小 Tool Loop（两轮）

典型流程是：

1) 发送请求（带 tools）  
2) 从模型输出中提取 tool calls  
3) 执行工具，产出 `Message::tool_result(...)`  
4) 再发一次请求（把 tool call 与 tool result 作为上下文交给模型）  

参考 `examples/tool_calling.rs`，一个最小可跑的两轮 loop 形如：

```rust
use ditto_llm::{ContentPart, GenerateRequest, LanguageModel, Message};
use serde_json::json;

fn add(arguments: &serde_json::Value) -> serde_json::Value {
    let a = arguments.get("a").and_then(|v| v.as_i64()).unwrap_or(0);
    let b = arguments.get("b").and_then(|v| v.as_i64()).unwrap_or(0);
    json!({ "result": a + b })
}

let response = llm.generate(request).await?;

let mut followup = vec![
    Message::system("You are a helpful assistant."),
    Message::user("Compute 40 + 2 using the add tool."),
];

for part in &response.content {
    if let ContentPart::ToolCall { id, name, arguments } = part {
        let output = match name.as_str() {
            "add" => add(arguments),
            _ => json!({ "error": "unknown tool" }),
        };

        followup.push(Message {
            role: ditto_llm::Role::Assistant,
            content: vec![ContentPart::ToolCall {
                id: id.clone(),
                name: name.clone(),
                arguments: arguments.clone(),
            }],
        });
        followup.push(Message::tool_result(id.clone(), output.to_string()));
    }
}

let response = llm.generate(followup.into()).await?;
println!("{}", response.text());
```

## Streaming 场景的工具调用

在 streaming 时，工具调用可能以增量形式出现：

- `StreamChunk::ToolCallStart { id, name }`
- `StreamChunk::ToolCallDelta { id, arguments_delta }`

如果你需要在 streaming 中实时执行工具，需要自行维护一个 “tool call buffer” 做增量拼接。

（提示：`StreamCollector` 在收集模式下已经实现了拼接，但它会把所有内容累计到最终响应，适合“先收集、后执行”的场景。）

## 安全建议（强烈建议阅读）

工具调用是高风险边界：模型输出的参数本质是不可信输入。

最低限度建议：

- 对工具参数做 schema 校验与长度限制（尤其是字符串）
- 对危险工具做 allowlist（shell / filesystem / network）
- 在服务端做权限隔离（root 限制、只读模式、超时、并发上限）

Ditto 的 `agent` feature 提供了一套 “可控工具执行器” 参考实现（例如 `safe-fs-tools`），但默认不启用。

================================================================================
FILE: docs/src/sdk/agents.md
================================================================================

# Agents（Tool Loop）

本页对标 AI SDK 的 “Agents / tool calling loop” 思路：当你需要 **多步工具调用**（而不仅是一次 tool call），Ditto 提供一个可选的、可控的工具循环实现：`ToolLoopAgent`（feature `agent`）。

> 默认的 `generate_text` / `generate_object_json` / `generate` 都是“单次请求”：不会自动执行工具、不会自动循环。

实现位置：`src/agent/tool_loop.rs`、`src/agent/types.rs`、`src/agent/toolbox/*`。

---

## 1) 何时应该用 Tool Loop？

适合：

- 你希望模型可以“调用工具 → 看到结果 → 再决定下一步”（最多 N 步）
- 你希望有明确的 `max_steps` 与 `stop_when`（对标 AI SDK 的 `maxSteps` / `stopWhen`）
- 你希望在执行危险工具前做审批/拦截

不适合：

- 你只想要一次工具调用（直接用「工具调用（Tool Calling）」页里手写两轮示例即可）
- 你把工具暴露给不可信输入但又没有隔离/审批（这是安全事故高发区）

---

## 2) 最小示例：max_steps + stop_when

启用 features：

- `agent`（会带上一个参考工具箱执行器：基于 `safe-fs-tools` 的文件系统工具、受控 shell 执行等；需要在仓库同级目录存在 `safe-fs-tools` checkout（`../safe-fs-tools`））

示例（伪代码风格，展示结构）：

```rust
use ditto_llm::{
    agent::{ToolLoopAgent, ToolboxExecutor},
    Message, OpenAI,
};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("OPENAI_API_KEY").map_err(|_| {
        ditto_llm::DittoError::InvalidResponse("missing OPENAI_API_KEY".into())
    })?;
    let llm = OpenAI::new(api_key).with_model("gpt-4o-mini");

    // 只允许在某个 root 下读写文件（建议给临时目录/工作区，而不是整个磁盘）
    let executor = ToolboxExecutor::new("./sandbox")?;

    let agent = ToolLoopAgent::new(llm, executor)
        .with_max_steps(8)
        .with_stop_when(|state| {
            // 例：如果模型已经给出最终文本（没有 tool calls），就停止
            state.last_tool_calls.is_empty()
        });

    let req = vec![
        Message::system("You are a helpful assistant. Use tools when needed."),
        Message::user("Read ./sandbox/input.txt and summarize it."),
    ]
    .into();

    let outcome = agent.run(req).await?;
    println!("stop_reason={:?}", outcome.stop_reason);
    println!("final_text={}", outcome.final_response.text());
    Ok(())
}
```

---

## 3) 审批/拦截：with_approval

Tool loop 默认会“批准所有工具调用”。生产中强烈建议加审批钩子：

- allowlist 工具名
- 对参数做长度/路径约束
- 对高风险工具（shell / http_fetch / 写文件）加人工或策略审批

`with_approval` 允许你针对每个 `ToolCall` 做决策：

- `Approve`
- `Deny { reason }`
- `Result(result)`（直接注入工具结果，不执行实际工具）

---

## 4) 安全边界（强烈建议）

如果你要把 tool loop 用在服务端：

- **隔离 root**：文件系统工具必须限定在工作目录（不要给 `/`）。
- **禁用或收紧 shell**：只允许少量白名单 program，限制 cwd/timeout。
- **限制网络**：`http_fetch` 需要域名 allowlist + 响应大小上限。
- **审计与脱敏**：日志里不要记录敏感文件内容与 token。

> “工具调用 = 执行不可信输入” 这件事本质上比 LLM 本身更危险；Ditto 只是提供可控的骨架，不替你做安全兜底。

下一步：

- 「工具调用（Tool Calling）」：工具 schema 与单次调用的基础形状
- 「SDK → 错误处理」：如何在 loop 中处理失败/超时/降级

================================================================================
FILE: docs/src/sdk/middleware.md
================================================================================

# Language Model Middleware（Layer）

AI SDK 的一个核心能力是“中间件/钩子”式的可组合扩展。Ditto-LLM 在 Rust 里提供等价的抽象：`LanguageModelLayer`（以及 `LayeredLanguageModel`）。

实现位置：`src/layer.rs`。

---

## 1) 什么时候用 Layer？

适合放进 Layer 的逻辑（横切关注点）：

- 统一日志 / 指标 / tracing
- 请求参数规范化（例如：限制 max_tokens、追加 system prompt）
- 失败重试（注意 streaming 的语义）
- 路由/多模型 fallback（如果你在 SDK 侧做，而不是 Gateway）

不建议放进 Layer：

- 业务强相关的 prompt 组装（更适合在调用方做）
- tool loop（推荐用 `ToolLoopAgent` 或显式循环）

---

## 2) 最小示例：记录 warnings

```rust
use async_trait::async_trait;
use ditto_llm::{LanguageModel, LanguageModelLayer, GenerateRequest, GenerateResponse, StreamResult};

struct WarningLoggerLayer;

#[async_trait]
impl LanguageModelLayer for WarningLoggerLayer {
    async fn generate(
        &self,
        inner: &dyn LanguageModel,
        request: GenerateRequest,
    ) -> ditto_llm::Result<GenerateResponse> {
        let resp = inner.generate(request).await?;
        if !resp.warnings.is_empty() {
            eprintln!("warnings: {:?}", resp.warnings);
        }
        Ok(resp)
    }

    async fn stream(
        &self,
        inner: &dyn LanguageModel,
        request: GenerateRequest,
    ) -> ditto_llm::Result<StreamResult> {
        inner.stream(request).await
    }
}
```

使用方式：

```rust
use ditto_llm::{LanguageModelLayerExt, OpenAI};

let api_key = std::env::var("OPENAI_API_KEY")
    .map_err(|_| ditto_llm::DittoError::InvalidResponse("missing OPENAI_API_KEY".into()))?;
let llm = OpenAI::new(api_key)
    .with_model("gpt-4o-mini")
    .layer(WarningLoggerLayer);
```

---

## 3) 组合多层 Layer

`LayeredLanguageModel::with_layer` 支持链式叠加：

```rust
let llm = base.layer(L1).with_layer(L2).with_layer(L3);
```

顺序建议：

- 最外层：观测/日志（确保覆盖所有后续行为）
- 中间层：参数规范化/策略
- 最内层：provider client（OpenAI/Anthropic/...）

---

## 4) 内置：缓存 Layer（含流式回放）

Ditto 提供一个轻量的 `CacheLayer`（feature `sdk`）：用于缓存 `generate()` 的响应，以及缓存 `stream()` 的 chunk 序列并在命中时回放（replay）。

```rust
use std::time::Duration;

use ditto_llm::{CacheLayer, LanguageModelLayerExt, OpenAI};

let llm = OpenAI::new(std::env::var("OPENAI_API_KEY")?)
    .with_model("gpt-4o-mini")
    .layer(CacheLayer::new().with_ttl(Duration::from_secs(60)));
```

默认策略：

- 只做进程内缓存（不会落盘/跨进程共享）
- 命中时不会再次调用 provider
- 对单条缓存设置体积上限与 streaming chunk 上限（超过上限会跳过缓存，避免无界内存增长）

================================================================================
FILE: docs/src/sdk/stream-protocol-v1.md
================================================================================

# Stream Protocol v1（NDJSON / SSE）

Ditto 的底层 streaming 统一输出为 `StreamChunk` 序列（见「核心概念 → Streaming」）。

如果你需要把 Ditto 的 streaming 接入你自己的 HTTP 服务（而不是直接用 Gateway 的 `/v1/*` passthrough），`sdk` feature 提供了一个很轻量的“线协议”：**stream protocol v1**。

实现位置：

- 协议：`src/sdk/protocol.rs`（`StreamEventV1` / `encode_v1` / `decode_v1`）
- HTTP 编码：`src/sdk/http/stream_v1.rs`（NDJSON / SSE）

---

## 1) 事件模型：StreamEventV1

每个 event 都会被包裹在一个 envelope 里：

```json
{ "v": 1, "type": "chunk", "data": { "...StreamChunk..." } }
```

事件类型：

- `chunk`：一个 `StreamChunk`
- `error`：`{ "message": "..." }`
- `done`：流结束（Ditto 保证一定会发）

---

## 2) 两种 HTTP 输出格式

Ditto 提供两种等价但适配不同生态的输出：

### 2.1 NDJSON（`<json>\n`）

- 每行一个 JSON（`encode_line_v1`）
- 适合 CLI、日志管道、部分 Web 框架的 streaming response

入口函数：

- `ditto_llm::sdk::http::stream_v1_ndjson(stream)`

### 2.2 SSE（`data: <json>\n\n`）

- 每个 event 是一条 SSE `data:`（payload 仍是 stream protocol v1 JSON）
- 适合浏览器 EventSource、以及更接近 OpenAI 的 streaming 体验

入口函数：

- `ditto_llm::sdk::http::stream_v1_sse(stream)`

---

## 3) 错误语义（重要）

如果底层 `StreamResult` 产生 `Err(DittoError)`：

- 先发 `error`
- 再发 `done`
- 然后结束

这比“直接断流”更利于客户端做可观测的错误处理。

---

## 4) 什么时候该用它？

- 你在自建 HTTP API（非 OpenAI-compatible）但希望统一流式协议
- 你需要在网关之外把 `StreamChunk` 安全地传到另一个服务/进程

如果你只需要 OpenAI-compatible `/v1/*`，优先用 Gateway（它直接 passthrough upstream 的 SSE）。

---

## 5) JS/TS client（最小实现）

仓库内提供一个最小 JS/TS client（以及 React hook），用于在浏览器/Node 侧消费 stream protocol v1：

- `packages/ditto-client`：`streamV1FromSseResponse` / `streamV1FromNdjsonResponse`
- `packages/ditto-react`：`useStreamV1`（把 stream protocol v1 映射成 React state）

它们不追求 1:1 复刻 AI SDK UI，只提供“能用、易嵌入、易排障”的最小 DX。

---

## 6) AI SDK UI Message Stream（可选）

如果你希望直接对接 Vercel AI SDK UI（例如 `@ai-sdk/react` 的 `useChat`），你需要输出 **UI Message Stream** 的 SSE 协议（与 Ditto 的 stream protocol v1 不同）。

Ditto 提供一个最小适配器（feature `sdk`）：

- `ditto_llm::sdk::http::ui_message_stream_v1_sse(stream)`：把 Ditto `StreamResult` 转为 UI Message Stream SSE（末尾以 `data: [DONE]` 结束）

输出中会包含基础的 step 边界事件（`start-step` / `finish-step`），并在 Ditto 侧额外附带一些 `data-ditto-*` 的诊断事件（例如 usage/warnings；客户端可忽略）。

HTTP 响应侧需要额外设置：

- `x-vercel-ai-ui-message-stream: v1`
- 推荐同时设置其它常用 SSE headers（`content-type` / `cache-control` / `connection` / `x-accel-buffering`），Ditto 提供了一个常量便于复用：`ditto_llm::sdk::http::UI_MESSAGE_STREAM_V1_HEADERS`

如果你使用的是 `axum`：

- 开启 `--features sdk-axum`（或已开启 `--features gateway`）后，可以直接用 `ditto_llm::sdk::http::ui_message_stream_v1_sse_response(stream)` 生成带 headers 的 streaming response。

================================================================================
FILE: docs/src/sdk/embeddings.md
================================================================================

# Embeddings

Ditto 通过 `EmbeddingModel` trait 统一 embeddings 调用，并提供 `EmbeddingModelExt` 作为 AI SDK 风格别名：

- `embed_many(texts)` → `embed(texts)`
- `embed_one(text)` → `embed_single(text)`

## 最小示例

```rust
use ditto_llm::EmbeddingModelExt;

let vectors = embeddings
    .embed_many(vec!["hello".to_string(), "world".to_string()])
    .await?;

let one = embeddings.embed_one("hi".to_string()).await?;
println!("n_vectors={} dim={}", vectors.len(), one.len());
```

## 如何构建 embeddings client

不同 provider 的 embeddings client 是 feature-gated 的：

- OpenAI：`OpenAIEmbeddings`（features: `openai` + `embeddings`）
- OpenAI-compatible：`OpenAICompatibleEmbeddings`（features: `openai-compatible` + `embeddings`）
- Google：`GoogleEmbeddings`（features: `google` + `embeddings`）
- Cohere：`CohereEmbeddings`（features: `cohere` + `embeddings`）

这些类型通常支持：

- `::new(api_key)`（或对应的 provider auth）
- `with_model(...)` / `with_base_url(...)`（不同实现略有差异）
- `::from_config(&ProviderConfig, &Env)`（当你希望统一配置管理）

建议在工程里用 `ProviderConfig` 做统一管理，避免把 base_url/token scattered 到代码里。

## 常见坑

- **向量维度与模型绑定**：维度不是 Ditto 决定的，取决于 provider 与 model。
- **大批量输入**：一次塞太多文本可能触发 provider 的 size limit 或导致较长延迟；建议你在上层做分批。
- **成本与 token 计数**：embeddings 的计费与 tokenization provider 相关；若你在 Gateway 场景要做成本控制，请配合 `gateway-costing` / `gateway-tokenizer`。

================================================================================
FILE: docs/src/sdk/images.md
================================================================================

# Images

Ditto 通过 `ImageGenerationModel` trait 提供统一的图片生成接口（对齐 OpenAI `/images/generations` 的核心形状）。

## 请求/响应类型

- `ImageGenerationRequest`：`prompt` + 可选 `model`/`n`/`size`/`response_format`
- `ImageGenerationResponse`：`images: Vec<ImageSource>`（URL 或 Base64）

## 最小示例

```rust
use ditto_llm::{ImageGenerationRequest, ImageResponseFormat, OpenAIImages};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("OPENAI_API_KEY").map_err(|_| {
        ditto_llm::DittoError::InvalidResponse("missing OPENAI_API_KEY".into())
    })?;
    let images = OpenAIImages::new(api_key).with_model("gpt-image-1");

    let resp = images
        .generate(ImageGenerationRequest {
            prompt: "A minimal flat icon of a rust crab.".to_string(),
            model: None,
            n: Some(1),
            size: Some("1024x1024".to_string()),
            response_format: Some(ImageResponseFormat::Url),
            provider_options: None,
        })
        .await?;

    println!("images={:?}", resp.images);
    println!("warnings={:?}", resp.warnings);
    Ok(())
}
```

> 注意：`OpenAIImages` 需要开启 features `openai` + `images`；OpenAI-compatible 也有对应的 images client（见 crate re-exports）。

## 常见坑

- **返回格式**：`response_format` 选择 `Url` 或 `Base64Json`；不同 provider/网关可能只支持其一。
- **size 的约束**：size 的合法值通常由 provider 决定，Ditto 仅做 best-effort 透传。
- **成本与带宽**：Base64 会显著增大 payload；生产建议优先使用 URL 或把图片落到对象存储。

================================================================================
FILE: docs/src/sdk/audio.md
================================================================================

# Audio（transcriptions / speech）

Ditto 提供两类音频能力（feature `audio`）：

- **Transcriptions / Translations**：语音转文字（对齐 OpenAI `/audio/transcriptions` 与 `/audio/translations`）
- **Speech**：文字转语音（对齐 OpenAI `/audio/speech`）

## 需要的 features

- OpenAI：`openai` + `audio`
- OpenAI-compatible：`openai-compatible` + `audio`

对应的 client（crate re-exports）：

- `OpenAIAudioTranscription` / `OpenAISpeech`
- `OpenAICompatibleAudioTranscription` / `OpenAICompatibleSpeech`

## Transcriptions：最小示例

```rust
use ditto_llm::{AudioTranscriptionRequest, OpenAIAudioTranscription, TranscriptionResponseFormat};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("OPENAI_API_KEY").map_err(|_| {
        ditto_llm::DittoError::InvalidResponse("missing OPENAI_API_KEY".into())
    })?;
    let model = OpenAIAudioTranscription::new(api_key).with_model("whisper-1");

    let resp = model
        .transcribe(AudioTranscriptionRequest {
            audio: std::fs::read("audio.wav")?,
            filename: "audio.wav".to_string(),
            media_type: Some("audio/wav".to_string()),
            model: None, // 也可以在这里覆盖
            language: None,
            prompt: None,
            response_format: Some(TranscriptionResponseFormat::Json),
            temperature: None,
            provider_options: None,
        })
        .await?;

    println!("{}", resp.text);
    Ok(())
}
```

## Speech：最小示例

```rust
use ditto_llm::{OpenAISpeech, SpeechRequest, SpeechResponseFormat};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("OPENAI_API_KEY").map_err(|_| {
        ditto_llm::DittoError::InvalidResponse("missing OPENAI_API_KEY".into())
    })?;
    let tts = OpenAISpeech::new(api_key).with_model("gpt-4o-mini-tts");

    let resp = tts
        .speak(SpeechRequest {
            input: "Hello from Ditto.".to_string(),
            voice: "alloy".to_string(),
            model: None,
            response_format: Some(SpeechResponseFormat::Mp3),
            speed: Some(1.0),
            provider_options: None,
        })
        .await?;

    std::fs::write("out.mp3", resp.audio)?;
    Ok(())
}
```

## 内存与性能注意事项

当前音频 API 以 `Vec<u8>` 形式读入/返回音频内容：

- 请求：`AudioTranscriptionRequest.audio: Vec<u8>`
- 响应：`SpeechResponse.audio: Vec<u8>`

这意味着大文件会带来较高的内存峰值。若你在网关/高并发服务中使用，建议：

- 对上传大小做限制（例如反向代理层或业务层）
- 将音频落盘或对象存储，再传 URL（若 provider 支持）
- 避免在日志里记录音频内容，务必脱敏

================================================================================
FILE: docs/src/sdk/files.md
================================================================================

# Files（upload / list / download）

Ditto 提供一个轻量的 `FileClient` trait，用于对齐 OpenAI/OpenAI-compatible 的 `/v1/files` 能力。

## 能力范围

当前 `FileClient` 覆盖：

- upload：`upload_file_with_purpose`
- list：`list_files`
- retrieve：`retrieve_file`
- delete：`delete_file`
- download content：`download_file_content`

对应的类型：

- `FileUploadRequest`
- `FileObject`
- `FileDeleteResponse`
- `FileContent`

## 最小示例：上传并下载

```rust
use ditto_llm::{FileClient, FileUploadRequest, OpenAI};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("OPENAI_API_KEY").map_err(|_| {
        ditto_llm::DittoError::InvalidResponse("missing OPENAI_API_KEY".into())
    })?;
    let client = OpenAI::new(api_key);

    let file_id = client
        .upload_file_with_purpose(FileUploadRequest {
            filename: "hello.txt".to_string(),
            bytes: b"hello".to_vec(),
            purpose: "assistants".to_string(),
            media_type: Some("text/plain".to_string()),
        })
        .await?;

    let obj = client.retrieve_file(&file_id).await?;
    println!("uploaded: id={} bytes={}", obj.id, obj.bytes);

    let content = client.download_file_content(&file_id).await?;
    println!("downloaded: {} bytes", content.bytes.len());
    Ok(())
}
```

## 目的字段（purpose）

OpenAI 的 files API 会要求一个 `purpose` 字段（例如 `assistants`）。Ditto 不对这个字段做强约束，按 provider 的要求透传。

## 内存注意事项

`download_file_content` 会把文件内容一次性读入 `Vec<u8>`。

如果你可能下载大文件，建议：

- 在业务层限制文件大小
- 或者扩展一层“流式下载到文件/Writer”的封装（避免一次性缓冲）

================================================================================
FILE: docs/src/sdk/batches.md
================================================================================

# Batches

Ditto 提供 `BatchClient` trait 对齐 OpenAI/OpenAI-compatible 的 `/v1/batches` 能力（feature `batches`）。

Batch 适合把大量请求离线提交给 provider，由 provider 异步执行并产出输出文件。

## 需要的 features

- OpenAI：`openai` + `batches`
- OpenAI-compatible：`openai-compatible` + `batches`

对应的 client（crate re-exports）：

- `OpenAIBatches`
- `OpenAICompatibleBatches`

## 最小示例：上传 JSONL 并创建 batch

参考 `examples/batches.rs`，核心步骤是：

1) 读取 `requests.jsonl`  
2) 通过 files API 上传（`purpose = "batch"`，`media_type = "application/jsonl"`）  
3) 创建 batch（指定 endpoint 与 completion window）  

```rust
use ditto_llm::{BatchClient, BatchCreateRequest, OpenAICompatible, OpenAICompatibleBatches};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("OPENAI_COMPAT_API_KEY")
        .or_else(|_| std::env::var("OPENAI_API_KEY"))
        .map_err(|_| {
            ditto_llm::DittoError::InvalidResponse(
                "missing OPENAI_COMPAT_API_KEY (or fallback OPENAI_API_KEY)".into(),
            )
        })?;

    let base_url = std::env::var("OPENAI_COMPAT_BASE_URL")
        .or_else(|_| std::env::var("OPENAI_BASE_URL"))
        .unwrap_or_else(|_| "https://api.openai.com/v1".to_string());

    let bytes = std::fs::read("requests.jsonl")?;

    let uploader = OpenAICompatible::new(api_key.clone()).with_base_url(base_url.clone());
    let input_file_id = uploader
        .upload_file_with_purpose(
            "requests.jsonl",
            bytes,
            "batch",
            Some("application/jsonl"),
        )
        .await?;

    let batches = OpenAICompatibleBatches::new(api_key).with_base_url(base_url);
    let resp = batches
        .create(BatchCreateRequest {
            input_file_id,
            endpoint: "/v1/chat/completions".to_string(),
            completion_window: "24h".to_string(),
            metadata: None,
            provider_options: None,
        })
        .await?;

    println!("batch_id={} status={:?}", resp.batch.id, resp.batch.status);
    Ok(())
}
```

## 常用操作

- 查询：`retrieve(batch_id)`
- 取消：`cancel(batch_id)`
- 列表：`list(limit, after)`

## provider_options

`BatchCreateRequest.provider_options` 支持与 `GenerateRequest.provider_options` 类似的“按 provider bucket”结构，用于传递特定 provider 的额外字段（不会被 Ditto 强类型化）。

建议：

- 只对你明确理解的字段使用 `provider_options`
- 并在审计日志/观测里记录（注意脱敏）

================================================================================
FILE: docs/src/sdk/rerank.md
================================================================================

# Rerank

Rerank 用于对候选文档/段落按相关性重新排序，常见于 RAG 管线的“重排”阶段。

Ditto 通过 `RerankModel` trait 统一接口，目前主要实现为 Cohere Rerank（feature `cohere` + `rerank`）。

## 最小示例（Cohere）

```rust
use ditto_llm::{CohereRerank, RerankDocument, RerankRequest};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("COHERE_API_KEY").map_err(|_| {
        ditto_llm::DittoError::InvalidResponse("missing COHERE_API_KEY".into())
    })?;
    let rerank = CohereRerank::new(api_key).with_model("rerank-english-v3.0");

    let resp = rerank
        .rerank(RerankRequest {
            query: "best rust async runtime".to_string(),
            documents: vec![
                RerankDocument::Text("Tokio is widely used.".to_string()),
                RerankDocument::Text("Rayon is for data parallelism.".to_string()),
            ],
            model: None,
            top_n: Some(2),
            provider_options: None,
        })
        .await?;

    for r in resp.ranking {
        println!("idx={} score={}", r.index, r.relevance_score);
    }
    Ok(())
}
```

## provider_options（Cohere）

在 Cohere rerank 中，`provider_options` 支持（按 `cohere` bucket）：

- `max_tokens_per_doc`
- `priority`

这些字段是 Cohere 特有的，不会被 Ditto 强类型化；传错字段可能会得到 `DittoError::InvalidResponse(...)`。

## 常见坑

- **documents 类型**：Ditto 的 `RerankDocument` 支持 `Text` 或 `Json`；Cohere 侧会把 object document 转成字符串，并产生 `Warning`（避免 silent coercion）。
- **top_n**：如果不填，provider 可能返回全部排序结果；生产建议显式限制，避免大结果集带来的成本与延迟。

================================================================================
FILE: docs/src/sdk/moderations.md
================================================================================

# Moderations

Ditto 通过 `ModerationModel` trait 对齐 OpenAI/OpenAI-compatible 的 `/v1/moderations` 能力（feature `moderations`）。

## 需要的 features

- OpenAI：`openai` + `moderations`
- OpenAI-compatible：`openai-compatible` + `moderations`

对应的 client（crate re-exports）：

- `OpenAIModerations`
- `OpenAICompatibleModerations`

## 最小示例

```rust
use ditto_llm::{ModerationInput, ModerationModel, ModerationRequest, OpenAIModerations};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("OPENAI_API_KEY").map_err(|_| {
        ditto_llm::DittoError::InvalidResponse("missing OPENAI_API_KEY".into())
    })?;
    let client = OpenAIModerations::new(api_key).with_model("omni-moderation-latest");

    let resp = client
        .moderate(ModerationRequest {
            input: ModerationInput::Text("hi".to_string()),
            model: None,
            provider_options: None,
        })
        .await?;

    println!("results={:?}", resp.results);
    println!("warnings={:?}", resp.warnings);
    Ok(())
}
```

## 输入类型（ModerationInput）

`ModerationInput` 支持三种形态：

- `Text(String)`
- `TextArray(Vec<String>)`
- `Raw(serde_json::Value)`（当你需要传 provider 特有结构）

## 常见坑

- **模型选择**：moderations 通常有独立模型（例如 OpenAI 的 `omni-moderation-latest`）。你可以通过 `with_model(...)` 设置默认，也可以通过 `ModerationRequest.model` 覆盖。
- **provider_options**：仅在你明确知道 provider 支持的字段时使用；传错字段可能导致请求失败或产生 Warning。

================================================================================
FILE: docs/src/sdk/provider-config.md
================================================================================

# ProviderConfig 与 Profile

Ditto 通过 `ProviderConfig` + `Env` 把“连接 provider 所需的所有信息”集中管理，避免：

- base_url/token scattered 在代码里
- 不同模块各自拼 headers/query/auth，导致行为不一致
- Gateway 与 SDK 使用两套配置结构

在 Ditto 中，“Profile”是指围绕 provider 的配置、能力与模型发现的一组工具（位于 `src/profile`）。

## ProviderConfig：字段说明

`ProviderConfig` 是一个可序列化/反序列化的结构（可用于 JSON/TOML/YAML 等），核心字段：

- `base_url: Option<String>`
  - OpenAI-compatible upstream 的根地址（通常以 `/v1` 结尾）
  - 在 OpenAI 原生场景可以不填（使用默认 `https://api.openai.com/v1`）
- `default_model: Option<String>`
  - 默认模型 id；请求里 `GenerateRequest.model` 会优先覆盖它
- `model_whitelist: Vec<String>`
  - 用于模型发现（`/v1/models`）的 allowlist（为空表示不过滤）
- `http_headers: BTreeMap<String, String>`
  - 每个请求默认附加的 header（适合注入企业网关需要的自定义 header）
- `http_query_params: BTreeMap<String, String>`
  - 每个请求默认附加的 query params（例如 Azure 的 `api-version`）
- `auth: Option<ProviderAuth>`
  - provider 鉴权策略（env/command/header/query/sigv4/oauth 等）
- `capabilities: Option<ProviderCapabilities>`
  - provider 能力声明（用于路由/模型发现/策略判断；不等同于“硬保证”）

> 在 Gateway 配置里，backend 的 `provider_config` 字段就是同一份 `ProviderConfig` 结构。

## Env：统一 env 与 dotenv

`Env` 是一个很小的抽象：

- 先从 `Env.dotenv`（进程内注入的 dotenv map）查 key
- 再回退到 `std::env::var`

用途：

- 在 SDK 场景：你可以把 dotenv 内容作为字符串解析后注入，避免测试依赖真实环境变量
- 在 Gateway 场景：`--dotenv` 会把文件加载进 `Env`，同时也用于 `${ENV_VAR}` 占位符展开

## ProviderAuth：常见鉴权方式

Ditto 支持多种鉴权方式，覆盖企业网关的常见形态。

### 1) API key from env（最常见）

```json
{
  "auth": { "type": "api_key_env", "keys": ["OPENAI_API_KEY"] }
}
```

你可以把 env 的值设置为 `secret://...`，让 Ditto 在运行时解析（Vault/AWS/GCP/Azure/file/env）：

- `OPENAI_API_KEY=secret://env/REAL_OPENAI_API_KEY`
- `OPENAI_API_KEY=secret://file?path=/run/secrets/openai_api_key`
- `OPENAI_API_KEY=secret://vault/secret/openai?field=api_key`

### 2) 自定义 header（例如 `api-key`）

```json
{
  "auth": {
    "type": "http_header_env",
    "header": "api-key",
    "keys": ["AZURE_OPENAI_API_KEY"],
    "prefix": null
  }
}
```

### 3) query param 鉴权（某些网关）

```json
{
  "auth": {
    "type": "query_param_env",
    "param": "api_key",
    "keys": ["GATEWAY_API_KEY"],
    "prefix": null
  }
}
```

### 4) Command 鉴权（从外部命令取 token）

适合与 `aws-vault`、`gcloud auth print-access-token`、Vault CLI 等集成：

```json
{
  "auth": { "type": "command", "command": ["bash", "-lc", "security find-generic-password ..."] }
}
```

约定：

- command 的 stdout 支持：
  - **纯文本 token**（推荐）
  - **JSON string**：`"sk-..."`
  - **JSON object**：`{"api_key":"..."}` / `{"token":"..."}` / `{"access_token":"..."}`
- Ditto 会对 stdout 做 `trim()`，并在执行时应用安全边界：
  - 超时：默认 15s，可通过 `DITTO_AUTH_COMMAND_TIMEOUT_MS/SECS` 调整
  - 输出上限：stdout/stderr 各 64KiB（超过则报错）

### 5) SigV4 / OAuth client credentials

用于 Bedrock（SigV4）与 Vertex（OAuth client credentials）等场景。字段较多，建议结合你组织的密钥管理方案统一下发。

#### SigV4（Bedrock / 自建 SigV4 网关）

```json
{
  "auth": {
    "type": "sigv4",
    "access_keys": ["AWS_ACCESS_KEY_ID"],
    "secret_keys": ["AWS_SECRET_ACCESS_KEY"],
    "session_token_keys": ["AWS_SESSION_TOKEN"],
    "region": "us-east-1",
    "service": "bedrock"
  }
}
```

> `access_keys/secret_keys/session_token_keys` 是 env key 列表（按顺序尝试）；如果你只用静态 AK/SK，可以只填前两项。

#### OAuth client credentials（Vertex / 企业 OAuth 网关）

```json
{
  "auth": {
    "type": "oauth_client_credentials",
    "token_url": "https://example.com/oauth/token",
    "client_id_keys": ["OAUTH_CLIENT_ID"],
    "client_secret_keys": ["OAUTH_CLIENT_SECRET"],
    "scope": "https://www.googleapis.com/auth/cloud-platform",
    "audience": null,
    "extra_params": {}
  }
}
```

> `client_id` / `client_secret` 字段也可以直接写死在配置里，但生产环境强烈不建议（用 env/secret 管理更安全）。

## ProviderOptions：请求级的 provider 特有字段

除了 `ProviderConfig` 的“连接/默认配置”外，Ditto 还提供 `GenerateRequest.provider_options` 用于请求级覆盖。

`ProviderOptions`（强类型）目前聚焦 OpenAI Responses 常见能力：

- `reasoning_effort`
- `response_format`（JSON schema）
- `parallel_tool_calls`

同时也允许传任意 JSON（弱类型）用于 provider 特有字段。

### Bucketed provider_options（按 provider 分桶）

你可以把 provider_options 写成一个对象，按 provider 名称分桶：

```json
{
  "*": { "parallel_tool_calls": true },
  "openai": { "reasoning_effort": "medium" },
  "openai-compatible": { "parallel_tool_calls": false }
}
```

Ditto 会在请求时按 `provider` 选择合适 bucket，并做合并（`*` + provider-specific）。

## 模型发现（/v1/models）

对于 OpenAI-compatible upstream，Ditto 提供：

- `list_available_models(&ProviderConfig, &Env)`：直接拉取并返回 `Vec<String>`
- `OpenAiModelsProvider`：实现 `Provider` trait，可作为“模型列表提供者”注入到路由系统

这部分常用于：

- 网关路由：按模型列表自动分配 backend
- 配置校验：启动时验证 default_model 是否存在

## 安全建议

- 不要把 token 写进配置文件，优先使用 env / `--dotenv` / command / KMS/Vault。
- 对 `auth.command` 要做 allowlist 与超时，避免被滥用。
- 将 `http_headers`/`http_query_params` 视为敏感面：不要允许非可信请求覆盖这些字段（Gateway 已默认避免把 client auth 头透传到 upstream）。

================================================================================
FILE: docs/src/sdk/devtools.md
================================================================================

# Devtools（JSONL 日志）

Ditto 的 `DevtoolsLogger` 是一个非常轻量的 JSONL 记录器（feature `sdk`），用于：

- 在开发/集成测试阶段记录请求/响应/事件，方便重放与离线分析
- 在 Gateway 里记录管理面与部分关键事件（通过 `--devtools` 启用）

实现位置：`src/sdk/devtools.rs`，Gateway 集成点：`src/bin/ditto-gateway.rs`（`--devtools`）。

---

## 1) 记录格式

每行一个 JSON：

```json
{ "ts_ms": 1738368000000, "kind": "proxy.request", "payload": { "...": "..." } }
```

字段：

- `ts_ms`：毫秒时间戳
- `kind`：事件名（你自定义或由网关写入）
- `payload`：任意 JSON（建议结构化，避免塞大文本/敏感信息）

---

## 2) 在你自己的服务里使用

```rust
use ditto_llm::sdk::devtools::DevtoolsLogger;
use serde_json::json;

fn main() -> ditto_llm::Result<()> {
    let logger = DevtoolsLogger::new("./logs/devtools.jsonl");
    logger.log_event("app.start", json!({ "ok": true }))?;
    Ok(())
}
```

---

## 3) 在 Gateway 里启用（推荐用于调试）

前置：

- 编译启用 `gateway-devtools`（它包含 `gateway` + `sdk`）

启动：

```bash
cargo run --features "gateway-devtools" --bin ditto-gateway -- ./gateway.json \
  --devtools ./logs/ditto-gateway.jsonl
```

注意事项：

- 你在自己的服务里直接用 `DevtoolsLogger` 时，不会自动脱敏；生产环境务必做好权限与脱敏。
- Ditto Gateway 通过 `--devtools` 写入的 JSONL 会应用 `gateway.json` 的 `observability.redaction` 统一脱敏策略（JSON logs / audit 同一套）。
- JSONL 文件会持续 append；建议配合日志轮转或定期清理。

================================================================================
FILE: docs/src/sdk/telemetry.md
================================================================================

# Telemetry（可插拔事件钩子）

Ditto 的 `Telemetry` 是一个非常小的抽象（feature `sdk`）：

- 你可以向 `Telemetry` 发事件（`TelemetryEvent`）
- 由你实现的 `TelemetrySink` 决定如何处理（写日志、发指标、写 tracing span、上报到你的平台）

实现位置：`src/sdk/telemetry.rs`。

> 现阶段 Telemetry 是“通用积木”，不会自动帮你埋点；它的价值在于让你用统一接口把 Ditto 集成到你现有的观测体系里。

---

## 1) 数据结构

- `TelemetryEvent { name: String, data: Option<Value> }`
- `TelemetrySink::emit(event)`
- `Telemetry::emit(event)`：对外统一入口

---

## 2) 最小示例：接入 tracing

```rust
use ditto_llm::sdk::telemetry::{Telemetry, TelemetryEvent, TelemetrySink};
use serde_json::Value;

struct TracingSink;

impl TelemetrySink for TracingSink {
    fn emit(&self, event: TelemetryEvent) {
        eprintln!("telemetry name={} data={:?}", event.name, event.data);
    }
}

fn main() {
    let telemetry = Telemetry::new(TracingSink);
    telemetry.emit(TelemetryEvent::with_data("llm.request", Value::Null));
}
```

---

## 3) 设计建议（好品味）

- 事件名用“点分层级”：`llm.request` / `llm.response` / `gateway.proxy.error` 等
- `data` 里只放结构化、可聚合字段（不要塞 prompt 全文与 token）
- 所有敏感字段（token、用户输入）默认脱敏或不记录

================================================================================
FILE: docs/src/sdk/mcp.md
================================================================================

# MCP（Tool Schema 互转）

Ditto 在 `sdk` feature 里提供了 MCP tool schema 的轻量互转（只做结构映射，不是 MCP client/server 实现）。

实现位置：`src/sdk/mcp.rs`。

如果你需要 **Gateway 级别** 的 MCP proxy（`/mcp*`）与 MCP tools 集成（`/v1/chat/completions` / `/v1/responses` 的 `tools: [{"type":"mcp", ...}]`），请看「Gateway → MCP Gateway（/mcp + tools）」。

---

## 1) 为什么需要互转？

在工具调用生态里，常见的两种 schema 形状：

- Ditto：`Tool { name, description, parameters, strict }`
- MCP：`McpTool { name, description, inputSchema }`

如果你需要把 Ditto 的工具定义复用到 MCP（或反过来），可以用本页的转换函数。

---

## 2) 从 Ditto Tool 转 MCP Tool

```rust
use ditto_llm::sdk::mcp::to_mcp_tool;

let mcp = to_mcp_tool(&tool);
```

---

## 3) 从 MCP Tool 转 Ditto Tool

```rust
use ditto_llm::sdk::mcp::from_mcp_tool;

let tool = from_mcp_tool(&mcp);
```

注意：

- `McpTool` 没有 `strict` 字段，因此从 MCP 转回 Ditto 时 `strict` 会是 `None`。

================================================================================
FILE: docs/src/sdk/errors.md
================================================================================

# 错误处理

Ditto 统一使用 `ditto_llm::Result<T>`（即 `Result<T, DittoError>`）。

## DittoError 结构

`DittoError` 主要覆盖：

- `Api { status, body }`
  - provider 返回非 2xx 时的错误（Ditto 会尽量把 body 读出来，便于排障）
- `Http(reqwest::Error)` / `Io(std::io::Error)` / `Json(serde_json::Error)`
  - 网络、IO、JSON 解析错误
- `InvalidResponse(String)`
  - 协议不符合预期、字段缺失、无法解析等“语义错误”
- `AuthCommand(String)`
  - `ProviderAuth::Command` 执行失败

## 生产建议

- **日志与脱敏**：`Api.body` 可能包含敏感信息；建议打日志前做脱敏或只保留摘要。
- **重试策略**：不要对所有 `DittoError` 盲目重试。一般建议只对：
  - 网络错误（`Http`）中的 transient 错误
  - 以及明确可重试的 `Api.status`（例如 429/502/503）
  做指数退避与上限控制。
- **错误聚合**：在 Gateway 场景里，推荐把请求 id（`x-request-id`/`x-ditto-request-id`）贯穿到日志与 trace，以便跨组件定位。

## 常见错误与定位思路

- `InvalidResponse("... model is not set ...")`
  - 没有设置默认 model，或请求里没填 `request.model`。请设置 `with_model(...)` 或在 request 中指定。
- `Api { status: 401/403, ... }`
  - token 无效、header 名不对、或网关需要 query param auth。检查 `ProviderConfig.auth` 与 base_url。
- `Api { status: 404/405, ... }`
  - base_url 不对（例如忘了 `/v1`）、或 upstream 不支持某个端点（例如 `/v1/responses`）。

================================================================================
FILE: docs/src/sdk/testing.md
================================================================================

# 测试与集成

Ditto 的测试分三类：

1) **纯逻辑/纯解析单测**：不依赖网络  
2) **HTTP mock 测试**：通过本地 `httpmock` 起一个 server（需要能 bind localhost）  
3) **集成 smoke tests（可选）**：需要真实 API key（feature `integration`）  

## 运行单测

默认：

```bash
cargo test
```

带某些 feature 才会编译的测试（例如 gateway）：

```bash
cargo test --features gateway
```

一次性覆盖更多能力（按需启用，避免无谓编译）：

```bash
cargo test --features all
```

## httpmock 测试说明

仓库里有大量基于 `httpmock` 的测试，用于验证：

- 请求/响应协议是否符合预期
- warnings 生成逻辑是否正确
- gateway 路由/缓存/预算等行为

如果运行环境禁止 bind `127.0.0.1`，这些测试会自动跳过（见 `src/utils/test_support.rs`）。

## integration smoke tests（真实调用，可选）

仓库包含 `tests/integration_smoke.rs`（`#![cfg(feature = "integration")]`）。

启用方式：

```bash
cargo test --features integration
```

这些测试会在缺少环境变量时自动跳过，不会 hard-fail。你需要按 provider 设置对应 key，例如：

- `OPENAI_API_KEY` + `OPENAI_MODEL`
- 以及可选的 embeddings keys（取决于你启用的 provider/features）

## 示例（examples/）

examples 是最直接的“可运行文档”：

```bash
cargo run --example basic
cargo run --example streaming
cargo run --example tool_calling
```

某些 examples 需要额外 features（例如 batches、audio、images），请按报错提示开启。

================================================================================
FILE: docs/src/clients/index.md
================================================================================

# 客户端（JS/React，AI SDK UI-like）

本章面向 **前端/Node** 使用场景：当你的服务端把 Ditto 的 streaming 暴露为 **Stream Protocol v1**（见「SDK → Stream Protocol v1」）时，你需要一个能消费该协议的客户端实现。

Ditto 的定位是提供“最小可用”的 DX：

- 不试图复刻完整的 AI SDK UI 生态（RSC/框架适配/高级 hooks）。
- 提供可靠的协议解析（SSE/NDJSON）与一个轻量的 React hook，便于快速接入 UI。

如果你希望直接对接 Vercel AI SDK UI（例如 `@ai-sdk/react` 的 `useChat`），请优先看「SDK → Stream Protocol v1」里关于 **UI Message Stream v1** 的适配器说明（它与 Ditto 的 stream protocol v1 不同）。

本章包括：

- 「JS：Stream Protocol v1 解析」：`@ditto-llm/client`
- 「React：useStreamV1」：`@ditto-llm/react`


================================================================================
FILE: docs/src/clients/js-client.md
================================================================================

# JS：Stream Protocol v1 解析（SSE / NDJSON）

`@ditto-llm/client` 提供两个能力：

1) 解析 Ditto 的 **Stream Protocol v1**（见「SDK → Stream Protocol v1」）。  
2) 一个很薄的 **Admin API client**（可选），便于脚本化管理 virtual keys / 审计导出。

> 目前这些包以 workspace 形式存在于仓库 `packages/` 下（`private: true`），主要用于示例与内部集成；如果你要在仓库外使用，可以先 vendor/拷贝实现，或把它当作未来可发布的稳定接口。

---

## 1) 解析 Stream Protocol v1（核心）

### 1.1 事件类型

解析后每个 event 都是一个对象：

- `{ v: 1, type: "chunk", data: <StreamChunk> }`
- `{ v: 1, type: "error", data: { message: string } }`
- `{ v: 1, type: "done" }`

### 1.2 SSE（`data: <json>\n\n`）

```ts
import { streamV1FromSseResponse } from "@ditto-llm/client";

const res = await fetch("http://127.0.0.1:8080/my/stream-v1-sse", {
  method: "POST",
  headers: { "content-type": "application/json" },
  body: JSON.stringify({ input: "hello" }),
});

for await (const evt of streamV1FromSseResponse(res)) {
  if (evt.type === "chunk") {
    // evt.data 是一个 StreamChunk（shape 取决于你的服务端输出）
    console.log("chunk", evt.data);
  } else if (evt.type === "error") {
    console.error("stream error", evt.data.message);
  } else if (evt.type === "done") {
    break;
  }
}
```

### 1.3 NDJSON（`<json>\n`）

```ts
import { streamV1FromNdjsonResponse } from "@ditto-llm/client";

const res = await fetch("http://127.0.0.1:8080/my/stream-v1-ndjson");
for await (const evt of streamV1FromNdjsonResponse(res)) {
  if (evt.type === "done") break;
}
```

### 1.4 自动分发（推荐）

如果你的 API 端点会根据 `content-type`/参数切换 SSE 与 NDJSON，可以统一用：

```ts
import { streamV1FromResponse } from "@ditto-llm/client";

const format = "sse"; // 或 "ndjson"
const res = await fetch("http://127.0.0.1:8080/my/stream", { method: "POST" });
for await (const evt of streamV1FromResponse(res, format)) {
  if (evt.type === "done") break;
}
```

---

## 2) Admin API client（可选）

`createAdminClient` 是一个薄封装，适合脚本/运维工具调用 `ditto-gateway` 的 `/admin/*` 端点。

```ts
import { createAdminClient } from "@ditto-llm/client";

const admin = createAdminClient({
  baseUrl: "http://127.0.0.1:8080",
  token: process.env.DITTO_ADMIN_TOKEN!,
  // 默认使用 Authorization: Bearer <token>
  // header: "x-admin-token",
});

const keys = await admin.listKeys({ limit: 100 });
console.log(keys);
```

可用方法（以源码为准）：

- `health()`
- `listKeys()` / `upsertKey()` / `deleteKey()`
- `listAudit()` / `exportAudit()`

下一步：

- 「Gateway → Admin API」与「Gateway → 鉴权：Virtual Keys 与 Admin Token」。


================================================================================
FILE: docs/src/clients/react.md
================================================================================

# React：useStreamV1

`@ditto-llm/react` 提供一个轻量 hook：`useStreamV1()`，用于把 Stream Protocol v1 的事件流聚合成适合 UI 使用的状态。

它适合两类场景：

- 你在浏览器里直接请求一个返回 **stream protocol v1（SSE/NDJSON）** 的端点。
- 你在 React App 里通过自建 `/api/*` 代理到 Ditto（或你的服务端 Ditto SDK）。

> 这个 hook 不依赖特定框架，不等同于 AI SDK UI 的完整 `useChat` 生态；目标是提供“最小、可控、易排障”的 streaming UI 基建。

---

## 1) 最小用法

```tsx
import { useStreamV1 } from "@ditto-llm/react";

export function Demo() {
  const { state, start, abort } = useStreamV1();

  return (
    <div>
      <button
        onClick={() =>
          start(
            (signal) =>
              fetch("/api/stream", {
                method: "POST",
                headers: { "content-type": "application/json" },
                body: JSON.stringify({ input: "hello" }),
                signal,
              }),
            "sse",
          )
        }
        disabled={state.isLoading}
      >
        Start
      </button>
      <button onClick={abort} disabled={!state.isLoading}>
        Abort
      </button>

      {state.error && <pre>Error: {state.error}</pre>}
      <pre>{state.text}</pre>
    </div>
  );
}
```

`start(createResponse, format)` 参数说明：

- `createResponse(signal)`：你提供一个能创建 `fetch()` Response 的函数（hook 会传入 AbortSignal）。
- `format`：`"sse"` 或 `"ndjson"`，与服务端输出一致。

---

## 2) State 字段

`state` 会持续更新：

- `text`：当收到 `text_delta` chunk 时自动拼接（best-effort）
- `chunks`：原始 `StreamChunk` 列表（用于 debug / 自定义 UI）
- `warnings`：聚合后的 warnings（当服务端输出 warnings chunk）
- `done` / `isLoading` / `error`
- `responseId` / `finishReason` / `usage`：best-effort 提取（具体 shape 取决于服务端输出）

下一步：

- 「SDK → Stream Protocol v1」了解服务端如何输出协议。
- 如果你希望兼容 Vercel AI SDK UI：看同页的 UI Message Stream v1 适配说明。


================================================================================
FILE: docs/src/gateway/index.md
================================================================================

# Gateway（LiteLLM-like）

Ditto-LLM 的 Gateway 是一个可选启用的 HTTP 服务（feature `gateway`），对外提供 OpenAI-compatible 的 `/v1/*` surface，并在内部提供控制面能力：

- virtual keys（鉴权 / 归因）
- 限流（rpm/tpm）
- 预算（tokens / USD）
- 路由（weighted / fallback）
- 缓存（control-plane cache + optional proxy cache）
- 审计（可选持久化）
- 观测（request id / logs / Prometheus / OTel）
- MCP gateway（`/mcp*` + MCP tools 集成）
- A2A agents（`/a2a/*` JSON-RPC 代理）

## Passthrough vs Translation

Gateway 同时支持两类路径：

- **Passthrough proxy**：`ANY /v1/*` 原样转发到 OpenAI-compatible upstream（不变形）。
- **Translation proxy**（feature `gateway-translation`）：把 OpenAI in/out 翻译到 native providers（Anthropic/Google/...）。

建议先从「运行网关」开始，跑通最小配置，再逐步加上 virtual keys / redis / routing / observability。

如果你更偏好“按任务走”的教程（复制配置即可跑），请看「Gateway Recipes（可复制落地）」。

================================================================================
FILE: docs/src/gateway/quickstart.md
================================================================================

# 运行网关

`ditto-gateway` 是一个可选启用的 HTTP 服务（feature `gateway`）。它提供：

- OpenAI-compatible passthrough proxy：`ANY /v1/*`
- 可选控制面：virtual keys / limits / budgets / guardrails / caching / routing
- 可选 translation：OpenAI in/out → native providers（feature `gateway-translation`）

如果你想要“像 LiteLLM Proxy 一样”的落地方式（发放 virtual keys + 管理面动态增删改 + 多副本共享），建议直接从「Gateway Recipes → Recipe 1」开始。

## 0) 准备环境变量（两种方式）

方式 A：直接 export（最小）

```bash
export OPENAI_API_KEY=...
```

方式 B：写入 `.env`（推荐，便于本地/容器复用）

```bash
# .env
OPENAI_API_KEY=...
```

> 注意：如果你的 `gateway.json` 使用了 `${OPENAI_API_KEY}`，但运行时 env 缺失或为空，网关会在启动时直接报错退出（避免 silent misconfig）。

## 1) 选择 features（建议用“套餐”）

最小网关（仅转发 /v1/*）：

```bash
cargo build --features gateway --bin ditto-gateway
```

常见套餐：

- 本地试玩：`gateway`
- 单机可持久化（管理 keys / 预算 ledger / 审计）：`gateway + gateway-store-sqlite`
- 多副本/分布式（推荐）：`gateway + gateway-store-redis`（可选再叠加 proxy-cache / routing-advanced / prometheus / otel）

> `ditto-gateway` 的完整 CLI 参数见「参考 → CLI 选项（ditto-gateway）」。目前 CLI 采用轻量参数解析：不提供 `--help`，但启动时缺少必填参数会打印 usage。

## 2) 准备最小 gateway.json（两种鉴权模式）

下面示例把所有 `/v1/*` 转发到 OpenAI（注意 `base_url` 一般以 `/v1` 结尾）。

### 模式 A：网关持有 upstream key（最常见）

特点：

- 你把 upstream 的真实 API key 配在 `backends[].headers`（或 `.env`）
- 客户端不需要提供 OpenAI key（但这意味着“网关本身就是一个能力入口”，生产请务必加 virtual keys 或外层网关鉴权）

```json
{
  "backends": [
    {
      "name": "primary",
      "base_url": "https://api.openai.com/v1",
      "max_in_flight": 64,
      "timeout_seconds": 60,
      "headers": { "authorization": "Bearer ${OPENAI_API_KEY}" },
      "query_params": {}
    }
  ],
  "virtual_keys": [],
  "router": { "default_backends": [{ "backend": "primary", "weight": 1.0 }], "rules": [] }
}
```

> 细节：当 `virtual_keys` 为空时，Ditto 不会把客户端 `Authorization` 当作 virtual key；但如果 backend 配了 `authorization`，它会覆盖同名 header（因此建议客户端不要再传 `Authorization`，避免误解）。

### 模式 B：客户端持有 upstream key（纯反向代理）

特点：

- 你不在 `backends[].headers` 注入 `authorization`
- 客户端请求时必须自带 `Authorization: Bearer <upstream_key>`（Ditto 会原样转发）

```json
{
  "backends": [
    {
      "name": "primary",
      "base_url": "https://api.openai.com/v1",
      "max_in_flight": 64,
      "timeout_seconds": 60,
      "headers": {},
      "query_params": {}
    }
  ],
  "virtual_keys": [],
  "router": { "default_backends": [{ "backend": "primary", "weight": 1.0 }], "rules": [] }
}
```

## 3) 启动（第一个参数必须是 config 路径）

`ditto-gateway` 的第一个参数必须是 `gateway.json` 路径；如果你想用 `gateway.yaml`，需要编译启用 feature `gateway-config-yaml`：

```bash
cargo run --features gateway --bin ditto-gateway -- ./gateway.json --listen 0.0.0.0:8080
```

如果你把 token 放在 `.env` 文件里（推荐），可以：

```bash
cargo run --features gateway --bin ditto-gateway -- ./gateway.json --dotenv .env --listen 0.0.0.0:8080
```

## 4) 验证

```bash
curl -sS http://127.0.0.1:8080/health
curl -sS http://127.0.0.1:8080/v1/models | head
```

最小对话（Chat Completions）：

```bash
curl -sS http://127.0.0.1:8080/v1/chat/completions \
  -H "content-type: application/json" \
  -d '{"model":"gpt-4o-mini","messages":[{"role":"user","content":"Say hello."}]}' | head
```

> 如果你使用的是「模式 B：客户端持有 upstream key」，请额外加上 `-H "authorization: Bearer <UPSTREAM_API_KEY>"`。

如果你测试的是 `POST /v1/responses`：

- upstream 支持时：直接透传
- upstream 不支持时：Ditto 会 fallback 到 `POST /v1/chat/completions` 并返回 best-effort Responses-like（响应头带 `x-ditto-shim: responses_via_chat_completions`）

## 5) 下一步

- 想加鉴权与配额：看「鉴权：Virtual Keys 与 Admin Token」与「预算与成本」。
- 想做多 backend 路由与故障切换：看「路由：Weighted / Fallback / Retry」。
- 想多副本部署：看「部署：多副本与分布式」。
- 想用容器/模板快速跑起来：看「Docker Compose（本地模板）」与「Kubernetes（多副本模板）」。
- 想直接复制一套可跑配置：看「Gateway Recipes（可复制落地）」。

================================================================================
FILE: docs/src/gateway/docker-compose.md
================================================================================

# Docker Compose（本地模板）

本页提供一个“复制即可跑”的 `docker compose` 模板，用于本地/CI 快速把 `ditto-gateway + redis` 跑起来（对标 LiteLLM docs 的 quickstart 体验）。

模板文件：

- `deploy/docker-compose.yml`
- `deploy/gateway.example.json`
- `deploy/.env.example`

---

## 1) 准备环境变量

在仓库根目录：

```bash
cp deploy/.env.example deploy/.env
```

编辑 `deploy/.env`，填入：

- `OPENAI_API_KEY`
- `DITTO_ADMIN_TOKEN`
- `DITTO_VK_BOOTSTRAP`
- `REDIS_URL`（默认 `redis://redis:6379`）

---

## 2) 启动

```bash
docker compose -f deploy/docker-compose.yml up --build
```

默认监听 `http://127.0.0.1:8080`。

---

## 3) 验证

健康检查：

```bash
curl -sS http://127.0.0.1:8080/health
```

OpenAI-compatible（用 virtual key 调用）：

```bash
curl -sS http://127.0.0.1:8080/v1/models -H "Authorization: Bearer ${DITTO_VK_BOOTSTRAP}" | head
```

Admin API（用 admin token）：

```bash
curl -sS http://127.0.0.1:8080/admin/keys -H "Authorization: Bearer ${DITTO_ADMIN_TOKEN}" | head
```

---

## 4) 生产注意事项（简版）

- 多副本建议直接走「部署：多副本与分布式」+ 「Kubernetes 模板」，并启用 redis store 保证一致性。
- 如果你在 ingress/LB 后面跑 streaming（SSE），请确保 proxy 不会对响应做缓冲（buffering），并把 idle timeout 调高。

================================================================================
FILE: docs/src/gateway/kubernetes.md
================================================================================

# Kubernetes（多副本模板）

本页提供一套最小 Kubernetes manifests，作为企业部署的起点（多副本 + Redis 共享状态）。

模板目录：`deploy/k8s/`

- `configmap.yaml`：`gateway.json`（支持 `${ENV_VAR}` 插值）
- `secret.example.yaml`：示例 Secret（请自行替换）
- `deployment.yaml`：2 副本 Deployment（含 /health 探针）
- `service.yaml`：ClusterIP Service

如果你更偏好用 Helm 管理参数化部署，也可以直接使用：

- `deploy/helm/ditto-gateway`

---

## 1) 构建与推送镜像

在 `ditto-llm` 仓库根目录：

```bash
docker build -t <registry>/ditto-gateway:<tag> .
docker push <registry>/ditto-gateway:<tag>
```

然后把 `deploy/k8s/deployment.yaml` 里的 `image:` 改成你的镜像地址。

---

## 2) 配置 Redis

多副本要想让 virtual keys / budgets / audit / cache 在实例间一致，建议启用 Redis store。

你需要：

- 集群内可访问的 Redis（Service 名例如 `redis:6379`）
- 在 Secret 里设置 `REDIS_URL`

---

## 3) 应用 manifests

```bash
kubectl apply -f deploy/k8s/configmap.yaml
kubectl apply -f deploy/k8s/secret.example.yaml
kubectl apply -f deploy/k8s/deployment.yaml
kubectl apply -f deploy/k8s/service.yaml
```

端口转发验证：

```bash
kubectl port-forward svc/ditto-gateway 8080:8080
curl -sS http://127.0.0.1:8080/health
```

---

## 4) Ingress / LB（streaming 注意事项）

如果你要在 ingress/LB 后面代理 `text/event-stream`：

- 关闭响应缓冲（buffering）
- 调高 idle timeout（streaming 请求会长连接）
- 确保不会把 streaming 响应强制压缩/聚合

具体配置与 controller 相关，这里不做绑定；生产建议把这类配置固化成你的平台层模板。

================================================================================
FILE: docs/src/gateway/recipes.md
================================================================================

# Gateway Recipes（可复制落地）

本页的定位类似 LiteLLM Proxy docs 里的“how-to / recipes”：每个 recipe 都给出 **可复制的配置 + 启动命令 + 验证 curl**。

---

## Recipe 1：OpenAI upstream + Virtual Keys + Admin API（最常见）

目标：

- 对外发放 virtual keys（客户端用）
- 对内用 OpenAI API key 访问 upstream（不暴露给客户端）
- 用 Admin API 动态增删改 key（并持久化到 Redis，支持多副本）

### 1) `.env`（示例）

```bash
OPENAI_API_KEY=...
DITTO_ADMIN_TOKEN=...
DITTO_VK_BOOTSTRAP=...
REDIS_URL=redis://127.0.0.1:6379
```

### 2) `gateway.json`（最小骨架）

```json
{
  "backends": [
    {
      "name": "openai",
      "base_url": "https://api.openai.com/v1",
      "max_in_flight": 64,
      "timeout_seconds": 60,
      "headers": { "authorization": "Bearer ${OPENAI_API_KEY}" },
      "query_params": {}
    }
  ],
  "virtual_keys": [
    {
      "id": "vk-bootstrap",
      "token": "${DITTO_VK_BOOTSTRAP}",
      "enabled": true,
      "tenant_id": null,
      "project_id": null,
      "user_id": null,
      "tenant_budget": null,
      "project_budget": null,
      "user_budget": null,
      "tenant_limits": null,
      "project_limits": null,
      "user_limits": null,
      "limits": { "rpm": 60, "tpm": 20000 },
      "budget": { "total_tokens": 5000000, "total_usd_micros": null },
      "cache": { "enabled": false, "ttl_seconds": null, "max_entries": 1024, "max_body_bytes": 1048576, "max_total_body_bytes": 67108864 },
      "guardrails": { "block_pii": true, "validate_schema": true },
      "passthrough": { "allow": true, "bypass_cache": true },
      "route": null
    }
  ],
  "router": { "default_backends": [{ "backend": "openai", "weight": 1.0 }], "rules": [] }
}
```

> 说明：virtual key 一旦启用，客户端的 `Authorization` 不会被转发 upstream；upstream 鉴权由 `backends[].headers` 注入。

### 3) 启动

```bash
cargo run --features "gateway gateway-store-redis" --bin ditto-gateway -- ./gateway.json \
  --listen 0.0.0.0:8080 \
  --dotenv .env \
  --admin-token-env DITTO_ADMIN_TOKEN \
  --redis-env REDIS_URL --redis-prefix ditto \
  --proxy-max-in-flight 256
```

### 4) 验证（客户端调用）

```bash
curl -sS http://127.0.0.1:8080/health
curl -sS http://127.0.0.1:8080/v1/models -H "Authorization: Bearer ${DITTO_VK_BOOTSTRAP}" | head
```

多语言最小模板（包含 request id 传递）：

- Node：`examples/clients/node/stream_chat_completions.mjs`
- Python：`examples/clients/python/chat_completions.py`
- Go：`examples/clients/go/chat_completions.go`

### 5) 验证（Admin API）

```bash
curl -sS http://127.0.0.1:8080/admin/keys -H "Authorization: Bearer ${DITTO_ADMIN_TOKEN}" | jq .
```

---

## Recipe 2：Weighted 路由 + fallback（主备）

目标：

- `primary`/`backup` 两个 upstream
- 按权重选择主 backend，并在失败时 fallback

关键配置：`router.default_backends` 或 `router.rules[].backends`（见「路由」）。

> 重要语义：\n> - 网络错误会自动尝试下一个 backend。\n> - 想在 `429/5xx` 等“可重试状态码”时 fallback，需要启用 `gateway-routing-advanced` 并打开 `--proxy-retry`。

示例（片段）：

```json
{
  "backends": [
    { "name": "primary", "base_url": "https://api.openai.com/v1", "headers": { "authorization": "Bearer ${OPENAI_API_KEY}" } },
    { "name": "backup", "base_url": "http://litellm:4000/v1", "headers": { "authorization": "Bearer ${LITELLM_MASTER_KEY}" } }
  ],
  "router": {
    "default_backends": [
      { "backend": "primary", "weight": 9 },
      { "backend": "backup", "weight": 1 }
    ],
    "rules": []
  }
}
```

---

## Recipe 3：Proxy cache（非 streaming）+ Redis L2（多副本）

目标：

- 缓存 `GET/POST` 的非 streaming 成功响应
- 多副本共享缓存（Redis）

启用条件：

- 编译启用 `gateway-proxy-cache` + `gateway-store-redis`
- 运行时加 `--proxy-cache --proxy-cache-ttl ...`

并确保你已启用 `--redis ...`（否则只有本机内存缓存）。

示例：

```bash
cargo run --features "gateway gateway-proxy-cache gateway-store-redis" --bin ditto-gateway -- ./gateway.json \
  --dotenv .env --redis-env REDIS_URL --redis-prefix ditto \
  --proxy-cache --proxy-cache-ttl 60 --proxy-cache-max-entries 2048
```

验证（命中会带响应头）：

- `x-ditto-cache: hit`
- `x-ditto-cache-key: ...`
- `x-ditto-cache-source: memory|redis`

---

## Recipe 4：预算（tokens / USD）+ pricing

目标：

- 用 `BudgetConfig.total_tokens` 限制 token 额度
- 用 `BudgetConfig.total_usd_micros` 限制美元额度（需要 pricing）

关键点：

- cost budgets 需要编译启用 `gateway-costing`
- 需要 `--pricing-litellm <path>` 加载 LiteLLM 风格 pricing JSON

示例（片段）：

```json
{
  "virtual_keys": [
    {
      "id": "vk-paid",
      "token": "${VK_PAID}",
      "enabled": true,
      "limits": {},
      "budget": { "total_tokens": 5000000, "total_usd_micros": 1000000 },
      "cache": {},
      "guardrails": {},
      "passthrough": { "allow": true, "bypass_cache": true },
      "route": null
    }
  ]
}
```

启动（示意）：

```bash
cargo run --features "gateway gateway-costing gateway-store-redis" --bin ditto-gateway -- ./gateway.json \
  --pricing-litellm ./pricing.json \
  --redis redis://127.0.0.1:6379 --redis-prefix ditto
```

---

## Recipe 5：重试/熔断/健康检查（routing-advanced）

目标：

- 在 upstream 不稳定时提高可用性

启用方式：

- 编译启用 `gateway-routing-advanced`
- 运行时打开 `--proxy-retry` / `--proxy-circuit-breaker` / `--proxy-health-checks`

并使用 `/admin/backends` 查看健康状态（需 admin token）。

示例：

```bash
cargo run --features "gateway gateway-routing-advanced" --bin ditto-gateway -- ./gateway.json \
  --proxy-retry --proxy-retry-max-attempts 2 \
  --proxy-circuit-breaker --proxy-cb-failure-threshold 3 --proxy-cb-cooldown-secs 30 \
  --proxy-health-checks --proxy-health-check-path /v1/models --proxy-health-check-interval-secs 10
```

---

## Recipe 6：OpenAI-compatible upstream → Claude Code CLI + Gemini CLI（指向 localhost）

目标：

- 上游是 **OpenAI-compatible**（例如 LiteLLM 的 `/v1`），模型为 `glm-4.7`
- 本地启动 `ditto-gateway`，同时对外提供：
  - OpenAI：`/v1/*`
  - Claude（Anthropic Messages）：`/v1/messages`
  - Gemini（Google GenAI）：`/v1beta/models/*:generateContent` / `:streamGenerateContent`
- 让 **Claude Code CLI** / **Gemini CLI** 都能通过 `localhost` 直接使用

### 1) 配置文件（示例）

直接用仓库内示例：`deploy/gateway.litellm.talesofai.cn.glm47.json`。

这个示例做了两件事：

- 上游鉴权从环境变量注入：`TALES_LITELLM_API_KEY`
- 任意下游 `model` 都会被改写到上游 `glm-4.7`：`model_map: { "*": "glm-4.7" }`

### 2) 启动

```bash
export TALES_LITELLM_API_KEY='...'
export DITTO_VK='vk-local'

cargo run --features gateway --bin ditto-gateway -- ./deploy/gateway.litellm.talesofai.cn.glm47.json \
  --listen 127.0.0.1:18080
```

### 3) 验证（curl）

```bash
# OpenAI
curl -sS http://127.0.0.1:18080/v1/models \
  -H "Authorization: Bearer ${DITTO_VK}" | head

# Claude (Anthropic Messages)
curl -sS http://127.0.0.1:18080/v1/messages \
  -H "x-api-key: ${DITTO_VK}" \
  -H "content-type: application/json" \
  -d '{"model":"claude-local","max_tokens":16,"messages":[{"role":"user","content":[{"type":"text","text":"Reply with ok"}]}]}' | jq -r '.content[0].text'

# Gemini (Google GenAI)
curl -sS http://127.0.0.1:18080/v1beta/models/gemini-pro:generateContent \
  -H "x-goog-api-key: ${DITTO_VK}" \
  -H "content-type: application/json" \
  -d '{"contents":[{"role":"user","parts":[{"text":"Reply with ok"}]}]}' | jq -r '.candidates[0].content.parts[0].text'
```

### 4) Claude Code CLI（Anthropic Base URL 指向 localhost）

```bash
export ANTHROPIC_BASE_URL='http://127.0.0.1:18080'
export ANTHROPIC_API_KEY="${DITTO_VK}"

claude -p 'Reply with ok'
```

### 5) Gemini CLI（Gemini Base URL 指向 localhost）

```bash
export GOOGLE_GEMINI_BASE_URL='http://127.0.0.1:18080'
export GEMINI_API_KEY="${DITTO_VK}"

# 建议显式选一个模型（避免 auto 模式走 classifier / generateJson）
gemini -m flash -p 'Reply with ok'
```

---

下一步：

- 想要更完整的端点/参数查表：看「参考 → CLI」与「Gateway → HTTP Endpoints」
- 想要生产部署注意事项：看「部署：多副本与分布式」与「安全与加固」

================================================================================
FILE: docs/src/gateway/config.md
================================================================================

# 配置文件（gateway.json / gateway.yaml）

Gateway 配置的核心类型是 `GatewayConfig`（见 `src/gateway/config.rs`）：

Ditto 支持用 **JSON** 表达配置；如果你希望用 YAML，也可以启用 `gateway-config-yaml` feature（字段完全一致）；下文以 JSON 为例。

```json
{
  "backends": [ ... ],
  "virtual_keys": [ ... ],
  "router": { ... },
  "a2a_agents": [ ... ],
  "mcp_servers": [ ... ],
  "observability": { ... }
}
```

## backends：两种模式（passthrough vs translation）

一个 backend 可以是两种形态之一：

### A) Passthrough proxy backend（OpenAI-compatible upstream）

使用 `base_url` + `headers` + `query_params` 描述一个 OpenAI-compatible upstream（例如 OpenAI、LiteLLM、Azure 网关等）。

```json
{
  "name": "primary",
  "base_url": "http://127.0.0.1:4000/v1",
  "headers": { "authorization": "Bearer ${OPENAI_COMPAT_API_KEY}" },
  "query_params": { "api-version": "${AZURE_API_VERSION}" }
}
```

### B) Translation backend（native provider）

当你启用 feature `gateway-translation` 后，backend 也可以写成：

```json
{
  "name": "anthropic",
  "provider": "anthropic",
  "provider_config": {
    "auth": { "type": "api_key_env", "keys": ["ANTHROPIC_API_KEY"] },
    "default_model": "claude-3-5-sonnet-20241022"
  }
}
```

此时 gateway 会把 OpenAI in/out 翻译为对应 provider 的 native 请求（并尽量保持 OpenAI shape）。

## backend 字段说明

`BackendConfig` 常用字段：

- `name`：唯一 backend 名称（用于路由选择与观测标签）
- `base_url`：passthrough upstream 根地址（通常以 `/v1` 结尾）
- `headers` / `query_params`：注入到 upstream 请求的默认 headers/query
- `max_in_flight`：该 backend 的并发上限（超限返回 429）
- `timeout_seconds`：该 backend 的请求超时（默认 300s）
- `provider` / `provider_config`：translation backend 配置（详见「SDK → ProviderConfig 与 Profile」）
- `model_map`：按 key/value 重写 `model`
  - 在 passthrough proxy 中：重写 JSON body 的 `model`
  - 在 translation 中：作为 `TranslationBackend.model_map` 使用

## virtual_keys：鉴权/限流/预算/策略的单位

当 `virtual_keys` 非空时：

- 客户端必须提供 virtual key（`Authorization: Bearer <virtual_key>` 或 `x-api-key` 等）
- 客户端的 `Authorization` 不会被透传到 upstream（避免把虚拟 key 泄露给上游）
- upstream 的鉴权由 backend 的 `headers/query_params` 或 translation backend 的 `provider_config.auth` 决定

virtual key 的字段很多，建议先从最小配置开始：

```json
{
  "id": "vk-dev",
  "token": "${DITTO_VK_DEV}",
  "enabled": true,
  "tenant_id": null,
  "project_id": null,
  "user_id": null,
  "tenant_budget": null,
  "project_budget": null,
  "user_budget": null,
  "tenant_limits": null,
  "project_limits": null,
  "user_limits": null,
  "limits": {},
  "budget": {},
  "cache": { "enabled": false },
  "guardrails": {},
  "passthrough": { "allow": true, "bypass_cache": true },
  "route": null
}
```

详细解释见「鉴权」「预算与成本」「缓存」「安全与加固」。

### Enterprise：Tenant/Project/User shared budgets & limits（可选）

如果你希望把多个 virtual keys 归并到同一个“配额桶”（企业常见：按 tenant/project/user 做聚合），可以启用：

- `tenant_id` + `tenant_budget` / `tenant_limits`
- `project_id` + `project_budget` / `project_limits`
- `user_id` + `user_budget` / `user_limits`

聚合语义：

- `tenant:*` / `project:*` / `user:*` scope 会被多个 key 共享
- 任意一个 scope 超额都会被拒绝（见「预算与成本」）
- 当启用 Redis store 时，shared limits/budgets 在多副本下也会保持全局一致（见「部署：多副本与分布式」与「预算与成本」）

## router：按模型路由到 backend

`RouterConfig` 支持：

- `default_backends`：按 weight 选择主 backend（并返回 fallback 顺序）
- `rules[]`：按 `model_prefix` 覆盖路由（默认前缀匹配；可选 `exact=true` 精确匹配；也可写 weighted backends）

示例：

```json
{
  "default_backends": [{ "backend": "primary", "weight": 1.0 }],
  "rules": [
    {
      "model_prefix": "gpt-4",
      "backends": [
        { "backend": "primary", "weight": 9 },
        { "backend": "backup", "weight": 1 }
      ]
    }
  ]
}
```

## `${ENV_VAR}` 占位符展开

Gateway 支持在以下字段使用 `${ENV_VAR}`：

- `backends[].base_url` / `headers` / `query_params`
- `backends[].provider_config.*`（base_url/default_model/http_headers/http_query_params/model_whitelist）
- `virtual_keys[].token`
- `a2a_agents[].agent_card_params.url` / `headers` / `query_params`
- `mcp_servers[].url` / `headers` / `query_params`

## a2a_agents：A2A agent registry（LiteLLM-like，beta）

如果你希望“通过 Ditto Gateway 调用 A2A agents”（对齐 LiteLLM 的 `/a2a/*` 端点），可以在配置里注册 agents：

```json
{
  "a2a_agents": [
    {
      "agent_id": "hello-world",
      "agent_card_params": {
        "name": "Hello World Agent",
        "url": "http://127.0.0.1:9999/"
      }
    }
  ]
}
```

说明：

- `agent_id`：Ditto 的路由 id（对应 `/a2a/:agent_id`）。
- `agent_card_params`：Ditto 会在 `GET /a2a/:agent_id/.well-known/agent-card.json` 返回它，并把其中的 `url` 字段重写为 Ditto 自己的 `/a2a/:agent_id`（让 A2A SDK 后续请求继续走 Ditto）。
- `agent_card_params.url`：同时也是 Ditto 代理请求时实际要打到的 **agent 后端 URL**（Ditto 会将 JSON-RPC 请求转发到该 URL；如果后端只实现了 `/message/send` 或 `/message/stream`，Ditto 会自动 fallback 一次）。
- `headers` / `query_params` / `timeout_seconds`：可选，用于给 agent 后端注入鉴权与超时（与 `backends[]` 同语义）。

同样支持 env/secret 占位符：

- `${ENV_KEY}`
- `os.environ/ENV_KEY`
- `secret://...`


若 env 缺失或为空，启动会失败（避免 silent misconfig）。

兼容性补充（迁移 LiteLLM 配置时常见）：

- 如果某个字段的值是 `os.environ/ENV_KEY`（整段字符串），Ditto 会把它解析为环境变量引用并替换为对应的 env 值。

## mcp_servers：MCP server registry（LiteLLM-like）

如果你希望通过 Ditto Gateway 暴露 `/mcp*` 端点，并在 `/v1/chat/completions` / `/v1/responses` 中使用 `tools: [{"type":"mcp", ...}]`，可以在配置里注册 MCP servers：

```json
{
  "mcp_servers": [
    {
      "server_id": "local",
      "url": "http://127.0.0.1:3000/mcp",
      "headers": { "authorization": "Bearer ${MCP_TOKEN}" },
      "query_params": {},
      "timeout_seconds": 30
    }
  ]
}
```

字段说明：

- `server_id`：Ditto 内部标识（用于选择 servers，以及多 server 时给工具名加 `<server_id>-` 前缀）
- `url`：MCP server 的 HTTP endpoint（只支持 `http://` / `https://`）
- `headers` / `query_params`：转发时注入（可用于鉴权）
- `timeout_seconds`：覆盖默认超时（默认 300s）

兼容性补充：

- `url` 同时接受别名字段 `http_url`

使用方式与端点说明见「Gateway → MCP Gateway（/mcp + tools）」。

## observability：观测与脱敏（重要）

`observability.redaction` 定义了 Ditto Gateway 写出的观测数据如何脱敏，包括：

- 结构化 JSON logs（`--json-logs`）
- 审计日志（sqlite/redis store）
- Devtools JSONL（`--devtools`）

> 这不是“安全万无一失”的魔法，而是把泄露面收敛到一处可配置的策略。生产环境仍需要最小权限、日志保留策略与访问控制。

### 默认行为（开箱即用）

默认会把匹配到的敏感信息替换为 `"<redacted>"`：

- 按 key 名脱敏（不区分大小写）：`authorization` / `token` / `secret` / `api_key` / `password` 等
- 对 `path` / `url` / `base_url` / `endpoint` 这类字段的字符串值：会把 URL query 中匹配到的参数值脱敏（例如 `?api_key=...` / `?token=...`）
- 额外正则（默认）：`Bearer <...>` 与 `sk-...` 风格 token

### 配置示例

```json
{
  "observability": {
    "redaction": {
      "replacement": "<redacted>",
      "redact_headers": ["authorization", "x-api-key"],
      "redact_key_names": ["token", "api_key", "secret"],
      "sanitize_query_in_keys": ["path", "url", "base_url", "endpoint"],
      "redact_query_params": ["api_key", "token"],
      "redact_json_pointers": ["/request/headers/authorization"],
      "redact_regexes": ["(?i)bearer\\s+[^\\s]+", "sk-[A-Za-z0-9]{10,}"]
    }
  }
}
```

说明：

- “按 key 名脱敏”作用于任意 JSON（不仅限 headers）。这是一种务实的策略：不要把 token 放进 payload 里指望“你会记得别打印”。
- 如果你真的要关闭脱敏（不推荐），把上面所有 `redact_*` 列表设为空数组即可；`replacement` 仍必须是非空字符串。
- `ditto-gateway` 启动时会校验 `redact_json_pointers` 与 `redact_regexes`，避免带着错误配置在生产里“以为自己脱敏了”。

================================================================================
FILE: docs/src/gateway/endpoints.md
================================================================================

# HTTP Endpoints

Gateway 的 HTTP 路由见 `src/gateway/http/core.rs`。

> 说明：本页重点描述 Ditto Gateway 自己暴露的端点与语义；对于 `/v1/*` passthrough 的具体请求/响应格式，请参考 OpenAI-compatible API（Ditto 尽量不变形）。

## Health

- `GET /health` → `{ "status": "ok" }`

## Core metrics（JSON）

- `GET /metrics` → `ObservabilitySnapshot`（简单计数器：requests/cache_hits/rate_limited/...）

## Prometheus metrics（可选）

需要启用 feature `gateway-metrics-prometheus` 并传 `--prometheus-metrics`：

- `GET /metrics/prometheus`

## OpenAI-compatible proxy（passthrough）

- `ANY /v1/*`

行为要点：

- 如果 `virtual_keys` 为空：
  - Ditto 不会把 client 的 `Authorization` 当作 virtual key；它会随请求一起被转发到 upstream。
  - **backend 的 `headers/query_params` 永远会被注入**，并且同名 header 会覆盖 client header（例如 backend 配了 `authorization` 时，会覆盖 client `Authorization`）。
- 如果 `virtual_keys` 非空：
  - client 必须提供 virtual key（`Authorization: Bearer <vk>` / `x-ditto-virtual-key` / `x-api-key`）
  - client 的 `Authorization` 被视为 virtual key，不会转发到 upstream
  - upstream 的鉴权由 backend 的 `headers` / `query_params` 决定

### /v1/responses shim（重要）

当 upstream 不支持 `POST /v1/responses`（例如返回 404/405/501），Ditto 会自动 fallback 到 `POST /v1/chat/completions` 并返回 best-effort 的 “Responses-like” response/stream：

- 返回头会包含 `x-ditto-shim: responses_via_chat_completions`

注意：

- 非 streaming 的 shim 需要把 upstream 的 chat/completions JSON 响应完整读入内存后再转换；为避免 OOM，Ditto 对该缓冲设置了上限（当前 8MiB）。如果响应超过上限，Ditto 会返回 502，并建议改用 streaming 或直接调用 `POST /v1/chat/completions`。

这使得你可以在同一个 gateway 下兼容“只支持 chat/completions 的 OpenAI-compatible 服务”。

## OpenAI-compatible translation（可选）

启用 feature `gateway-translation` 后，以下端点可由 translation backend（配置了 `provider` 的 backend）直接服务：

- `GET /v1/models`、`GET /v1/models/*`
- `POST /v1/chat/completions`、`POST /v1/completions`
- `POST /v1/responses`、`POST /v1/responses/compact`
- `POST /v1/embeddings`
- `POST /v1/moderations`
- `POST /v1/images/generations`
- `POST /v1/audio/transcriptions`、`POST /v1/audio/translations`、`POST /v1/audio/speech`
- `POST /v1/rerank`
- `/v1/batches`（以及 retrieve/cancel）

当请求由 translation backend 处理时，响应会包含：

- `x-ditto-translation: <provider>`

## Anthropic Messages（compat）

Ditto Gateway 提供 Anthropic Messages API 的兼容端点（请求/响应为 Anthropic 口径），内部会转成 OpenAI-compatible 的 `/v1/chat/completions` 进行代理，然后再翻回 Anthropic message（含 streaming）。

- `POST /v1/messages`
- `POST /v1/messages/count_tokens`
- 兼容别名：
  - `POST /messages`
  - `POST /messages/count_tokens`

`/messages/count_tokens` 是 best-effort 估算（启用 `gateway-tokenizer` 时会尽量按模型计数，否则回退按 body 字节估算）。

## A2A Agents（LiteLLM-like，beta）

Ditto Gateway 支持 LiteLLM 风格的 A2A 协议端点（JSON-RPC 2.0），用于“通过网关调用已注册的 agent 服务”：

- `GET /a2a/:agent_id/.well-known/agent-card.json`
- `POST /a2a/:agent_id`
- `POST /a2a/:agent_id/message/send`
- `POST /a2a/:agent_id/message/stream`
- `POST /v1/a2a/:agent_id/message/send`
- `POST /v1/a2a/:agent_id/message/stream`

语义：

- 请求体是 JSON-RPC 2.0（`jsonrpc: "2.0"`），`method` 支持：
  - `message/send`（非流式）
  - `message/stream`（流式；NDJSON，一行一个 JSON）
- Ditto 会把请求代理到该 agent 的真实 `url`（来自配置 `a2a_agents[].agent_card_params.url`），并原样转发响应。
- `agent-card.json` 会将 `url` 重写为 Ditto 的 `/a2a/:agent_id`（让 A2A SDK 后续请求继续走 Ditto）。
- 当 `virtual_keys` 非空时，A2A 端点同样需要 virtual key（与 `/v1/*` 一致）。

## MCP Gateway（LiteLLM-like）

Ditto Gateway 支持 MCP HTTP JSON-RPC proxy，并提供 `/v1/chat/completions` 与 `/v1/responses` 的 MCP tools 集成：

- MCP JSON-RPC：
  - `POST /mcp`
  - `POST /mcp/<servers>` 或 `POST /<servers>/mcp`（选择 server，例如 `local,github`）
- 便捷端点：
  - `ANY /mcp/tools/list`
  - `ANY /mcp/tools/call`
- server 选择（任选其一）：
  - header：`x-mcp-servers: local,github`
  - path：`/mcp/local,github` 或 `/local,github/mcp`
- 当 `virtual_keys` 非空时，`/mcp*` 端点同样需要 virtual key。

完整说明与示例见「Gateway → MCP Gateway（/mcp + tools）」。

## Control-plane demo endpoint

- `POST /v1/gateway`
  - 请求体：`GatewayRequest`（包含 `virtual_key/model/prompt/input_tokens/max_output_tokens/passthrough`）
  - 响应体：`GatewayResponse`（包含 `content/output_tokens/backend/cached`）

这个端点主要用于“演示控制面能力”（预算/限流/缓存/路由/策略）；实际生产更多使用 `/v1/*` passthrough 或 translation。

## Admin endpoints（可选）

当你通过 `--admin-token*`（write）或 `--admin-read-token*`（read-only）启用 admin token 后，会开放 `/admin/*`（只读或读写）。

常见端点：

- `GET /admin/keys`（read-only 或 write token）
- `POST /admin/keys`、`PUT|DELETE /admin/keys/:id`（需要 write token）
- `POST /admin/proxy_cache/purge`（需要 write token + proxy cache）
- `GET /admin/backends`（read-only 或 write token）
- `POST /admin/backends/:name/reset`（需要 write token + `gateway-routing-advanced`）
- `GET /admin/audit`、`GET /admin/budgets*`（需要启用 sqlite/redis store）
- `GET /admin/costs*`（需要启用 sqlite/redis store + `gateway-costing`）

详细见「Admin API」。

## 响应头（Observability）

Ditto 会尽量为每个响应附加以下头（便于排障/观测）：

- `x-ditto-backend`: 实际使用的 backend 名称
- `x-ditto-request-id`: request id（复用或生成 `x-request-id`）
- `x-ditto-cache`: `hit`（当 proxy cache 命中时）
- `x-ditto-cache-key`: cache key（当 cacheable 时）
- `x-ditto-cache-source`: `memory` 或 `redis`（当 cache 命中时）

================================================================================
FILE: docs/src/gateway/mcp.md
================================================================================

# MCP Gateway（/mcp + tools）

Ditto Gateway 提供一个 **LiteLLM-like** 的 MCP HTTP JSON-RPC proxy，并把 MCP tools 融合进 OpenAI-compatible 的 `POST /v1/chat/completions` 与 `POST /v1/responses`。

你可以把它理解为两条能力：

1) **MCP Proxy**：`/mcp*` 端点 → 转发 `tools/list` / `tools/call` 到你注册的 MCP servers  
2) **OpenAI endpoints 集成**：在 `tools` 里写 `{"type":"mcp", ...}`，Ditto 会把 MCP tools 转成 OpenAI `function` tools，并可选自动执行 tool calls

---

## 1) 配置：mcp_servers registry

在 `gateway.json`（或启用 `gateway-config-yaml` 后的 `gateway.yaml`）里注册 MCP servers：

```json
{
  "mcp_servers": [
    {
      "server_id": "local",
      "url": "http://127.0.0.1:3000/mcp",
      "headers": { "authorization": "Bearer ${MCP_TOKEN}" },
      "query_params": {},
      "timeout_seconds": 30
    }
  ]
}
```

字段说明：

- `server_id`：server 的逻辑 id（用于选择与工具名加前缀）
- `url`：MCP server 的 HTTP endpoint（只支持 `http://` / `https://`）
- `headers` / `query_params`：转发时注入（可用于鉴权）
- `timeout_seconds`：覆盖默认超时（默认 300s）

兼容性补充：

- `url` 也接受别名字段 `http_url`（迁移/对齐时更顺手）
- 上述字段支持 `${ENV}` / `os.environ/ENV` / `secret://...`（env/secret 缺失会启动失败，避免 silent misconfig）

---

## 2) 作为 MCP Proxy 使用（/mcp）

### 2.1 tools/list

默认会聚合 **全部** 已配置的 MCP servers：

```bash
curl -sS http://127.0.0.1:8080/mcp/tools/list \
  -H 'content-type: application/json' \
  -d '{"servers":["local"]}'
```

也可以直接走 MCP JSON-RPC：

```bash
curl -sS http://127.0.0.1:8080/mcp \
  -H 'content-type: application/json' \
  -d '{"jsonrpc":"2.0","id":1,"method":"tools/list","params":{}}'
```

性能说明：

- Ditto 会对每个 MCP server 的 `tools/list` 结果做短 TTL 缓存（默认 60s），减少把 MCP tools 融合进 `/v1/chat/completions` 与 `/v1/responses` 时的额外 RTT。

### 2.2 tools/call

```bash
curl -sS http://127.0.0.1:8080/mcp/tools/call \
  -H 'content-type: application/json' \
  -d '{"server_id":"local","name":"hello","arguments":{"who":"world"}}'
```

---

## 3) 选择 MCP servers（多 server 支持）

默认行为：未显式指定时，会使用 **全部** `mcp_servers`。

显式指定 server 的方式（任选其一）：

- HTTP header：`x-mcp-servers: local,github`
- URL path selector：
  - `/mcp/local,github`
  - `/local,github/mcp`

当一次选择多个 servers 时，为了避免工具名冲突，Ditto 会给工具名加前缀：

- `hello` → `local-hello`

随后 `tools/call` 也需要用同样的前缀形式（`<server_id>-<tool_name>`）。

---

## 4) 在 /v1/chat/completions / /v1/responses 中使用 MCP tools

Ditto 支持 LiteLLM 风格的请求写法：在 `tools` 数组中放入 `type: "mcp"` 的条目。

最小示例：

```json
{
  "model": "gpt-4o-mini",
  "messages": [{ "role": "user", "content": "Call hello tool." }],
  "tools": [
    {
      "type": "mcp",
      "server_url": "litellm_proxy/mcp/local",
      "allowed_tools": ["hello"]
    }
  ]
}
```

行为：

- Ditto 会对选中的 MCP server(s) 执行 `tools/list`
- 将 MCP tool schema 转换为 OpenAI `function` tools
- 把转换后的 `tools` 发送给 upstream（passthrough 或 translation backend）

### 4.1 自动执行（require_approval: "never"）

当 **所有** MCP tool config 中都包含：

```json
{ "type": "mcp", "require_approval": "never" }
```

Ditto 会做一个最小 tool loop（对齐 LiteLLM 的默认行为）：

1) 先用 `stream=false` 调一次对应端点（`/v1/chat/completions` 或 `/v1/responses`）获取 tool calls
2) 逐个调用 MCP `tools/call`
3) 把结果回填后再发起一次最终请求（最终请求的 `stream` 会保持和原请求一致）

### 4.2 多步 tool loop（max_steps）

在 `require_approval: "never"` 的基础上，你可以用 `max_steps` 扩展为多步：

```json
{ "type": "mcp", "require_approval": "never", "max_steps": 2 }
```

语义：

- `max_steps` 表示 Ditto 最多自动执行多少轮 tool calls（默认 `1`，最大 `8`）
- 当模型在 follow-up 里再次产生 tool calls，Ditto 会继续执行，直到：
  - 没有新的 tool calls，或
  - 达到 `max_steps` 上限（此时会把包含 tool calls 的响应原样返回给客户端）

已知限制（务实口径）：

- `POST /v1/chat/completions`：`max_steps` 对 `stream=true/false` 都生效（但 `stream=true` 可能会导致额外的 upstream 调用）
- `POST /v1/responses`：
  - upstream 支持 `/v1/responses` 时：`max_steps` 仅对 `stream=false` 生效（避免重复提交非幂等的 `/responses` continuation）
  - upstream 不支持 `/v1/responses`、走 shim fallback（`/chat/completions` → `/responses`）时：`max_steps` 生效

---

## 5) 鉴权（Virtual Keys）

如果你的 `gateway.json` 里配置了 `virtual_keys`（即非空），那么：

- `/mcp*` 端点同样需要 virtual key
- 兼容以下 header（优先级从高到低）：
  1) `x-litellm-api-key`（支持 `Bearer ...` 前缀）
  2) `Authorization: Bearer ...`
  3) `x-ditto-virtual-key`
  4) `x-api-key`

---

## 6) 已实现范围与差异（务实口径）

Ditto 的 MCP gateway 当前聚焦在“让 MCP tools 能跑起来”：

- ✅ HTTP JSON-RPC：`initialize` / `tools/list` / `tools/call`
- ✅ LiteLLM-like 路由：`/mcp`、`/mcp/<servers>`、`/<servers>/mcp`、`x-mcp-servers`
- ✅ tools → OpenAI function tools 转换（`/v1/chat/completions`）
- ✅ `allowed_tools`（请求级过滤；支持带/不带 `<server_id>-` 前缀）

未覆盖项（如果你需要，可以作为后续切片推进）：

- per-key/team/org 的 MCP 权限管理、`allowed_params` 等更细粒度策略（LiteLLM 有更完整的控制面）
- streaming cache / 更复杂的审批流

================================================================================
FILE: docs/src/gateway/auth.md
================================================================================

# 鉴权：Virtual Keys 与 Admin Token

Ditto Gateway 的鉴权分两层：

- **Virtual Keys**：给“业务调用方/客户端”使用，作用于 `/v1/*` 与 `POST /v1/gateway`，以及 Ditto 暴露的 MCP/A2A/Anthropic/Google 兼容端点（例如 `/mcp*`、`/a2a/*`、`/messages`、`/v1beta/models/*`）。
- **Admin Token**：给“运维/平台管理员”使用，作用于 `/admin/*`（仅在显式启用时挂载）。

本文以网关实现为准（见 `src/gateway/config.rs`、`src/gateway/http/core.rs`、`src/gateway/http/openai_compat_proxy.rs`、`src/gateway/http/admin/auth.rs`）。

---

## 1) Virtual Keys（面向客户端）

### 什么时候会启用？

当 `gateway.json` 中 `virtual_keys` **非空**时：

- `/v1/*` passthrough proxy 会要求客户端提供 virtual key（否则 401）。
- `/mcp*`、`/a2a/*`、`/messages`、`/v1beta/models/*` 等兼容端点同样会要求 virtual key（用于统一的限流/预算/审计归因）。
- 客户端提供的 key 会绑定到一个 `VirtualKeyConfig`，并作为 **策略单位**：limits/budget/cache/guardrails/routing/审计归因等。

当 `virtual_keys` 为空时：

- `/v1/*` passthrough 不做 Ditto 层鉴权，客户端的 `Authorization` 会按原样转发到 upstream（除非被你自己的反向代理拦截）。

### Key 如何匹配？

- Key 的“秘密值”是 `VirtualKeyConfig.token`。
- 匹配方式是 **字符串全等**（不是 hash、不是前缀匹配）。
- `enabled=false` 的 key 视为不可用（401）。

### 客户端如何携带 Virtual Key？

对 OpenAI-compatible passthrough：`ANY /v1/*`

- `Authorization: Bearer <virtual_key>`
- `x-litellm-api-key: Bearer <virtual_key>`（也接受不带 `Bearer` 的纯 token）
- `x-ditto-virtual-key: <virtual_key>`
- `x-api-key: <virtual_key>`

对控制面 demo：`POST /v1/gateway`

- JSON body 的 `virtual_key` 字段（可选）
- `Authorization: Bearer <virtual_key>`
- `x-litellm-api-key: Bearer <virtual_key>`（也接受不带 `Bearer` 的纯 token）
- `x-ditto-virtual-key: <virtual_key>`
- `x-api-key: <virtual_key>`

### 启用 Virtual Keys 后：Upstream 的真实鉴权怎么做？

当 `virtual_keys` 非空时，Ditto 会把客户端提供的 `authorization` / `x-api-key` / `x-litellm-api-key` 当作 virtual key 使用，并在转发 upstream 前做清理（见 `sanitize_proxy_headers`），以避免把虚拟 key 泄露到上游。

因此 upstream 的鉴权必须来自：

- `backends[].headers` / `backends[].query_params`（passthrough upstream）
- `backends[].provider_config.auth`（translation backend）

建议写成 `${ENV_VAR}`，并用 `--dotenv` 或运行环境变量注入：

```json
{
  "backends": [
    {
      "name": "openai",
      "base_url": "https://api.openai.com/v1",
      "headers": { "authorization": "Bearer ${OPENAI_API_KEY}" }
    }
  ],
  "virtual_keys": [
    { "id": "vk-dev", "token": "${DITTO_VK_DEV}", "enabled": true, "limits": {}, "budget": {}, "cache": {}, "guardrails": {}, "passthrough": { "allow": true, "bypass_cache": true }, "route": null }
  ],
  "router": { "default_backends": [{ "backend": "openai", "weight": 1.0 }], "rules": [] }
}
```

### 归因字段（可选，但推荐）

`VirtualKeyConfig` 还支持：

- `tenant_id` / `project_id` / `user_id`：为审计与预算分组提供归因信息（见「预算与成本」与「Admin API」）。
- `route`：把该 key 的请求 **固定路由**到某个 backend（绕过 router rules，见「路由」）。

---

## 2) Admin Token（面向管理员）

### 什么时候会启用？

只有当你在启动 `ditto-gateway` 时显式设置：

- `--admin-token <TOKEN>` 或
- `--admin-token-env <ENV_NAME>`（可配合 `--dotenv`）
- `--admin-read-token <TOKEN>` 或
- `--admin-read-token-env <ENV_NAME>`（可配合 `--dotenv`）

才会挂载 `/admin/*` 路由（见 `src/gateway/http/core.rs`）。

> 未配置 admin token 时，`/admin/*` 直接 404，这比“暴露出来但永远 401”更不容易被误用。

### 读写权限（RBAC-lite）

Ditto 目前不实现完整 RBAC/SSO，但提供一个“足够企业落地”的最小切片：

- **Write token（运维写）**：`--admin-token` / `--admin-token-env`
  - 允许所有 `/admin/*`（包含写操作）。
- **Read token（只读）**：`--admin-read-token` / `--admin-read-token-env`
  - 仅允许只读的 `/admin/*`（例如 `GET /admin/keys`、`GET /admin/audit`、`GET /admin/budgets*`、`GET /admin/costs*`、`GET /admin/backends`）。
  - 当你只配置 read token（不配置 write token）时，写端点不会挂载（404）。

实践建议：把 read token 用于 dashboard/报表/审计查看，把 write token 只给少数运维人员或自动化发布系统。

### 管理请求如何携带 Admin Token？

支持两种等价方式（见 `src/gateway/http/admin/auth.rs`）：

- `Authorization: Bearer <admin_token>`
- `x-admin-token: <admin_token>`

---

## 3) 最佳实践（生产建议）

- 不要把 token 明文写进 `gateway.json`；用 `${ENV_VAR}` + `--dotenv` / K8s Secret 注入。
- `/admin/*` 建议只在内网开放，或由反向代理加一层 IP allowlist / mTLS。
- Virtual key 是“对外 API key”，应支持轮换：优先通过 Admin API 做 key 的 upsert/delete，并配合 `--state`/`--sqlite`/`--redis` 持久化。
- 不要把 virtual key/token 打进日志；Ditto 在 `GET /admin/keys` 默认会对 token 做 `redacted`。

================================================================================
FILE: docs/src/gateway/routing.md
================================================================================

# 路由：Weighted / Fallback / Retry

本页覆盖两类“路由”：

1) **RouterConfig（静态路由）**：按 `model` 选择 backend，支持 rule + 权重 + fallback（见 `src/gateway/router.rs`）。  
2) **Proxy routing（运行时鲁棒性）**：重试 / 熔断 / 健康检查（feature `gateway-routing-advanced`，见 `src/gateway/proxy_routing.rs` 与 `src/gateway/http/proxy/core.rs`）。

---

## 1) RouterConfig：按模型选择 backend

### 配置结构

`gateway.json` 的 `router` 是 `RouterConfig`：

```json
{
  "router": {
    "default_backends": [{ "backend": "primary", "weight": 1.0 }],
    "rules": []
  }
}
```

- `default_backends`：支持权重的默认候选集（会选出主 backend，并附带 fallback 顺序）。
- `rules[]`：按 `model_prefix` 覆盖路由；每条 rule 也可以用单 backend 或 weighted backends。

### Rule 匹配规则

- 默认：`model_prefix` 是前缀匹配：`model.starts_with(model_prefix)`。
- 兼容：如果 `model_prefix` 以 `*` 结尾（例如 `anthropic/*`），Ditto 会忽略 `*` 并按前缀匹配。
- 可选：如果 rule 设置了 `"exact": true`，则变为精确匹配：`model == model_prefix`。
- 优先级：**exact rules 优先于 prefix rules**；同一类里仍是“第一条匹配生效”（按 `rules` 数组顺序）。

### Weighted 选择与 deterministic fallback 顺序

当你配置 `backends: [{backend, weight}, ...]` 时：

- Ditto 会对候选集做 **确定性**的加权选择（FNV-1a hash + weight 区间）。
- 返回结果不是“只返回一个 backend”，而是一个 **有序列表**：
  - 第一个是选中的“主 backend”
  - 后面的元素是去重后的 fallback 顺序（用于失败时尝试下一个）

这使得你可以写出 “9:1” 的主备分流，同时在主后端故障时有自然的 fallback。

示例：

```json
{
  "router": {
    "default_backends": [
      { "backend": "primary", "weight": 9 },
      { "backend": "backup", "weight": 1 }
    ],
    "rules": [
      {
        "model_prefix": "gpt-4",
        "backends": [
          { "backend": "primary", "weight": 9 },
          { "backend": "backup", "weight": 1 }
        ]
      }
    ]
  }
}
```

### VirtualKeyConfig.route：固定路由（绕过规则）

如果某个 virtual key 设置了 `route: "<backend_name>"`：

- 该 key 的请求会直接路由到这个 backend
- router 的 `rules` 不再对它生效（包括 per-route 的 guardrails 覆盖）

这适合做：

- “VIP key” 固定走高配 backend
- 灰度 key 固定走新 upstream

---

## 2) Per-route Guardrails：按 model_prefix 覆盖策略

`RouteRule` 可以携带 `guardrails`：

```json
{
  "model_prefix": "gpt-4",
  "backends": [{ "backend": "primary", "weight": 1 }],
  "guardrails": {
    "allow_models": ["gpt-4*"],
    "deny_models": ["gpt-4o-realtime*"],
    "block_pii": true,
    "validate_schema": true
  }
}
```

实际生效逻辑：

- 先匹配到 rule 后，如果 rule 有 `guardrails`，则以它为准
- 否则回退到 `VirtualKeyConfig.guardrails`

---

## 3) Retry / Circuit Breaker / Health Checks（可选）

需要启用 feature `gateway-routing-advanced`，并在启动时通过 CLI 打开对应开关：

- `--proxy-retry` / `--proxy-retry-status-codes` / `--proxy-retry-max-attempts`
- `--proxy-circuit-breaker` / `--proxy-cb-failure-threshold` / `--proxy-cb-cooldown-secs`
- `--proxy-health-checks` / `--proxy-health-check-*`

这些选项会影响 `/v1/*` passthrough 的“backend 候选集如何被尝试/过滤”。

### 3.1 Retry（按状态码/网络错误）

默认 retry 状态码（可覆盖）：`429, 500, 502, 503, 504`（见 `ProxyRetryConfig`）。

重要细节：

- `max_attempts` 的默认值是 “候选 backend 数量”（即最多尝试一遍 fallback 列表）
- 只有当启用 retry 时才会对“失败”继续尝试下一个 backend

### 3.2 Circuit Breaker（按连续失败）

熔断器默认配置（可覆盖）：

- `failure_threshold = 3`
- `cooldown_seconds = 30`

计数策略（见 `FailureKind`）：

- 网络错误会计入失败
- retryable status 里 **只有 5xx** 会计入失败（例如 429 不计入熔断）

### 3.3 Health Checks（主动探活）

健康检查默认配置（可覆盖）：

- `path = /v1/models`
- `interval_seconds = 10`
- `timeout_seconds = 2`

实现细节：

- 健康检查以后台任务形式运行；当 `ditto-gateway` 退出/被 drop 时会自动取消，避免进程内残留任务。

启用后，gateway 会对每个 backend 定期发起 `GET <path>`：

- 2xx → healthy
- 非 2xx 或请求错误 → unhealthy

不健康的 backend 会在候选集中被过滤（若过滤后为空，则仍会回退到原候选集，避免“全拒绝”）。

### 3.4 运维接口：查看/重置 backend health

开启 admin token + `gateway-routing-advanced` 后：

- `GET /admin/backends`：返回每个 backend 的 health snapshot（连续失败、熔断到期、上次健康检查等）
- `POST /admin/backends/:name/reset`：清除某个 backend 的 health 状态（立刻视为健康）

---

## 4) 常见路由策略（建议）

- **主备（9:1）+ fallback**：用 weighted backends；失败自动落到 backup。
- **按模型族路由**：用 `rules[].model_prefix` 把 `gpt-4*`、`claude-*` 分流到不同 upstream。
- **按 key 固定路由**：用 `VirtualKeyConfig.route` 做灰度/专线。

下一步建议：

- 「预算与成本」：理解“路由之后如何计费/预算/预留”
- 「部署：多副本与分布式」：理解多副本下路由与 store 的关系

================================================================================
FILE: docs/src/gateway/budgets-and-costing.md
================================================================================

# 预算与成本（Tokens / USD）

本页解释 Ditto Gateway 的“配额治理”三件套：

1) **Limits（速率限制）**：rpm / tpm（`LimitsConfig`，内存实现）。  
2) **Budget（token 预算）**：`BudgetConfig.total_tokens`。  
3) **Cost budget（美元预算，可选）**：`BudgetConfig.total_usd_micros` + pricing table（feature `gateway-costing`）。

实现位置：

- `src/gateway/limits.rs`
- `src/gateway/budget.rs`
- `src/gateway/costing.rs`（可选）
- `/v1/*` proxy 预算预留：`src/gateway/http/openai_compat_proxy.rs` + `src/gateway/http/proxy/budget_reservations.rs`

---

## 1) Limits：rpm / tpm（默认进程内；Redis 可分布式）

每个 `VirtualKeyConfig` 都有 `limits`：

```json
{
  "limits": { "rpm": 60, "tpm": 20000 }
}
```

- `rpm`：每分钟请求数上限
- `tpm`：每分钟 token 上限（token 计算见下文）

实现有两种模式：

- **不启用 store / 使用 sqlite**：进程内计数（按分钟窗口滚动），单实例可用；多副本下每个副本各算各的，不等价于全局限流。
- **使用 redis store**（`gateway-store-redis` + `--redis`）：通过 Redis 原子计数实现 **全局一致** 的 rpm/tpm（按 virtual key id 维度；窗口=分钟；计数 key 带 TTL，避免无界增长）。

> 如果你需要更复杂的策略（滑动窗口、按 IP、按 route 分组等），仍建议外层 API gateway 承接；Ditto 也会在后续里程碑继续扩面（见 Roadmap）。

### 1.1 Tenant/Project/User shared limits（可选）

除了 key 自身的 `limits` 外，你还可以配置“聚合限流”（多个 key 共享一个限流桶）：

- `tenant_id` + `tenant_limits`
- `project_id` + `project_limits`
- `user_id` + `user_limits`

当启用 redis store 时，上述 shared limits 也会变成 **多副本全局一致** 的限流。

示例：

```json
{
  "id": "vk-1",
  "token": "${VK_1}",
  "enabled": true,
  "tenant_id": "tenant-a",
  "tenant_limits": { "rpm": 600, "tpm": 200000 },
  "project_id": "proj-a",
  "project_limits": { "rpm": 120, "tpm": 40000 },
  "user_id": "user-42",
  "user_limits": { "rpm": 30, "tpm": 8000 },
  "limits": { "rpm": 60, "tpm": 20000 }
}
```

---

## 2) Token Budget：`total_tokens`

`VirtualKeyConfig.budget.total_tokens` 控制“总 token 额度”：

```json
{
  "budget": { "total_tokens": 5000000 }
}
```

一条请求的 **charge_tokens**（计费 token）在 `/v1/*` proxy 中按以下方式估算：

- `input_tokens_estimate`：
  - 若启用 `gateway-tokenizer`：尽量用 tiktoken 对 OpenAI 请求做 token 估算
  - 否则：fallback 为 `body_bytes_len / 4` 的粗估
- `charge_tokens = input_tokens_estimate + max_output_tokens`

其中 `max_output_tokens` 会从请求 JSON 中抽取（若缺失则按内部默认值处理）。

### 2.1 Tenant/Project/User 预算（可选）

除了 key 自身预算外，Ditto 支持额外的“聚合预算”：

- `tenant_id` + `tenant_budget`
- `project_id` + `project_budget`
- `user_id` + `user_budget`

示例：

```json
{
  "id": "vk-1",
  "token": "${VK_1}",
  "enabled": true,
  "tenant_id": "tenant-a",
  "project_id": "proj-a",
  "user_id": "user-42",
  "tenant_budget": { "total_tokens": 5000000 },
  "project_budget": { "total_tokens": 1000000 },
  "user_budget": { "total_tokens": 200000 },
  "budget": { "total_tokens": 5000000 },
  "limits": {},
  "cache": {},
  "guardrails": {},
  "passthrough": { "allow": true, "bypass_cache": true },
  "route": null
}
```

一条请求会同时消耗：

- key 预算（scope：`<key.id>`）
- tenant 预算（scope：`tenant:<tenant_id>`）
- project 预算（scope：`project:<project_id>`）
- user 预算（scope：`user:<user_id>`）

只要任意一个 scope 超额，就会被拒绝（OpenAI 风格错误：HTTP 402 `insufficient_quota`）。

---

## 3) 持久化预算：sqlite / redis（推荐用于生产）

当你启用 store（`--sqlite` 或 `--redis`）时，`/v1/*` proxy 会切换到“预算预留 + 结算”模式：

- **预留（reserve）**：在请求进入 upstream 前，按 `charge_tokens` 先把额度预留起来（避免并发穿透）。
- **结算（commit/rollback）**：请求结束后，根据是否成功、以及是否能观测到真实 usage，提交或回滚预留。

为什么需要预留？

- streaming 场景下，最终 usage 可能要到最后一个 chunk 才出现
- 并发场景下，不预留会导致“同时通过检查 → 同时超额”

实现细节：

- reservation id 基于 `request_id`：
  - key 预算：`<request_id>`
  - tenant/project/user 预算：`<request_id>::budget::<scope>`
- redis 预留记录**不会静默过期**：过期会丢失“回收 reserved 的唯一信息源”，从而让 ledger 永久卡死（预算被永久占用）。
  - 如需运维回收陈旧预留，请使用 Admin API：`POST /admin/reservations/reap`（支持 `dry_run`/`limit`/`older_than_secs`）。
  - 建议把 `older_than_secs` 设得足够保守（例如 24h），避免误伤超长 streaming 请求。

### 3.1 sqlite vs redis 的选择

- `--sqlite <path>`：单机持久化（重启不丢），不支持多副本共享。
- `--redis <url> [--redis-prefix p]`：多副本共享（推荐用于分布式部署）。

---

## 4) Cost Budget：`total_usd_micros`（可选）

### 4.1 启用条件

要启用“美元预算”，需要同时满足：

- 编译启用 feature `gateway-costing`
- 运行时通过 `--pricing-litellm <path>` 加载 LiteLLM 风格的 pricing JSON
- 你的 key/tenant/project/user budget 中至少一个设置了 `total_usd_micros`

示例（1 美元 = 1_000_000 micros）：

```json
{ "budget": { "total_usd_micros": 1000000 } }
```

如果配置了 cost budget 但没有 pricing table，Ditto 会返回 500（`pricing_not_configured`），避免 silently 不计费。

### 4.2 估算策略（best-effort）

Ditto 会对请求做 cost 估算：

- 以请求的 `model` 为主
- 若某个 backend 配置了 `model_map`，并且 pricing 表里存在映射后的 model，则会取“更保守”的估算（在多个 backend 候选时取 max）
- 支持 LiteLLM 的 prompt-cache 成本字段（若响应 usage 提供）
- 支持 `service_tier`（若请求带该字段且 pricing 支持）

与 token 预算类似，cost 预算在启用 store 后也会“预留 + 结算”，并可在 `/admin/costs*` 查看 ledger。

### 4.3 适用端点（重要）

Ditto 的 cost budget 基于 **token 定价**（LiteLLM pricing JSON 的 `*_cost_per_token` / `*_cost_per_1k_tokens` 等字段），因此只对“token 口径”端点有意义：

- ✅ `POST /v1/chat/completions`
- ✅ `POST /v1/responses`（含 Ditto 的 shim fallback）
- ✅ `POST /v1/completions`
- ✅ `POST /v1/embeddings`
- ✅ `POST /v1/moderations`
- ✅ `POST /v1/rerank`

对于非 token 计费端点（例如 images/audio/batches 等），Ditto 在检测到任意 scope 配置了 `total_usd_micros` 时会直接拒绝请求（`cost_budget_unsupported_endpoint`），避免“误计费/绕过治理”。

例外：`POST /v1/files` 与所有非 `POST` 请求会被视为 **0 成本**（仍可能受 rpm/tpm/token budget 约束）。

---

## 5) 建议的生产配置组合

- 需要稳定的 token 预算：启用 `gateway-store-redis` 或 `gateway-store-sqlite`
- 需要多副本一致：优先 `gateway-store-redis`
- 需要美元预算：再加 `gateway-costing` + `--pricing-litellm`
- 需要更准确 token 估算：再加 `gateway-tokenizer`

下一步：

- 「缓存」：理解预算与缓存（cache hit 是否计费）之间的边界
- 「Admin API」：如何查看 ledger / audit / 动态管理 keys

================================================================================
FILE: docs/src/gateway/caching.md
================================================================================

# 缓存：Control-plane / Proxy Cache

Ditto Gateway 有两类缓存，面向不同使用场景：

1) **Control-plane cache**：只作用于 `POST /v1/gateway`（demo/控制面端点）。  
2) **Proxy cache**：作用于 OpenAI-compatible passthrough `ANY /v1/*`（非 streaming 响应）。

实现位置：

- Control-plane：`src/gateway/cache.rs` + `src/gateway/mod.rs`
- Proxy cache：`src/gateway/proxy_cache.rs` + `src/gateway/http/proxy/core.rs` + `src/gateway/redis_store/virtual_keys_and_proxy_cache.rs`

---

## 1) Control-plane cache（/v1/gateway）

### 如何开启？

在某个 `VirtualKeyConfig` 下：

```json
{
  "cache": {
    "enabled": true,
    "ttl_seconds": 60,
    "max_entries": 1024,
    "max_body_bytes": 1048576,
    "max_total_body_bytes": 67108864
  }
}
```

缓存 key 由如下信息组成（并包含 prompt hash）：

- key id
- model / input_tokens / max_output_tokens
- prompt 的 hash 与长度

### 什么时候会绕过？

`POST /v1/gateway` 有一个 `passthrough` 布尔字段；并且 key 上有：

- `passthrough.allow`
- `passthrough.bypass_cache`

当请求 `passthrough=true` 且 key 允许 passthrough 且 `bypass_cache=true` 时，会绕过 control-plane cache。

> 这套语义主要用于 demo 端点，生产建议更多使用 `/v1/*` passthrough 或 translation。

### 内存安全（体积上限）

Control-plane cache 是 **进程内存缓存**。为了避免把进程内存打爆，Ditto 会对缓存写入施加硬上限：

- `max_body_bytes`：单条响应（`GatewayResponse.content`）最大可缓存字节数，超过则跳过缓存
- `max_total_body_bytes`：单个 scope（virtual key）下的总缓存字节预算，超过则按 LRU 驱逐

---

## 2) Proxy cache（/v1/*）

### 2.1 启用条件

Proxy cache 需要：

- 编译启用 feature `gateway-proxy-cache`
- 运行时添加 `--proxy-cache`（或设置 `--proxy-cache-ttl/--proxy-cache-max-entries`）

常用启动例子：

```bash
cargo run --features "gateway gateway-proxy-cache" --bin ditto-gateway -- ./gateway.json \
  --proxy-cache \
  --proxy-cache-ttl 60 \
  --proxy-cache-max-entries 2048 \
  --proxy-cache-max-body-bytes 1048576 \
  --proxy-cache-max-total-body-bytes 67108864
```

> `--proxy-cache-max-body-bytes` 会跳过缓存“过大的响应”（包含 memory 与 redis L2）；`--proxy-cache-max-total-body-bytes` 用于限制内存总缓存体积，避免内存被打爆。

> 注意：`--proxy-cache-max-body-bytes` 只影响“缓存写入”的上限；Ditto 为了从 JSON 响应解析 `usage` 做更准的 token/cost 结算，另外提供 `--proxy-usage-max-body-bytes`（默认 1MiB）作为独立上限，避免把 cache 上限调大后导致 usage 缓冲也被动变大。

另外，为避免把大响应整段读入内存，Ditto 对 proxy 的“缓冲读取”采用**有界策略**：若 upstream 提供 `content-length` 且不超过上限，则缓冲并用于（a）写入 proxy cache 或（b）从 JSON 解析 `usage`；若 upstream 未提供 `content-length`，Ditto 会最多预读到上限（逐步累积，不会因为 chunk 切分过细造成额外内存放大），只有当响应在上限内结束时才会写入 cache/解析 usage；超过上限会切换为流式转发并跳过缓存/usage 解析。

### 2.2 缓存范围（What gets cached）

Ditto 只会缓存：

- 方法：`GET` / `POST`
- 响应：**非** `text/event-stream`（也就是非 streaming）
- 状态：2xx（成功响应）

因此：

- `POST /v1/chat/completions`（非 streaming）可以被缓存
- `POST /v1/chat/completions`（stream=true）不会被缓存
- `GET /v1/models` 可以被缓存

### 2.3 Cache key 与 scope（重要）

Proxy cache key 由以下因素决定（见 `proxy_cache_key`）：

- HTTP method
- path（包含 `/v1/...`）
- body hash
- scope

scope 的选择规则（见 `proxy_cache_scope`）：

- 如果启用 virtual keys：scope = `vk:<virtual_key_id>`
- 否则：
  - 若请求带 `Authorization`：scope = `auth:<hash>`
  - 否则若请求带 `x-api-key`：scope = `x-api-key:<hash>`
  - 否则：`public`

这能避免不同 key/不同上游 token 之间的缓存串用。

### 2.4 如何绕过 proxy cache

任一条件成立即 bypass：

- 请求头包含 `x-ditto-cache-bypass` 或 `x-ditto-bypass-cache`
- `Cache-Control` 包含 `no-store` 或 `no-cache`

> 注意：Ditto 会在转发 upstream 前移除这些 Ditto 私有 header，避免污染上游。

### 2.5 命中时的响应头

当 proxy cache 命中时，你会看到：

- `x-ditto-cache: hit`
- `x-ditto-cache-key: <cache_key>`
- `x-ditto-cache-source: memory|redis`（若同时启用 redis store）

---

## 3) Redis 共享缓存（多副本）

当你同时启用：

- feature `gateway-store-redis`
- 运行时 `--redis <url>`

proxy cache 会：

- 仍写入本机内存（L1）
- 同时写入 redis（L2，共享）

命中时会返回 `x-ditto-cache-source` 指示来源。

---

## 4) 管理：清理缓存（Admin API）

启用 admin token + proxy cache 后：

- `POST /admin/proxy_cache/purge`
  - `{ "all": true }`：清理全部
  - `{ "cache_key": "ditto-proxy-cache-v1-..." }`：按 key 清理

如果启用 redis store，会同时清理 redis 中的记录，并在响应里返回 `deleted_redis`（删除条数）。

---

## 5) 使用建议（好品味版）

- 不要对 streaming 响应做缓存：语义复杂且容易引入“半截缓存”问题；Ditto 直接选择不缓存。
- 对大响应（例如 files/audio download）谨慎开启缓存：它会占用内存与 redis 带宽。
- 如果你需要“更像 CDN 的缓存”，建议把 `/v1/*` 放到边缘缓存层做细粒度策略，Ditto 负责控制面与路由治理。

================================================================================
FILE: docs/src/gateway/storage.md
================================================================================

# 存储：state / sqlite / redis

Ditto Gateway 的“存储”主要用于两类数据：

- **配置态（virtual keys）**：允许用 Admin API 动态增删改 key，并在重启后保留。
- **运行态（审计/预算/成本/缓存）**：用于运维观测与多副本一致性（视 feature 而定）。

启动参数解析见 `src/bin/ditto-gateway.rs`，核心约束是：

> **只能选择一种存储后端**：`--state`、`--sqlite`、`--redis` 三选一。

---

## 1) 不启用存储（默认）

行为：

- virtual keys 只来自 `gateway.json`
- Admin API（如果启用）对 key 的变更只存在于内存，重启会丢
- `/v1/*` proxy 的预算：
  - 没有 store 时使用内存预算（并发下可能穿透；不会跨实例共享）

适用：

- 本地开发
- 单实例、无治理需求的简易 passthrough

---

## 2) `--state <path>`：JSON state file（只存 keys）

启用方式：

```bash
cargo run --features gateway --bin ditto-gateway -- ./gateway.json --state ./gateway.state.json
```

行为（启动时）：

- 若文件存在：读取 `GatewayStateFile.virtual_keys` 覆盖 `gateway.json` 里的 keys
- 若文件不存在：用 `gateway.json` 里的 keys 初始化并写入文件

特性：

- 只持久化 **virtual keys**
- 不持久化预算 ledger / 审计 / proxy cache
- 不支持多副本共享（每个实例各写各的，容易冲突）

适用：

- 单机部署，想要“Admin API 修改 key 可持久化”的最小方案

---

## 3) `--sqlite <path>`：单机持久化（keys + ledger + audit）

前置：

- 编译启用 feature `gateway-store-sqlite`

启用方式：

```bash
cargo run --features "gateway gateway-store-sqlite" --bin ditto-gateway -- ./gateway.json \
  --sqlite ./ditto-gateway.sqlite
```

行为（启动时）：

- 如果 sqlite 文件已存在：从 sqlite 载入 keys 覆盖 `gateway.json`
- 如果 sqlite 文件不存在：用 `gateway.json` 的 keys 初始化 sqlite

可存内容（视功能而定）：

- virtual keys（Admin API upsert/delete 的来源与落盘）
- audit logs（`/admin/audit`）
- token budgets ledger（`/admin/budgets*`）
- cost budgets ledger（`/admin/costs*`，需要 `gateway-costing`）
  - 建议根据合规需求配置 `--audit-retention-secs`（默认 30 天），避免审计日志无限增长（见下文）

限制：

- 不支持多副本共享（仍是单机）

适用：

- 单机部署但需要“预算/审计可追溯”

---

## 4) `--redis <url>`：分布式共享存储（推荐）

前置：

- 编译启用 feature `gateway-store-redis`

启用方式：

```bash
cargo run --features "gateway gateway-store-redis" --bin ditto-gateway -- ./gateway.json \
  --redis redis://127.0.0.1:6379 --redis-prefix ditto
```

也可以从 env 读取（配合 `--dotenv`）：

```bash
cargo run --features "gateway gateway-store-redis" --bin ditto-gateway -- ./gateway.json \
  --dotenv .env --redis-env REDIS_URL --redis-prefix ditto
```

行为（启动时）：

- Ditto 会先 `PING` redis
- 若 redis 里已有 keys：以 redis 为准覆盖 `gateway.json`
- 若 redis 里没有 keys：用 `gateway.json` 初始化写入 redis

可存内容：

- virtual keys（共享）
- audit logs（共享）
- token/cost budgets ledger（共享，支持多副本预算一致）
- proxy cache（若启用 `gateway-proxy-cache`，会作为 L2 共享缓存）
  - 建议根据合规需求配置 `--audit-retention-secs`（默认 30 天），避免审计日志无限增长（见下文）

适用：

- 多副本/高可用部署（同一套 keys/budgets/audit 需要全局一致）

---

## 5) 选型建议

- 只想“Admin API 修改 key 可持久化”：`--state`（最小）
- 单机但想要 ledger/audit：`--sqlite`
- 多副本/分布式：`--redis`（推荐）

下一步：

- 「部署：多副本与分布式」：如何把 redis store 用在实际部署拓扑里

---

## 6) 审计日志保留期（强烈建议）

当你启用 sqlite/redis store 并且开启审计（`/admin/audit`）时，建议配置：

- `--audit-retention-secs SECS`：只保留最近 `SECS` 秒的审计日志（sqlite/redis 都会按时间戳清理）

默认会按 30 天清理；如果你禁用清理（`--audit-retention-secs 0`），审计日志会随时间增长（取决于你的 QPS），可能导致 sqlite 文件或 redis 数据集不断变大。

================================================================================
FILE: docs/src/gateway/observability.md
================================================================================

# 观测：logs / Prometheus / OTel

Ditto Gateway 的观测分三层：

1) **响应头 + request id**：每个请求都能被定位与串联。  
2) **内置 metrics**：`GET /metrics`（JSON counters）与可选 Prometheus。  
3) **Tracing（可选）**：OpenTelemetry OTLP exporter（feature `gateway-otel`）。

实现位置：

- request id / 响应头：`src/gateway/http/proxy/core.rs`
- JSON metrics：`src/gateway/observability.rs` + `GET /metrics`
- Prometheus：`src/gateway/metrics_prometheus.rs` + `GET /metrics/prometheus`
- OTel：`src/gateway/otel.rs`

---

## 1) 请求链路：x-request-id 与 x-ditto-request-id

Ditto 会尽量保证每个响应都有可追踪的 request id：

- 若客户端提供 `x-request-id`，Ditto 会复用它
- 否则 Ditto 会生成一个 `ditto-<ts_ms>-<seq>` 风格的 id

响应里你会看到：

- `x-ditto-request-id: <id>`
- `x-request-id: <id>`（为了兼容下游链路）

并且 proxy 会附带：

- `x-ditto-backend: <backend_name>`

> 在排障时，请优先用 `x-ditto-request-id` 做全链路 grep。

---

## 2) JSON metrics：`GET /metrics`

返回 `ObservabilitySnapshot`（简单计数器）：

```json
{
  "requests": 123,
  "cache_hits": 10,
  "rate_limited": 2,
  "guardrail_blocked": 1,
  "budget_exceeded": 0,
  "backend_calls": 120
}
```

适用：

- 本地调试
- 简单 health/观测面板

限制：

- 指标粒度较粗
- 进程内计数（重启清零）

---

## 3) Prometheus metrics（可选）

前置：

- 编译启用 feature `gateway-metrics-prometheus`
- 运行时传 `--prometheus-metrics`

访问：

- `GET /metrics/prometheus`

### 控制指标基数（很重要）

Prometheus 的最大坑是“label 基数爆炸”。Ditto 提供一组上限参数：

- `--prometheus-max-key-series N`
- `--prometheus-max-model-series N`
- `--prometheus-max-backend-series N`
- `--prometheus-max-path-series N`

建议：

- 先用较小的上限跑在生产影子环境，观察 cardinality 再逐步放宽。

### 指标契约（Prometheus）

> 口径：以下是 Ditto Gateway **目前实现**的 Prometheus 指标族（`ditto_gateway_proxy_*`）。指标名与 label 我们会尽量保持稳定；如果需要破坏性调整，会在 `CHANGELOG.md` 里明确标注。

#### Labels 与基数控制

- `path`：不是原始 URL，而是**归一化后的 OpenAI 路径**（实现：`src/gateway/metrics_prometheus.rs` 的 `normalize_proxy_path_label`）。
  - 例如：`/v1/models/<id>` 会归一化为 `/v1/models/*`，未知路径会归一化为 `/v1/*`。
- `virtual_key_id`：未启用 virtual key 或未命中时为 `public`。
- `model`：仅在请求体里可解析到 `model` 时才打点。
- `backend` / `source` / `target` / `scope`：均做了基数上限控制。
- 当某个 label 维度超过 `--prometheus-max-*-series` 上限时，会把后续新值聚合到 `__overflow__`（避免把 Prometheus 打爆）。

#### Histogram buckets（duration）

`*_duration_seconds` 直方图使用固定 buckets（秒）：`0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10`。

#### Metrics（概览）

| Metric | Type | Labels | Meaning |
| --- | --- | --- | --- |
| `ditto_gateway_proxy_requests_total` | counter | - | 代理请求总数 |
| `ditto_gateway_proxy_requests_by_key_total` | counter | `virtual_key_id` | 按 virtual key id 分组的请求计数 |
| `ditto_gateway_proxy_requests_by_model_total` | counter | `model` | 按 model 分组的请求计数 |
| `ditto_gateway_proxy_requests_by_path_total` | counter | `path` | 按归一化 OpenAI 路径分组的请求计数 |
| `ditto_gateway_proxy_rate_limited_total` | counter | - | 触发限流的请求计数 |
| `ditto_gateway_proxy_rate_limited_by_key_total` | counter | `virtual_key_id` | 按 virtual key id 分组的限流计数 |
| `ditto_gateway_proxy_rate_limited_by_model_total` | counter | `model` | 按 model 分组的限流计数 |
| `ditto_gateway_proxy_rate_limited_by_path_total` | counter | `path` | 按 path 分组的限流计数 |
| `ditto_gateway_proxy_guardrail_blocked_total` | counter | - | 被 guardrail 拦截的请求计数 |
| `ditto_gateway_proxy_guardrail_blocked_by_key_total` | counter | `virtual_key_id` | 按 virtual key id 分组的 guardrail 拦截计数 |
| `ditto_gateway_proxy_guardrail_blocked_by_model_total` | counter | `model` | 按 model 分组的 guardrail 拦截计数 |
| `ditto_gateway_proxy_guardrail_blocked_by_path_total` | counter | `path` | 按 path 分组的 guardrail 拦截计数 |
| `ditto_gateway_proxy_budget_exceeded_total` | counter | - | 预算超限（token/USD）的请求计数 |
| `ditto_gateway_proxy_budget_exceeded_by_key_total` | counter | `virtual_key_id` | 按 virtual key id 分组的预算超限计数 |
| `ditto_gateway_proxy_budget_exceeded_by_model_total` | counter | `model` | 按 model 分组的预算超限计数 |
| `ditto_gateway_proxy_budget_exceeded_by_path_total` | counter | `path` | 按 path 分组的预算超限计数 |
| `ditto_gateway_proxy_request_duration_seconds` | histogram | `path` | 端到端代理请求耗时（按 path） |
| `ditto_gateway_proxy_request_duration_seconds_by_model` | histogram | `model` | 端到端代理请求耗时（按 model） |
| `ditto_gateway_proxy_responses_total` | counter | `status` | 按 HTTP status 分组的响应计数 |
| `ditto_gateway_proxy_responses_by_path_status_total` | counter | `path,status` | 按 path+status 分组的响应计数 |
| `ditto_gateway_proxy_responses_by_backend_status_total` | counter | `backend,status` | 按 backend+status 分组的响应计数 |
| `ditto_gateway_proxy_responses_by_model_status_total` | counter | `model,status` | 按 model+status 分组的响应计数 |
| `ditto_gateway_proxy_backend_attempts_total` | counter | `backend` | 后端尝试次数（含 fallback） |
| `ditto_gateway_proxy_backend_success_total` | counter | `backend` | 后端成功次数 |
| `ditto_gateway_proxy_backend_failures_total` | counter | `backend` | 后端失败次数（网络错误/可重试 status 等） |
| `ditto_gateway_proxy_backend_in_flight` | gauge | `backend` | 后端 in-flight 请求数（用于背压观测） |
| `ditto_gateway_proxy_backend_request_duration_seconds` | histogram | `backend` | 后端请求耗时（按 backend） |
| `ditto_gateway_proxy_stream_connections` | gauge | - | 当前活跃 SSE 流数量 |
| `ditto_gateway_proxy_stream_connections_by_backend` | gauge | `backend` | 按 backend 分组的活跃 SSE 流数量 |
| `ditto_gateway_proxy_stream_connections_by_path` | gauge | `path` | 按 path 分组的活跃 SSE 流数量 |
| `ditto_gateway_proxy_stream_bytes_total` | counter | - | SSE 流累计输出字节数（best-effort） |
| `ditto_gateway_proxy_stream_bytes_by_backend_total` | counter | `backend` | 按 backend 分组的 SSE 输出字节数 |
| `ditto_gateway_proxy_stream_bytes_by_path_total` | counter | `path` | 按 path 分组的 SSE 输出字节数 |
| `ditto_gateway_proxy_stream_completed_total` | counter | - | 正常完成的 SSE 流计数 |
| `ditto_gateway_proxy_stream_completed_by_backend_total` | counter | `backend` | 按 backend 分组的正常完成 SSE 流计数 |
| `ditto_gateway_proxy_stream_completed_by_path_total` | counter | `path` | 按 path 分组的正常完成 SSE 流计数 |
| `ditto_gateway_proxy_stream_errors_total` | counter | - | 出错结束的 SSE 流计数（含 timeout/断流等） |
| `ditto_gateway_proxy_stream_errors_by_backend_total` | counter | `backend` | 按 backend 分组的 SSE error 计数 |
| `ditto_gateway_proxy_stream_errors_by_path_total` | counter | `path` | 按 path 分组的 SSE error 计数 |
| `ditto_gateway_proxy_stream_aborted_total` | counter | - | 客户端提前断开导致的 SSE abort 计数（best-effort） |
| `ditto_gateway_proxy_stream_aborted_by_backend_total` | counter | `backend` | 按 backend 分组的 SSE abort 计数 |
| `ditto_gateway_proxy_stream_aborted_by_path_total` | counter | `path` | 按 path 分组的 SSE abort 计数 |
| `ditto_gateway_proxy_cache_lookups_total` | counter | - | proxy cache 查找次数 |
| `ditto_gateway_proxy_cache_lookups_by_path_total` | counter | `path` | 按 path 分组的 proxy cache 查找次数 |
| `ditto_gateway_proxy_cache_hits_total` | counter | - | proxy cache 命中次数 |
| `ditto_gateway_proxy_cache_hits_by_source_total` | counter | `source` | 按来源分组的命中次数（例如 memory/redis） |
| `ditto_gateway_proxy_cache_hits_by_path_total` | counter | `path` | 按 path 分组的命中次数 |
| `ditto_gateway_proxy_cache_misses_total` | counter | - | proxy cache 未命中次数 |
| `ditto_gateway_proxy_cache_misses_by_path_total` | counter | `path` | 按 path 分组的未命中次数 |
| `ditto_gateway_proxy_cache_stores_total` | counter | `target` | cache 写入次数（例如 memory/redis） |
| `ditto_gateway_proxy_cache_store_errors_total` | counter | `target` | cache 写入错误次数 |
| `ditto_gateway_proxy_cache_purges_total` | counter | `scope` | admin purge 次数（按 scope） |

### Dashboard / 告警模板

仓库内提供一套“开箱即用但不强绑定”的模板资产：

- Grafana dashboard：`deploy/grafana/ditto-gateway.dashboard.json`
- PrometheusRule（Prometheus Operator）：`deploy/prometheus/ditto-gateway-prometheusrule.yaml`

它们默认基于 Ditto 的 `ditto_gateway_proxy_*` 指标族（见 `GET /metrics/prometheus` 输出），你可以按自己平台的 label/job 约定做小幅调整。

---

## 4) 结构化 JSON 日志（轻量）

运行时传 `--json-logs` 后，Ditto 会把关键事件以 JSON 行写到 stderr（见 `emit_json_log`）。

注意：

- 日志 payload 会应用 `observability.redaction` 的统一脱敏策略（见「Gateway → 配置文件」的 `observability`）。
- 默认会替换 `authorization`/`token`/`api_key` 等字段，并对 `path/url/base_url/endpoint` 中的敏感 query 参数做 value 脱敏。

事件示例（概念）：

- `proxy.request` / `proxy.response` / `proxy.error`
- `proxy.blocked`（预算/存储错误导致的拦截）
- `gateway.request` / `gateway.response` / `gateway.error`（/v1/gateway demo）

适用：

- 直接接入日志系统（ELK / Loki / CloudWatch）
- 用 request id 做关联分析

---

## 5) OpenTelemetry（Tracing，可选）

前置：

- 编译启用 feature `gateway-otel`
- 运行时传 `--otel`（可选 `--otel-endpoint` 指定 OTLP HTTP endpoint）

示例：

```bash
RUST_LOG=info \
cargo run --features "gateway gateway-otel" --bin ditto-gateway -- ./gateway.json \
  --otel --otel-endpoint http://127.0.0.1:4318/v1/traces
```

说明：

- OTel 使用 `tracing_subscriber::EnvFilter`，可以通过 `RUST_LOG` 控制级别。
- `--otel-json` 会把 tracing logs 也输出为 JSON（便于收集）。
- 为避免把敏感 query 参数带进 tracing，Ditto 的 proxy span `path` 默认会丢弃 query string（只保留路径部分）。

---

## 6) Devtools JSONL（可选）

如果你需要把请求/响应记录为 JSONL 以便重放或离线分析：

- 编译启用 `gateway-devtools`（它隐含 `gateway` + `sdk`）
- 运行时传 `--devtools <path>`

> Devtools 日志包含敏感信息的风险更高；生产环境务必配合脱敏/权限控制。

Ditto Gateway 写入 devtools 前同样会应用 `observability.redaction`（与 JSON logs / audit 一致），但这不等于你可以忽略生产的权限与留存策略。

更多格式与用法见「SDK → Devtools（JSONL 日志）」。

================================================================================
FILE: docs/src/gateway/deployment.md
================================================================================

# 部署：多副本与分布式

Ditto Gateway 的部署目标是“尽量无状态”，把状态放到外部 store（尤其是 Redis），从而支持多副本与滚动升级。

本页的建议以当前实现为准（见 `src/bin/ditto-gateway.rs`、`src/gateway/http/core.rs`、`src/gateway/redis_store/*`）。

---

## 0) 可复制模板（推荐从这里开始）

- 本地：`docs/Gateway → Docker Compose（本地模板）` 对应 `deploy/docker-compose.yml`
- K8s：`docs/Gateway → Kubernetes（多副本模板）` 对应 `deploy/k8s/*`
- Helm：`deploy/helm/ditto-gateway`（把上面的 K8s 模板参数化）

这些模板的目标是“跑起来 + 默认节制（不会轻易把内存/Redis 打爆）”，然后你再按需打开 routing/otel/metrics 等能力。

## 1) 最小部署拓扑（单实例）

- 1 个 `ditto-gateway` 实例
- 1 份 `gateway.json`
- 上游是 OpenAI-compatible upstream（OpenAI / LiteLLM / 其他兼容网关）

启动：

```bash
cargo run --features gateway --bin ditto-gateway -- ./gateway.json --listen 0.0.0.0:8080
```

健康检查：

- `GET /health` → `{"status":"ok"}`

---

## 2) 多副本（stateless）会遇到什么问题？

把 `ditto-gateway` 横向扩容到 N 个副本后，如果你不配置共享 store，会出现：

- virtual keys：每个副本只读自己的 `gateway.json`；Admin API 修改也不会同步。
- token/cost budgets：每个副本各算各的，无法形成“全局预算”。
- proxy cache：每个副本各有一份内存缓存，命中率低且不一致。

因此“多副本”要想具备“企业级一致性”，核心是引入共享存储。

---

## 3) 推荐：Redis 作为共享状态（分布式）

启用条件：

- 编译启用 feature `gateway-store-redis`
- 启动时传 `--redis <url>`（建议配置 `--redis-prefix`）

```bash
cargo run --features "gateway gateway-store-redis" --bin ditto-gateway -- ./gateway.json \
  --redis redis://redis:6379 --redis-prefix ditto \
  --listen 0.0.0.0:8080
```

有了 redis store 后，你可以做到：

- virtual keys 全局一致（Admin API 修改后立刻对所有副本生效）
- token/cost budgets 预留/结算全局一致（避免并发穿透）
- audit logs 全局收集
- proxy cache 可选写入 redis（作为 L2，见「缓存」）

---

## 4) 运行时保护：并发与超时（防止内存被打爆）

Ditto 的 proxy 会在一些位置“把内容读入内存”：

- `/v1/*` 请求体会先读入内存（默认上限 64MiB；可用 `--proxy-max-body-bytes` 调整）
- 非 streaming 响应会**尽量流式转发**；当响应体积可确定且较小（用于从 JSON 提取 `usage` 做更准的结算，或写入 proxy cache）时才会缓冲读取；其中 `usage` 缓冲上限由 `--proxy-usage-max-body-bytes`（默认 1MiB）控制，与 `--proxy-cache-max-body-bytes` 解耦；无 `content-length` 或超过上限时会跳过缓冲/缓存并直接流式转发

生产建议至少打开两类“背压”：

### 4.1 全局并发：`--proxy-max-in-flight`

限制“同时在代理中的请求数”，超限会 429。

```bash
... --proxy-max-in-flight 256
```

### 4.2 后端并发：`backends[].max_in_flight`

对某个 backend 单独限并发：

```json
{
  "name": "primary",
  "base_url": "https://api.openai.com/v1",
  "max_in_flight": 64
}
```

### 4.3 后端超时：`backends[].timeout_seconds`

避免某个 upstream 挂死导致连接长期占用：

```json
{ "timeout_seconds": 60 }
```

---

## 5) 多副本下的配置发布

建议把配置拆成两部分：

- `gateway.json`：非敏感配置（backends/router/策略骨架）
- `.env` / Secret：敏感信息（upstream token / virtual key / admin token / redis url）

启动时通过 `--dotenv`（开发）或容器环境变量（生产）注入 `${ENV_VAR}`：

```bash
... --dotenv .env
```

---

## 6) 企业落地的现实边界（当前 vs 需要补齐）

当前 Ditto Gateway 已经具备多副本运行所需的关键积木（redis store + 预算预留 + 可选共享缓存），但“企业级调用”通常还需要：

- 分布式限流：使用 redis store 时 rpm/tpm 已全局一致（按 virtual key；可选 tenant/project/user shared limits）；route 维度与更强策略仍在 Roadmap
- RBAC/SSO、多租户隔离、权限模型
- 配置中心/灰度发布、不可变审计、告警

这些条目见「Roadmap → 企业与合规能力清单」。

================================================================================
FILE: docs/src/gateway/security.md
================================================================================

# 安全与加固

本页只覆盖 Ditto Gateway **自身实现提供的**安全控制点，以及推荐的部署加固方式。

> 任何 API gateway 的安全都不是“单点开关”，建议把 Ditto 视为你平台的一部分：外层有网络边界/认证授权/审计，内层有预算/策略/路由治理。

---

## 1) Secret 管理：避免把 token 写进配置

推荐用 `${ENV_VAR}` 占位符，并通过 `--dotenv`（开发）或运行环境注入（生产）：

- `backends[].headers` / `query_params`
- `backends[].provider_config.*`
- `virtual_keys[].token`

缺失/为空的 env 会导致启动失败（避免 silent misconfig）。

### 可选：`secret://...`（Vault / AWS SM / GCP SM / Azure KV / file）

在不方便用纯 env 的企业环境里，你也可以把敏感值写成 `secret://...` 形式，并让 `ditto-gateway` 在启动时解析：

- `virtual_keys[].token`
- `backends[].headers` / `query_params`
- `backends[].provider_config.http_headers` / `http_query_params`
- CLI：`--admin-token*` / `--admin-read-token*` / `--redis*`

示例（从 env / 文件）：

- `secret://env/OPENAI_API_KEY`
- `secret://file?path=/run/secrets/openai_api_key`

示例（通过外部 CLI 拉取）：

- `secret://vault/secret/openai?field=api_key&namespace=team`
- `secret://aws-sm/mysecret?region=us-east-1&json_key=api_key`
- `secret://gcp-sm/mysecret?project=myproj&version=latest&json_key=api_key`
- `secret://azure-kv/myvault/mysecret`

注意：

- 这些 provider 会调用本机 CLI（`vault` / `aws` / `gcloud` / `az`），需要你在运行环境里预装并配置好权限。
- Ditto 不会把解析后的值打印到日志（但错误信息会包含 provider/参数，用于排障）。

---

## 2) Virtual Keys：把“对外 API key”当作一等公民

启用 virtual keys 后（`gateway.json.virtual_keys` 非空）：

- 所有 `/v1/*` 请求必须携带 virtual key
- Ditto 会把客户端的 `authorization` / `x-api-key` 当作 virtual key，并在转发 upstream 前移除，避免泄露

建议：

- key 默认最小权限：限制 `allow_models`、启用 `validate_schema`、设置预算与并发上限
- 定期轮换 key，并通过 Admin API 下线旧 key

---

## 3) Admin API：只在启用 admin token 时开放

只有当你显式设置 `--admin-token*`（write）或 `--admin-read-token*`（read-only）时，Ditto 才会挂载 `/admin/*`。

建议把 read-only token 用于只读观测与审计查询；写操作只给 write token。

部署建议：

- 把 `/admin/*` 放在内网
- 或者由反向代理加一层 IP allowlist / mTLS / WAF

---

## 4) Guardrails：内容/模型/Schema 的“入口拦截”

每个 virtual key 都可以配置 `guardrails`（`GuardrailsConfig`）：

- `allow_models` / `deny_models`：模型 allow/deny（支持 `prefix*` 通配）
- `max_input_tokens`：限制输入 token（基于估算，配合 `gateway-tokenizer` 更准）
- `banned_phrases` / `banned_regexes`：按文本包含/正则拦截（case-insensitive）
- `block_pii`：内置 email/SSN 的粗粒度 PII 拦截
- `validate_schema`：对常见 OpenAI 请求做 schema 校验（JSON 与 multipart 都覆盖），不合规直接 400

此外，你还可以在 `router.rules[].guardrails` 做“按模型前缀覆盖”的策略（见「路由」）。

---

## 5) Passthrough 控制（仅 /v1/gateway demo）

`PassthroughConfig` 用于 `/v1/gateway` demo 端点（不是 `/v1/*` passthrough proxy）：

- `allow=false` 可以禁止 `passthrough=true` 的请求
- `bypass_cache=true` 可以在 passthrough 请求时绕过 control-plane cache

---

## 6) 资源滥用防护（DoS 基线）

建议至少做三件事：

1) `--proxy-max-in-flight` 限制全局并发
2) `backends[].max_in_flight` 限制单 backend 并发
3) `backends[].timeout_seconds` 设置合理超时

补充：

- 对大响应（files/audio download）谨慎开启 proxy cache
- 对不可信客户端启用 `validate_schema`，避免无意义的大 payload 打到 upstream

---

## 7) 企业级安全缺口（诚实说明）

当前 Ditto Gateway 还不内置：

- RBAC/SSO（多角色、多租户权限模型）
- 可配置的 IP allow/deny、mTLS 终止、WAF 集成
- 更复杂的分布式限流策略（IP/tenant/route 维度、滑窗/令牌桶等）

这些能力通常由外层 API gateway / service mesh 提供；Ditto 侧的补齐计划见 Roadmap。

================================================================================
FILE: docs/src/gateway/admin-api.md
================================================================================

# Admin API

Admin API 用于“管理与观测控制面状态”：

- virtual keys：list / upsert / delete
- proxy cache：purge（可选）
- backend health：list / reset（可选）
- audit / budgets / costs：查询（可选，需要 store）

实现位置：

- 路由挂载：`src/gateway/http/core.rs`
- 鉴权：`src/gateway/http/admin/auth.rs`
- handlers：`src/gateway/http/admin/handlers.rs`

仓库内也提供一个最小 Admin UI（React）用于快速试用与演示：

- `apps/admin-ui`

---

## 0) 启用条件与鉴权方式

### 0.1 必须启用 admin token（read 或 write）

只有在启动时设置了：

- `--admin-token <TOKEN>` 或
- `--admin-token-env <ENV>`（write admin token）
- `--admin-read-token <TOKEN>` 或
- `--admin-read-token-env <ENV>`（read-only admin token）

才会挂载 `/admin/*` 路由。

写端点（例如 upsert/delete keys、purge cache、reset backend）需要 **write admin token**；当你只配置 read-only token 时，这些写端点不会挂载（404）。

### 0.2 如何携带 admin token

两种等价方式：

- `Authorization: Bearer <admin_token>`
- `x-admin-token: <admin_token>`

---

## 1) Keys：管理 virtual keys

### 1.1 `GET /admin/keys`

默认会把 `token` 字段替换为 `"redacted"`。

权限：read-only admin token 或 write admin token。

常用 query 参数：

- `include_tokens=true`：返回真实 token（谨慎使用）。
- `tenant_id` / `project_id` / `user_id`：按归因字段过滤。
- `enabled=true|false`：按启用状态过滤。
- `id_prefix=...`：按 key id 前缀过滤。
- `limit` / `offset`：分页（默认不限制；`limit` 最大 10000）。为了稳定分页，返回结果会按 `id` 排序。

### 1.2 `POST /admin/keys`：upsert

请求体是完整的 `VirtualKeyConfig` JSON。

- 若 id 不存在：创建（201）
- 若 id 已存在：更新（200）

权限：需要 write admin token。

### 1.3 `PUT /admin/keys/:id`：upsert（id 在 path）

与 `POST /admin/keys` 类似，但以 path 的 `:id` 覆盖 body 的 `id`。

权限：需要 write admin token。

### 1.4 `DELETE /admin/keys/:id`

- 成功：204
- 不存在：404

权限：需要 write admin token。

### 1.5 keys 的持久化（重要）

upsert/delete 后 Ditto 会尝试持久化 keys：

- `--sqlite`：写入 sqlite
- `--redis`：写入 redis
- `--state`：写入 state file
- 都没有：只在内存生效（重启丢失）

---

## 2) Proxy cache：清理缓存（可选）

启用条件：

- admin token 已启用（read 或 write）
- proxy cache 已启用（`--proxy-cache` 且编译启用 `gateway-proxy-cache`）

### 2.1 `POST /admin/proxy_cache/purge`

权限：需要 write admin token。

请求体二选一：

- `{ "all": true }`
- `{ "cache_key": "ditto-proxy-cache-v1-..." }`

响应：

```json
{ "cleared_memory": true, "deleted_redis": 123 }
```

- `deleted_redis` 仅在启用 redis store 时出现

实现细节与运维提示：

- `{ "all": true }` 在启用 redis store 时会使用 `SCAN + DEL` 按批删除（不会把所有 key 一次性读进内存），但仍然是 O(N) 操作；大规模缓存场景建议优先依赖 TTL、并避免频繁 purge-all。

---

## 3) Backends：查看/重置健康状态（可选）

启用条件：

- 编译启用 `gateway-routing-advanced`
- admin token 已启用（read 或 write）

### 3.1 `GET /admin/backends`

权限：read-only admin token 或 write admin token。

返回每个 backend 的 `BackendHealthSnapshot`，字段包括：

- `consecutive_failures`
- `unhealthy_until_epoch_seconds`
- `health_check_healthy` / `health_check_last_error`

### 3.2 `POST /admin/backends/:name/reset`

清除某个 backend 的健康状态（把它恢复为默认健康）。

权限：需要 write admin token。

---

## 4) Audit：查询审计日志（可选，需要 store）

启用条件：

- 编译启用 `gateway-store-sqlite` 或 `gateway-store-redis`
- 运行时启用 `--sqlite` 或 `--redis`
- admin token 已启用（read 或 write）

### 4.1 `GET /admin/audit`

权限：read-only admin token 或 write admin token。

Query 参数：

- `limit`（默认 100，最大 1000）
- `since_ts_ms`（可选）

返回 `AuditLogRecord[]`：

```json
{
  "id": 1,
  "ts_ms": 1738368000000,
  "kind": "proxy.blocked",
  "payload": { "...": "..." }
}
```

### 4.2 `GET /admin/audit/export`

返回带防篡改 hash-chain 的审计导出流（JSONL/CSV）。

权限：read-only admin token 或 write admin token。

Query 参数：

- `format=jsonl|csv`（默认 `jsonl`；`ndjson` 视为 `jsonl`）
- `limit`（默认 1000；最大 10000）
- `since_ts_ms`（可选）
- `before_ts_ms`（可选）

JSONL 输出每行是一个 `AuditExportRecord`（包含 `prev_hash`/`hash`，用 SHA-256 串起来；用于离线校验与合规留存）。

### 4.3 离线校验与对象存储导出

仓库内提供两个 CLI：

- `ditto-audit-verify`：校验 JSONL 导出的 hash-chain。
- `ditto-audit-export`：从 gateway 拉取 `/admin/audit/export`，写到本地文件，并可选上传到对象存储（S3/GCS）+ 生成 manifest（含文件 sha256、最后一个 hash-chain 值等）。

示例：

```bash
# 1) 导出到本地文件 + 生成 manifest
cargo run --bin ditto-audit-export --features gateway -- \
  --base-url http://127.0.0.1:8080 \
  --admin-token-env DITTO_ADMIN_TOKEN \
  --output audit.jsonl

# 2) 校验 hash-chain
cargo run --bin ditto-audit-verify --features gateway -- --input audit.jsonl

# 3) 上传到 S3（需要本机 aws cli + 凭证）
cargo run --bin ditto-audit-export --features gateway -- \
  --base-url http://127.0.0.1:8080 \
  --admin-token-env DITTO_ADMIN_TOKEN \
  --output audit.jsonl \
  --upload s3://my-bucket/ditto/audit.jsonl

# 4) 上传到 GCS（需要本机 gsutil + 凭证）
cargo run --bin ditto-audit-export --features gateway -- \
  --base-url http://127.0.0.1:8080 \
  --admin-token-env DITTO_ADMIN_TOKEN \
  --output audit.jsonl \
  --upload gs://my-bucket/ditto/audit.jsonl
```

WORM（不可变/保留期）建议在对象存储侧开启（例如 S3 Object Lock）。如需在上传时设置 S3 Object Lock 参数，可使用 `ditto-audit-export` 的 `--s3-object-lock-*` 选项（详见 `--help`）。

---

## 5) Budgets：查看 token 预算 ledger（可选，需要 store）

### 5.1 `GET /admin/budgets`

返回 `BudgetLedgerRecord[]`，其中 `key_id` 既可能是：

- virtual key id（例如 `vk-dev`）
- 也可能是 scope（例如 `tenant:tenant-a`、`project:proj-a`、`user:user-42`）

常用 query 参数：

- `key_prefix=tenant:` / `key_prefix=project:` / `key_prefix=user:`：按 ledger `key_id` 前缀过滤（便于大规模部署按 scope 查看）。
- `limit` / `offset`：分页（默认不限制；`limit` 最大 10000）。

### 5.2 `GET /admin/budgets/tenants` / `GET /admin/budgets/projects` / `GET /admin/budgets/users`

这是“按 virtual key 的 `tenant_id` / `project_id` / `user_id` 字段做聚合”的视图：

- 它主要用于“按 key 归因汇总”
- 如果你想直接查看 `tenant:*` / `project:*` / `user:*` scope 的 ledger，请用 `GET /admin/budgets` 自行筛选

---

## 6) Costs：查看美元预算 ledger（可选，需要 store + costing）

启用条件：

- 编译启用 `gateway-costing`
- 启用 sqlite/redis store

端点与 budgets 类似：

- `GET /admin/costs`
- `GET /admin/costs/tenants`
- `GET /admin/costs/projects`
- `GET /admin/costs/users`

常用 query 参数：

- `key_prefix=tenant:` / `key_prefix=project:` / `key_prefix=user:`：按 ledger `key_id` 前缀过滤。
- `limit` / `offset`：分页（默认不限制；`limit` 最大 10000）。

---

## 7) Maintenance：回收陈旧预算预留（可选，需要 store）

> 用途：当进程崩溃/异常中断导致“预留未结算”时，ledger 的 `reserved_*` 可能长期不归零。该端点用于运维回收陈旧预留。

权限：需要 write admin token。

### 7.1 `POST /admin/reservations/reap`

请求体：

```json
{
  "older_than_secs": 86400,
  "limit": 1000,
  "dry_run": true
}
```

- `older_than_secs`：只回收“创建时间早于 now-older_than_secs”的 reservations（默认 24h）。
- `limit`：最多回收多少条（默认 1000；最大 100000）。
- `dry_run=true`：只统计，不实际修改。

响应体：

```json
{
  "store": "redis",
  "dry_run": true,
  "cutoff_ts_ms": 1738368000000,
  "budget": { "scanned": 0, "reaped": 0, "released": 0 },
  "cost": { "scanned": 0, "reaped": 0, "released": 0 }
}
```

实现与注意事项：

- 当前仅支持 redis store（`--redis` + feature `gateway-store-redis`）；sqlite store 会返回 501（后续会补齐）。
- 该操作会扫描 `redis-prefix` 下的 reservation keys（O(N)）；建议在离峰时以较小 `limit` 分批执行。
- 建议把 `older_than_secs` 设得足够保守，避免误伤超长 streaming 请求。

---

## 8) 常见错误与排障

- 401 `unauthorized`：admin token 未配置或不匹配
- 404：
  - 未启用 admin token（/admin 路由不会挂载）
  - 或者未启用对应 feature（例如 proxy cache / routing-advanced）
- 400 `not_configured`：依赖 store/feature 的端点未启用（例如 budgets/audit）

================================================================================
FILE: docs/src/reference/index.md
================================================================================

# 参考

这里放的是“查表型”内容：

- provider 能力矩阵（哪些 provider 支持哪些能力、对应 feature flags）
- `ditto-gateway` 的 CLI 选项速查
- FAQ / 术语表

如果你更需要“教程式”的路径，请优先阅读 SDK/Gateway 两章。

================================================================================
FILE: docs/src/reference/providers.md
================================================================================

# Providers 能力矩阵

本页是“查表型”入口，帮助你快速回答：

- 我该启用哪些 Cargo features？
- 某个 provider 支持哪些能力（stream/tools/embeddings/…）？
- Gateway 的 passthrough 与 translation 分别覆盖到什么程度？

更完整的矩阵请直接看仓库根目录的 `PROVIDERS.md`（它会随代码演进而更新）。

---

## 1) Ditto 的两条集成路径

### A) Native adapters（推荐）

直接调用 provider 的原生 API，语义最完整、兼容性最清晰：

- OpenAI：Responses API（`/responses`）
- Anthropic：Messages API（`/messages`）
- Google：GenAI（`generateContent` / `streamGenerateContent`）
- Cohere：Chat v2（`/v2/chat`）
- Bedrock / Vertex：各自的认证与 API（feature-gated）

适用：

- 你在 Rust 服务端直接集成模型
- 你希望 Warnings 明确暴露能力差异

### B) OpenAI-compatible adapters（务实）

通过 OpenAI-compatible upstream（例如 LiteLLM Proxy、各类兼容网关或厂商兼容层）：

- Chat Completions（`/chat/completions`）
- Embeddings（`/embeddings`）
- 以及 upstream 自己支持的其它 OpenAI 端点（视具体实现）

适用：

- 你已经有一个“兼容 OpenAI API 的统一入口”
- 你需要把 Ditto 放在现有网关/平台上逐步替换

---

## 2) Provider features（Cargo）

常见 provider feature：

- `openai`
- `openai-compatible`
- `anthropic`
- `google`
- `cohere`
- `bedrock`（依赖 `auth` + `base64`）
- `vertex`（依赖 `auth`）

你也可以直接用 bundles：

- `all-providers`
- `all`

---

## 3) Capability features（Cargo）

Ditto 把能力拆成独立 feature，避免默认拉入所有依赖：

- `streaming`
- `tools`
- `embeddings`
- `images`
- `audio`
- `moderations`
- `rerank`
- `batches`

以及 bundles：

- `all-capabilities`
- `all`

> 注意：某个能力 feature 打开，只代表 Ditto **提供了相应 trait 与实现入口**；具体 provider 是否支持，还要看 provider 自身能力与请求映射（不支持会产出 `Warning`）。

---

## 4) Gateway 相关 features（Cargo）

Gateway 的能力也拆成多个 feature：

- `gateway`：HTTP server + passthrough proxy（`ANY /v1/*`）+ 基础控制面
- `gateway-translation`：OpenAI in/out → native providers（translation backends）
- `gateway-proxy-cache`：非 streaming proxy cache
- `gateway-routing-advanced`：retry/circuit-breaker/health-checks
- `gateway-store-sqlite` / `gateway-store-redis`：持久化 store
- `gateway-costing`：美元预算（需要 pricing table）
- `gateway-tokenizer`：更准确的 token 估算（tiktoken）
- `gateway-metrics-prometheus`：Prometheus 指标
- `gateway-otel`：OpenTelemetry tracing

推荐组合（多副本生产常见）：

- `gateway`
- `gateway-store-redis`
- `gateway-routing-advanced`（可选）
- `gateway-proxy-cache`（可选）
- `gateway-metrics-prometheus` 或 `gateway-otel`（可选）
- `gateway-tokenizer`（可选：预算更准）

---

## 5) 快速决策：我该用哪个 provider 路径？

- 你只需要“一个 HTTP 入口”并且 upstream 已经统一：**OpenAI-compatible**（SDK 或 Gateway passthrough）。
- 你要拿到最完整语义（tool calling / structured outputs / provider options）：**Native adapters**。
- 你需要“OpenAI API surface → Anthropic/Google/Cohere 等原生 API”的转换：启用 **Gateway translation**（`gateway-translation`）。

下一步：

- 继续阅读「SDK → ProviderConfig 与 Profile」
- 或阅读「Gateway → 配置文件」「Gateway → HTTP Endpoints」

================================================================================
FILE: docs/src/reference/cli.md
================================================================================

# CLI 选项（ditto-gateway）

本页是 `ditto-gateway` 的运行参数速查（实现见 `src/bin/ditto_gateway/cli.rs` + `src/bin/ditto-gateway.rs`）。

> 当前 CLI 采用轻量参数解析：**没有 `--help`**。运行时缺少必填参数会打印 usage（并退出）。

---

## 1) 基本用法

`ditto-gateway` 的第一个参数必须是配置文件路径：

```bash
ditto-gateway <gateway.(json|yaml)> [flags...]
```

> YAML 配置需要编译启用 feature `gateway-config-yaml`（否则只支持 JSON）。

开发期常见用法：

```bash
cargo run --features gateway --bin ditto-gateway -- ./gateway.json --listen 0.0.0.0:8080
```

---

## 2) 配置与运行（Core）

- `--listen HOST:PORT`（或 `--addr`）：监听地址（默认 `127.0.0.1:8080`）
- `--dotenv PATH`：加载 dotenv 文件（供 `${ENV_VAR}` 展开与 `*-env` 选项读取）
- `--json-logs`：输出 Ditto 自定义的 JSON 行事件日志（stderr）

---

## 3) Admin（管理面）

- `--admin-token TOKEN`：启用 `/admin/*` 并设置 **write admin token**（可执行写操作）
- `--admin-token-env ENV`：从环境变量读取 write admin token（可配合 `--dotenv`）
- `--admin-read-token TOKEN`：启用 `/admin/*` 并设置 **read-only admin token**（只读）
- `--admin-read-token-env ENV`：从环境变量读取 read-only admin token（可配合 `--dotenv`）
- `--admin-tenant-token TENANT_ID=TOKEN`：启用 `/admin/*` 并设置 **tenant-scoped write token**（只能管理该 tenant 的 keys/budgets/costs/audit）
- `--admin-tenant-token-env TENANT_ID=ENV`：从环境变量读取 tenant-scoped write token（可配合 `--dotenv`）
- `--admin-tenant-read-token TENANT_ID=TOKEN`：启用 `/admin/*` 并设置 **tenant-scoped read-only token**
- `--admin-tenant-read-token-env TENANT_ID=ENV`：从环境变量读取 tenant-scoped read-only token（可配合 `--dotenv`）

说明：

- `TOKEN` 也可以是 `secret://...`（见「Gateway 安全与加固」的 secret 管理章节）。

约束：

- `--admin-token` 与 `--admin-token-env` 互斥
- `--admin-read-token` 与 `--admin-read-token-env` 互斥

说明：

- 如果只配置 `--admin-read-token*`（不配置 `--admin-token*`），则写端点不会挂载（404）。

---

## 4) 存储（state / sqlite / redis）

三选一（超过一个会直接报错）：

- `--state PATH`：JSON state file（只持久化 virtual keys）
- `--sqlite PATH`：sqlite store（需要 `--features gateway-store-sqlite`）
- `--redis URL`：redis store（需要 `--features gateway-store-redis`）

可选（适用于 sqlite/redis）：

- `--audit-retention-secs SECS`：审计日志保留期（只保留最近 `SECS` 秒；启用 sqlite/redis store 时默认 30 天；设置为 `0` 表示不做清理）

redis 相关：

- `--redis-env ENV`：从环境变量读取 redis url（可配合 `--dotenv`；需要 `gateway-store-redis`）
- `--redis-prefix PREFIX`：设置 redis key prefix（需要 `--redis`/`--redis-env`）

约束：

- `--redis` 与 `--redis-env` 互斥

---

## 5) Proxy cache（可选）

需要编译启用 `gateway-proxy-cache`：

- `--proxy-cache`：启用
- `--proxy-cache-ttl SECS`：TTL（隐式启用 cache；默认 60；最小 1）
- `--proxy-cache-max-entries N`：内存缓存容量（隐式启用 cache；默认 1024；最小 1）
- `--proxy-cache-max-body-bytes N`：单条响应最大 body bytes（隐式启用 cache；默认 1048576；最小 1）
- `--proxy-cache-max-total-body-bytes N`：内存缓存总 body budget（隐式启用 cache；默认 67108864；最小 1）

如果同时启用 redis store，cache 会作为 L2 写入 redis（共享）。

---

## 6) Proxy backpressure（强烈建议）

- `--proxy-max-in-flight N`：限制同时代理的请求数（超限 429；N 必须 > 0）
- `--proxy-max-body-bytes N`：限制 `/v1/*` 入口请求体最大 bytes（默认 64MiB；N 必须 > 0）
- `--proxy-usage-max-body-bytes N`：限制为了解析 `usage` 而缓冲的 **非 streaming JSON 响应**最大 bytes（默认 1MiB；`0` 表示禁用 usage 缓冲并回退到估算）

此外，`gateway.json.backends[].max_in_flight` 也会对单 backend 限并发（更细粒度）。

---

## 7) Proxy routing advanced（可选）

需要编译启用 `gateway-routing-advanced`：

- Retry：
  - `--proxy-retry`
  - `--proxy-retry-status-codes CODES`（逗号分隔，如 `429,500,502`）
  - `--proxy-retry-max-attempts N`
- Circuit breaker：
  - `--proxy-circuit-breaker`
  - `--proxy-cb-failure-threshold N`
  - `--proxy-cb-cooldown-secs SECS`
- Health checks：
  - `--proxy-health-checks`
  - `--proxy-health-check-path PATH`
  - `--proxy-health-check-interval-secs SECS`
  - `--proxy-health-check-timeout-secs SECS`

---

## 8) Costing（可选）

需要编译启用 `gateway-costing`：

- `--pricing-litellm PATH`：加载 LiteLLM 风格 pricing JSON（用于 cost budgets）

---

## 9) Prometheus（可选）

需要编译启用 `gateway-metrics-prometheus`：

- `--prometheus-metrics`：启用 `GET /metrics/prometheus`
- `--prometheus-max-key-series N`
- `--prometheus-max-model-series N`
- `--prometheus-max-backend-series N`
- `--prometheus-max-path-series N`

---

## 10) Devtools（可选）

需要编译启用 `gateway-devtools`（或 `gateway + sdk`）：

- `--devtools PATH`：输出 JSONL（用于调试/重放/离线分析）

---

## 11) OpenTelemetry（可选）

需要编译启用 `gateway-otel`：

- `--otel`：启用 tracing export
- `--otel-endpoint URL`：覆盖 OTLP HTTP endpoint
- `--otel-json`：把 tracing logs 输出成 JSON

`RUST_LOG` 控制日志级别（默认 `info`）。

---

## 12) 临时覆盖后端（高级）

这两组参数用于“运行时注入/覆盖”一部分后端配置：

- `--upstream name=base_url`：注入一个 OpenAI-compatible passthrough upstream（ProxyBackend）
- `--backend name=url`：给 `POST /v1/gateway` demo 注册一个 HttpBackend

它们主要用于快速试验；生产建议以 `gateway.json` 为准。

================================================================================
FILE: docs/src/reference/faq.md
================================================================================

# 常见问题（FAQ）

## Q1：Ditto Gateway 现在算“企业级可用”了吗？

可以用于生产的部分：

- 多副本运行所需的核心积木（推荐：`gateway-store-redis`）
- virtual keys / budgets / audit / routing / 观测（取决于你启用的 feature）

尚缺的典型“企业治理项”：

- 分布式限流（rpm/tpm 全局一致）
- RBAC/SSO、多租户隔离、权限模型
- 配置中心、不可变审计、告警与运营面板

建议先按「部署：多副本与分布式」落地，再对照 Roadmap 逐步补齐。

---

## Q2：为什么我启用了多副本，但 budgets/limits 不一致？

- `limits`（rpm/tpm）目前是进程内计数，不会跨副本共享。
- `budgets` 如果没有启用 `--sqlite/--redis`，也不会持久化与共享。

解决：

- 多副本预算：用 `gateway-store-redis` + `--redis`
- 多副本限流：暂时建议外置（API gateway / service mesh）

---

## Q3：Ditto 会把我的 virtual key 转发给 upstream 吗？

不会（当启用 virtual keys 时）。

当 `gateway.json.virtual_keys` 非空时，Ditto 会把客户端 `authorization`/`x-api-key` 当作 virtual key，并在转发前移除，避免泄露。

上游鉴权应配置在 `backends[].headers/query_params` 或 translation backend 的 `provider_config.auth`。

---

## Q4：为什么 `--proxy-cache` 没有命中？

proxy cache 只缓存：

- `GET`/`POST`
- 非 streaming 响应
- 2xx 成功响应

并且以下情况会 bypass：

- 请求头有 `x-ditto-cache-bypass` / `x-ditto-bypass-cache`
- `Cache-Control` 包含 `no-store`/`no-cache`

---

## Q5：Ditto 的 token 预算是如何估算的？准确吗？

默认情况下（未启用 `gateway-tokenizer`），Ditto 用一个保守的粗估：`body_bytes_len / 4`。

如果你需要更准确的预算：

- 编译启用 `gateway-tokenizer`

即便启用了 tokenizer，预算仍然是 best-effort（不同 provider 的 token 规则不同），建议结合 usage 的最终统计做审计与校准。

---

## Q6：我能用 Ditto 做 OpenAI Responses 的兼容吗？

可以（passthrough proxy 的 shim 逻辑）。

当 upstream 不支持 `POST /v1/responses`（404/405/501），Ditto 会 fallback 到 `POST /v1/chat/completions` 并返回 best-effort Responses-like 结果，并附加：

- `x-ditto-shim: responses_via_chat_completions`

如果你遇到 502：

- 对非 streaming shim，Ditto 需要缓冲并转换 upstream 的 JSON 响应；为避免 OOM，存在最大缓冲上限（当前 8MiB）。超限时建议改用 streaming（SSE）或直接调用 `POST /v1/chat/completions`。

---

## Q7：我在 SDK 里如何发现模型列表？

Ditto 支持从 `ProviderConfig` 做模型发现（OpenAI-compatible 的 `/models`、以及部分 native provider 的能力）。

入口与字段解释见「SDK → ProviderConfig 与 Profile」。

================================================================================
FILE: docs/src/reference/glossary.md
================================================================================

# 术语表

## Provider

模型提供方（OpenAI / Anthropic / Google / Cohere / Bedrock / Vertex / OpenAI-compatible upstream 等）。

## Native adapter

Ditto 直接对接 provider 的原生 API（语义更完整、warnings 更准确）。

## OpenAI-compatible adapter

Ditto 通过 OpenAI-compatible API（通常是 `/v1/chat/completions` 等）对接 upstream。

## Gateway

Ditto 的 HTTP 服务（feature `gateway`），对外暴露 OpenAI-compatible 的 `/v1/*` surface，并提供控制面能力。

## Passthrough proxy

`ANY /v1/*` 原样转发到 OpenAI-compatible upstream（不变形）。

## Translation proxy

把 OpenAI in/out 翻译为 native provider 请求/响应（feature `gateway-translation`）。

## Backend

Gateway 内部用于处理请求的后端条目（`GatewayConfig.backends[]`），可以是：

- passthrough upstream（`base_url`）
- translation backend（`provider` + `provider_config`）

## Router / RouteRule

按 `model` 选择 backend 的规则系统（`RouterConfig` / `RouteRule`）。

## Virtual Key

对外发放给调用方的 API key，用来做鉴权、归因、预算、限流、路由与审计。

## Admin Token

管理面 `/admin/*` 的鉴权 token（只在启用时挂载）。

## Scope

预算/缓存等的“隔离维度”。

例如 budgets：

- key scope：`<virtual_key_id>`
- project scope：`project:<project_id>`
- user scope：`user:<user_id>`

## Budget（token budget）

按 token 计的总额度（`BudgetConfig.total_tokens`）。

## Cost budget

按美元计的总额度（`BudgetConfig.total_usd_micros`），需要 pricing table。

## Proxy cache

对 `/v1/*` passthrough 的非 streaming 成功响应做缓存（可选）。

## Control-plane cache

对 `POST /v1/gateway` demo 端点做缓存（可选）。

## Warnings

Ditto 明确暴露“能力差异/降级/参数处理”的机制（SDK 侧为 `Warning`；Gateway 可将其用于策略或观测）。

================================================================================
FILE: docs/src/migration/index.md
================================================================================

# 迁移

这部分面向两类读者：

- 已经在用 LiteLLM Proxy：希望迁移到 Ditto Gateway（或两者并行）。
- 已经在用 Vercel AI SDK：希望把“AI SDK Core 的调用方式”映射到 Rust/服务端。

迁移文档的目标不是“营销对比”，而是帮助你：

- 找到 Ditto 里对应的能力与配置
- 明确哪些能力已经对齐、哪些仍是 roadmap
- 识别行为差异（例如：Warnings、更严格的参数校验、stream 语义差异）

================================================================================
FILE: docs/src/migration/from-litellm.md
================================================================================

# 从 LiteLLM Proxy 迁移

Ditto Gateway 的目标是覆盖 LiteLLM Proxy 的核心使用路径（OpenAI-compatible `/v1/*` + 控制面治理），并在 Rust-first 的基础上把“路由/预算/审计/观测”做成可组合、可部署的积木。

本页给一个务实的迁移路线：**先并行、再替换**。

---

## 0) 先做一个现实判断：你当前依赖 LiteLLM 的哪些能力？

把能力分三类：

1) **HTTP 兼容面**：你主要用 `/v1/chat/completions`、`/v1/embeddings`、`/v1/models` 等。
2) **治理面**：virtual keys / budgets / rate limit / caching / routing / audit。
3) **生态面**：特定 provider 的适配与一堆“快捷开关”。

Ditto 当前覆盖度：

- (1) passthrough：覆盖（`ANY /v1/*`）
- (1) translation：覆盖一批（见 README 的 translation endpoints 列表；需要 `gateway-translation`）
- (2) 治理面：覆盖一部分（virtual keys / budgets / routing / cache / audit / metrics），但仍缺一些企业治理项（见 Roadmap）
- (3) provider 生态：以“原生 adapter + OpenAI-compatible adapter”为主（见 `PROVIDERS.md`）

---

## 1) 迁移路线 A：把 Ditto 放在 LiteLLM 前面（最稳）

目的：

- 你不改变现有 upstream（仍是 LiteLLM）
- 先把“鉴权/预算/路由/观测”收拢到 Ditto

配置思路：

- Ditto 的 `backends[].base_url` 指向 LiteLLM 的 `/v1`
- Ditto 自己启用 `virtual_keys`（对外发放 key）
- LiteLLM 的真实 token 仍由 Ditto backend header 注入（对客户端不可见）

示例（片段）：

```json
{
  "backends": [
    {
      "name": "litellm",
      "base_url": "http://litellm:4000/v1",
      "headers": { "authorization": "Bearer ${LITELLM_MASTER_KEY}" }
    }
  ],
  "virtual_keys": [
    { "id": "vk-dev", "token": "${DITTO_VK_DEV}", "enabled": true, "limits": {}, "budget": {}, "cache": {}, "guardrails": {}, "passthrough": { "allow": true, "bypass_cache": true }, "route": null }
  ],
  "router": { "default_backends": [{ "backend": "litellm", "weight": 1.0 }], "rules": [] }
}
```

优势：

- 迁移风险小：只改一个入口地址
- 你可以逐步打开 Ditto 的缓存/预算/路由功能

---

## 2) 迁移路线 B：让 Ditto 直接接 upstream（替换 LiteLLM）

如果你的 upstream 本身就是 OpenAI-compatible（或你只用 OpenAI），你可以让 Ditto passthrough 直接打到 upstream：

- OpenAI：`https://api.openai.com/v1`
- 某些厂商：提供了兼容 OpenAI 的 `/v1`

如果你的 upstream 不是 OpenAI-compatible（例如 Anthropic/Google 原生），可以考虑：

- 启用 `gateway-translation`，用 Ditto 的 native adapters 做 translation backends
- 或者继续用 LiteLLM 作为兼容层，直到 Ditto translation 覆盖到你的 endpoint 集合

---

## 3) 迁移最容易踩坑的点（差异说明）

### 3.1 配置格式与 env 展开

- Ditto 配置默认是 JSON（`gateway.json`）；如需 YAML（`gateway.yaml`），需要编译启用 feature `gateway-config-yaml`
- 支持 `${ENV_VAR}` 占位符展开，并且 env 缺失会启动失败（避免 silent misconfig）
- 兼容性补充：当启用 `gateway-config-yaml` 时，`ditto-gateway` 也支持直接读取 LiteLLM 的 `proxy_config.yaml` / `proxy_server_config.yaml`（会将 `model_list` 与 `general_settings.master_key` 转为 Ditto 配置）

### 3.2 Virtual keys 的行为差异

启用 virtual keys 后：

- 客户端的 `Authorization` 会被视为 virtual key，不会转发 upstream
- upstream 的鉴权必须由 Ditto backend headers/query 注入

这是为了防止“把虚拟 key 泄露给上游”。

### 3.3 分布式一致性

- 启用 redis store（`gateway-store-redis` + `--redis`）后：virtual keys / budgets（预留/结算）/ audit logs / rpm/tpm limits 都可做到多副本一致（按 virtual key 维度）
- 不启用 redis store：以上能力大多是进程内/本地存储（多副本不一致）

### 3.4 Costing（pricing）

Ditto 支持加载 LiteLLM 风格 pricing JSON（`--pricing-litellm`）用于 cost budgets。

注意：

- 这只用于“预算/估算”，不是“完整 billing 系统”

### 3.5 HTTP surface（兼容性补充）

- Ditto 的 passthrough proxy 主入口是 `ANY /v1/*`，但也接受 LiteLLM 常用的无 `/v1` 前缀别名（例如 `/chat/completions`、`/models/*`、`/files/*`、`/responses/*`）。
- Ditto 提供 LiteLLM 风格的 `/key/*` endpoints（`/key/generate|update|regenerate|delete|info|list`），用于迁移过程中减少改动；它们由 Ditto admin auth 控制（未配置 admin token 时不可用）。

### 3.6 MCP tools（兼容性补充）

如果你在 LiteLLM 里已经用了 MCP（`/mcp` + `tools: [{"type":"mcp", ...}]`），Ditto Gateway 也支持相同方向：

- ✅ `/mcp*` MCP JSON-RPC proxy（`tools/list` / `tools/call`）
- ✅ `POST /v1/chat/completions` 与 `POST /v1/responses` 的 MCP tools 集成（把 MCP tools 转成 OpenAI `function` tools；可选 `require_approval: "never"` 自动执行）

迁移口径（最小映射）：

- LiteLLM 的 `mcp_servers: { <label>: { url: ... } }` → Ditto 的 `mcp_servers: [{ "server_id": "<label>", "url": "..." }]`
- `server_url` 选择器：Ditto 支持 LiteLLM 常见形式 `litellm_proxy/mcp/<servers>`，也支持 path/header 选择（`/mcp/<servers>`、`/<servers>/mcp`、`x-mcp-servers`）

差异/注意：

- Ditto 当前不覆盖 LiteLLM 那种更细粒度的 MCP 权限控制面（例如 per-key/tool permissions、`allowed_params` 等）；可以先用请求级 `allowed_tools` + 多实例隔离承接。
- ✅ 如果 upstream 不支持 `POST /v1/responses`，Ditto 会自动 shim 到 `POST /v1/chat/completions`（同样保留 MCP tools 集成）。

完整说明见「Gateway → MCP Gateway（/mcp + tools）」。

---

## 4) 推荐的“最小可用替换”清单

如果你希望尽快替换 LiteLLM，但又要稳定：

- 先把 Ditto 部署在 LiteLLM 前（路线 A）
- 开启 `gateway-store-redis` + `--redis`（多副本一致）
- 开启 `--proxy-max-in-flight` + `backends[].max_in_flight`（背压）
- 逐步启用：routing-advanced / proxy-cache / prometheus/otel

当这一层稳定后，再考虑路线 B。

================================================================================
FILE: docs/src/migration/from-ai-sdk.md
================================================================================

# 从 Vercel AI SDK 迁移（概念对照）

AI SDK（JS/TS）强调“语义统一”：`generateText`、`streamText`、`generateObject`、tool calling、provider abstraction 等。

Ditto-LLM 在 Rust 里走的是同一条路：

- 统一语义（traits/types）
- 显式暴露差异（`Warning`）
- 以 provider adapters 承接底层 API 差异

本页给你一张“概念映射表 + 最小迁移示例”。

---

## 1) 核心 API 映射

| AI SDK（概念） | Ditto-LLM（Rust） | 说明 |
| --- | --- | --- |
| `generateText` | `LanguageModelTextExt::generate_text` | 返回 `GenerateTextResponse { text, response }` |
| `streamText` | `LanguageModelTextExt::stream_text` | 返回 `StreamTextResult { text_stream, full_stream, final_* }` |
| `generateObject` | `generate_object_json` | 结构化输出（JSON），best-effort |
| `streamObject` | `stream_object` | 流式结构化输出（数组可 `element_stream`） |
| messages | `Vec<Message>` | `Message::system/user/assistant` + `ContentPart` |
| tool calling | `Tool` / `ToolChoice` / `ContentPart::ToolCall` | 不做自动 tool loop（除非用 `agent` feature） |
| model provider | `OpenAI` / `Anthropic` / `Google` / `OpenAICompatible`… | 也可从 `ProviderConfig` 构建 |
| provider options | `ProviderOptions` | 以 `provider_options` best-effort 传递/降级 |

---

## 2) 最小示例：generateText → generate_text

AI SDK（示意）：

```ts
// const result = await generateText({ model: openai('gpt-4o-mini'), messages: [...] })
```

Ditto（Rust）：

```rust
use ditto_llm::{LanguageModelTextExt, Message, OpenAI};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("OPENAI_API_KEY").map_err(|_| {
        ditto_llm::DittoError::InvalidResponse("missing OPENAI_API_KEY".into())
    })?;
    let llm = OpenAI::new(api_key).with_model("gpt-4o-mini");

    let req = vec![
        Message::system("You are a helpful assistant."),
        Message::user("Say hello in one sentence."),
    ]
    .into();

    let out = llm.generate_text(req).await?;
    println!("{}", out.text);
    Ok(())
}
```

---

## 3) 最小示例：streamText → stream_text

Ditto 的 `stream_text` 返回两个 stream：

- `text_stream`：只输出增量文本（最常用）
- `full_stream`：输出 `StreamChunk`（包含 usage/warnings/tool-calls 等）

示例：

```rust
use futures_util::StreamExt;
use ditto_llm::{LanguageModelTextExt, Message, OpenAI};

#[tokio::main]
async fn main() -> ditto_llm::Result<()> {
    let api_key = std::env::var("OPENAI_API_KEY").map_err(|_| {
        ditto_llm::DittoError::InvalidResponse("missing OPENAI_API_KEY".into())
    })?;
    let llm = OpenAI::new(api_key).with_model("gpt-4o-mini");
    let req = vec![Message::user("Stream one sentence.")].into();

    let (handle, mut text_stream) = llm.stream_text(req).await?.into_text_stream();
    while let Some(delta) = text_stream.next().await {
        print!("{}", delta?);
    }
    println!();

    let summary = handle.final_summary()?;
    println!("summary: {summary:?}");
    Ok(())
}
```

---

## 4) 结构化输出：generateObject → generate_object_json

Ditto 的结构化输出以“尽量返回合法 JSON”为目标：

- 对支持原生 JSON schema / response_format 的 provider 会尽量走原生能力
- 不支持时会降级（可能通过 tool call 或 text-json），并通过 `Warning` 说明

建议：

- 在生产里把 `warnings` 打进日志或指标
- 对关键路径在 CI 断言“不允许出现某些 Warning”

---

## 5) Tool calling：Ditto 不自动跑 tool loop

AI SDK 中常见的“自动 tool calling 循环”，在 Ditto 里默认不自动进行：

- Ditto 会把 tool call 作为 `ContentPart::ToolCall` 返回给你
- 你决定是否执行工具、如何把 tool result 回填、以及循环策略

如果你需要一个可选的 tool loop，可以看 Ditto 的 `agent` feature（`ToolLoopAgent`）。

---

## 6) Provider 配置迁移：用 ProviderConfig 收拢配置

AI SDK 通常把 base_url/api_key 分散在不同 provider package 或环境变量里。

Ditto 推荐把它们收拢为：

- `ProviderConfig`：base_url/auth/headers/query/model_whitelist/…
- `Env`：dotenv/环境变量注入

这样同一份配置可以在：

- SDK 直接调用
- Gateway translation backend
- 模型发现（`/models`）

之间复用。

================================================================================
FILE: docs/src/roadmap/index.md
================================================================================

# Roadmap

Ditto-LLM 的定位是“可替换 LiteLLM、并覆盖 AI SDK Core 使用场景”，但在企业落地上仍然有可分阶段演进的治理项。

本章以“可验收的工程条目”形式列出：

- 企业能力缺口（RBAC/SSO、多租户隔离、密钥管理、不可变审计、配置中心等）
- 分布式与高可用建议（Redis、无状态网关、多副本部署注意事项）
- 可执行切片（按 P0/P1/P2 拆分的实现清单）

如果你希望把 Roadmap 变成任务拆分（可直接落地到 issues），可以继续让我按你的部署规模拆成里程碑。

================================================================================
FILE: docs/src/roadmap/contract.md
================================================================================

# Superset Contract（兼容性口径）

本页把“成为 LiteLLM Proxy + Vercel AI SDK Core 的能力超集”这句话，落成一个**可执行、可验收**的契约：

- 哪些行为必须 **严格对齐**（否则就不是可替换/可迁移）
- 哪些行为是 **best-effort**（允许差异，但必须显式暴露）
- 哪些行为是 **非目标**（避免把项目拖成“全都要”的泥潭）

> 说明：Ditto 的实现策略是“分层 + feature gating”。默认构建保持小；需要 gateway/translation/metrics/otel 等能力时再显式开启 features。

---

## 1) 四种形态（长期不变）

Ditto 必须能同时以 4 种形态工作（见 `README.md` / `TODO.md`）：

1. **SDK**：Rust 里直接调用 providers（统一类型/Warnings/严格错误边界）
2. **Gateway**：提供 OpenAI-compatible HTTP surface + control-plane（virtual keys/limits/budget/cache/routing）
3. **Passthrough Proxy**：payload 不变形直通（对接 OpenAI-compatible upstream）
4. **Translation Proxy**：OpenAI in/out → native providers（并把差异显式化）

---

## 2) Must-have（严格对齐）

### 2.1 OpenAI Responses 的不变形路径

目标：对接 Codex CLI 等“依赖 items round-trip”场景时，不允许 silent downgrade。

契约：

- raw passthrough 时，**请求/响应 body 不做语义层面的改写**（除了必要的 hop-by-hop header 清理）。
- `/responses` 与 `/responses/compact` 需要支持 items round-trip（含 streaming）。
- 如果发生降级/兼容 shim，必须在响应头中显式标注（例如 `x-ditto-shim: ...`），并保持 OpenAI-style error shape。

### 2.2 Gateway 的 OpenAI-compatible 行为

契约（核心）：

- OpenAI-compatible 端点在行为上尽量对齐 OpenAI（含 SSE streaming）。
- 错误必须以 OpenAI-style error shape 返回（不要吞错/静默成功）。
- 差异必须可观测：响应头 `x-ditto-request-id` 贯穿；必要时添加 `x-ditto-*` headers 解释行为。

---

## 3) Best-effort（允许差异，但必须显式）

### 3.1 Provider 差异暴露

Ditto 的策略不是“把差异藏起来”，而是：

- SDK 层用 `Warning` 暴露兼容性缺口（例如 tools/schema/多模态不支持）
- Gateway 层用 OpenAI-style error + `x-ditto-*` headers 暴露降级/回退

### 3.2 结构化输出 / JSON Schema 转换

契约：

- 转换是 best-effort 且可能有损；不支持的关键字应被丢弃并以 `Warning` 暴露（避免静默数据损失）。

### 3.3 Token 计数与成本估算

契约：

- token 计数/成本估算允许 best-effort（失败可回退估算），但必须可观测、可配置、可限制（避免 OOM/超大缓冲）。

---

## 4) Non-goals（当前明确不做）

- 不 1:1 复刻 AI SDK UI/前端 hooks/RSC 生态（Ditto 只提供最小 JS/React client 以降低接入成本）。
- 不承诺一次性覆盖所有 LiteLLM 企业能力（RBAC/SSO/SCIM/审批流等按切片推进；外层 IAM/WAF/API gateway 可先承接）。

---

## 5) 验证（Stop Gate）

本仓库建议的最小验证集：

```bash
cargo fmt -- --check
cargo run --bin ditto-llms-txt -- --check
cargo clippy --all-targets --all-features -- -D warnings
cargo test --all-targets --all-features

cargo check --no-default-features
cargo clippy --no-default-features -- -D warnings
```

Node/前端（如改动涉及 `packages/*` 或 `apps/*`）：

```bash
pnpm -r run typecheck
pnpm -r run build
```


================================================================================
FILE: docs/src/roadmap/gaps.md
================================================================================

# Gap Analysis（对标 LiteLLM + AI SDK）

本页回答一个问题：**Ditto-LLM 距离“更好用、更快、更内存安全、企业级超集”还差什么？**

口径说明：

- 对标对象：
  - **LiteLLM Proxy**：OpenAI-compatible AI Gateway（多租户、鉴权、限流、预算、路由、观测、运维）
  - **Vercel AI SDK（Core）**：应用侧开发体验（generate/stream/object/tools/agents/middleware）
- 目标不是 1:1 复刻 UI/前端生态（那是 AI SDK UI 的强项），而是提供：
  - Rust 侧可测试/可审计/可控依赖的 SDK
  - 一个更偏“控制面/治理”的网关（更像 infra 组件）
  - 默认安全、默认节制（避免在无意间把内存/Redis 打爆）

---

## 1) 对标 AI SDK：还缺什么？

AI SDK 的优势不在“接口形式”，而在“生态 + 工程化体验”。Ditto-LLM 当前已覆盖 Core 主干（generate/stream/tools/structured output/middleware/telemetry/devtools/MCP），仍有差距：

### 1.1 开发体验（DX）

- **模板与样例不足**：AI SDK 有大量 cookbook/模板；Ditto 需要：
  - Rust examples（SDK、agent loop、middleware、stream protocol v1）
  - 多语言客户端调用 `ditto-gateway` 的最小工程模板（Node/Python/Go）
- **UI/前端生态（可选超集）**：AI SDK 的强项是 UI hooks（React/Vue/Svelte）与 RSC/Generative UI；Ditto 不追求 1:1 复刻，但可以通过：
  - 官方“stream protocol v1”客户端（JS/TS）+ 最小 hooks（React）降低接入成本
  - 端到端模板（Next.js/Node 调 `ditto-gateway`）把“工程化路径”补齐
- **缓存与回放（应用侧）**：AI SDK 有成熟的 caching/backpressure 示例；Ditto 可以补齐：
  - 基于 `LanguageModelLayer` 的缓存 middleware（含流式回放）
  - 可复制的性能/稳定性 recipe（超时、并发、重试、背压）
- **生态适配器**：AI SDK 有 LangChain/LlamaIndex 等 adapters；Ditto 需要明确“协议级桥接”与最小适配层（否则迁移成本高）。
- **调试/重放链路需要更“开箱即用”**：
  - devtools JSONL 的字段稳定化（版本/事件类型 taxonomy）
  - 更容易把一次失败请求最小化复现出来（request_id → 事件切片）

### 1.2 “正确性默认值”

- **stream abort / backpressure 的默认策略**：AI SDK 的用户很少会踩到“慢消费导致缓冲增长”的坑；Ditto 需要进一步把这些坑变成“默认不会出事”的路径（见第 3 节）。

---

## 2) 对标 LiteLLM：还缺什么？

LiteLLM 的强项是“平台化能力 + 企业功能覆盖”。Ditto Gateway 的核心能力（virtual keys / budgets / routing / proxy cache / OTel/Prometheus / redis store）已具备，但距离企业平台仍有缺口：

### 2.1 企业身份与权限（P0）

- **RBAC/SSO/SCIM**：仍缺组织/角色/权限模型。
- ✅ 已支持（RBAC-lite 切片）：admin token 分为 **read-only** 与 **write** 两类（`--admin-read-token*` / `--admin-token*`），便于把 dashboard/只读审计与写操作分离。
- 推荐承接方式（现实主义）：外层 API gateway / IAM 做 OIDC/mTLS/WAF，Ditto 先专注模型治理；当交易需要时，再逐步补齐更细粒度的 RBAC（只读/运维/审计/密钥管理员）与 tenant 隔离边界。

### 2.2 多租户隔离（P0→P1）

- ✅ 已支持 tenant 维度的归因与配额桶：`tenant_id` + `tenant_budget` / `tenant_limits`（与 project/user 同语义；启用 Redis store 时多副本全局一致）。
- 仍缺：tenant 级别的权限与隔离边界（例如 tenant 独立 keys 管理、跨 tenant 查询默认拒绝、审计/导出按 tenant 隔离、RBAC/审批流）。

### 2.3 分布式限流（P0）

- 已支持：启用 redis store（`gateway-store-redis` + `--redis`）时，rpm/tpm 通过 Redis 原子计数实现 **全局一致**（按 virtual key id；窗口=分钟；计数 key 带 TTL），并支持可选的 tenant/project/user shared limits。
- ✅ 已支持：按 route 分组的分布式限流（Redis 加权滑动窗口 60s；适合多副本一致）。
- 仍缺：更丰富的策略（令牌桶、分级限流、IP/地理维度等）与更完整的可观测性/告警配套。

### 2.4 审计合规（P1→P2）

- 当前审计可写入 sqlite/redis，并支持基础保留期（`--audit-retention-secs`，默认 30 天）：
  - ✅ admin 写操作（例如 key upsert/delete、backend reset、cache purge）在启用 sqlite/redis store 时也会写入 audit log（作为 taxonomy 的一部分）。
  - ✅ 防篡改导出：`GET /admin/audit/export` 提供 hash-chain（含 `ditto-audit-verify` 校验工具）。
  - ✅ 对象存储导出：`ditto-audit-export` 可将导出文件上传到 S3/GCS，并生成 manifest（含文件 sha256、最后一个 hash-chain 值等）；WORM 建议在对象存储侧开启（例如 S3 Object Lock）。
  - 仍缺：全链路脱敏策略（logs/audit/devtools/metrics）与更完整的合规导出流程（审批/分批/追踪）。

### 2.5 运维资产（P1）

- LiteLLM 有成熟的部署资产与运维说明；Ditto 需要补齐：
  - ✅ 已提供：`deploy/docker-compose.yml`（本地模板）、`deploy/k8s/*`（多副本模板）、Helm chart（`deploy/helm/ditto-gateway`）、Grafana dashboard 模板与 PrometheusRule 模板。
  - 仍缺：Kustomize overlays、以及“带监控栈”的组合模板（redis、OTel collector、prometheus + dashboards）与更完整的 SLO/告警体系。

### 2.6 “平台扩展项”（P2）

- ✅ A2A agent gateway（LiteLLM-like）：已支持 `/a2a/*` 的 JSON-RPC 代理端点（beta；需要配置 `a2a_agents`）。
- ✅ MCP gateway（LiteLLM-like）：已支持 `/mcp*` 的 MCP JSON-RPC proxy + OpenAI-compatible `POST /v1/chat/completions` 与 `POST /v1/responses` 的 `tools: [{"type":"mcp", ...}]` 工具集成（多 server 时工具名会加 `<server_id>-` 前缀；支持 `allowed_tools` 过滤）。
- Provider 覆盖面：LiteLLM 的优势是“海量 providers”；Ditto 需要平衡“可维护的 native adapters”与“更强的 OpenAI-compatible 兼容层”。
- Guardrails/告警/日志目的地生态：LiteLLM 提供大量集成；Ditto 需要优先补齐“通用扩展点 + 官方 adapter（Langfuse/Datadog/S3 等）”。
- ✅ Secret 管理：已支持 `secret://...` 解析（env/file/Vault/AWS SM/GCP SM/Azure KV），并已接入 gateway/SDK 配置与 CLI flags。
- ✅ 管理 UI：已提供最小 Admin UI（`apps/admin-ui`），用于演示 keys/budgets/costs/audit 等控制面能力。

---

## 3) 性能与内存安全：还缺什么？

### 3.1 已改进（降低 OOM 风险）

- **Proxy cache 增加体积上限**：支持限制单条缓存 body 与总缓存体积，避免缓存把内存/Redis 打爆。
- **避免 key churn 导致无界增长**：对 rate limit / budget / control-plane cache 的 scope map 增加 `retain_scopes` 清理（当 virtual keys 变更时同步 prune），避免频繁 key 轮换时内存随 scope 数增长。
- **Admin 列表端点支持分页**：`/admin/keys`、`/admin/budgets`、`/admin/costs` 支持 `limit/offset`（最大 10000），避免大租户场景一次性返回超大 payload。
- **预算预留可运维回收**：提供 `POST /admin/reservations/reap` 回收陈旧预算预留；并避免 Redis reservation key 静默过期导致 ledger `reserved_*` 永久卡死。
- **Control-plane cache 增加体积上限**：`/v1/gateway` 的进程内缓存支持 `max_body_bytes` / `max_total_body_bytes`，避免 demo/control-plane 缓存导致内存增长。
- **Proxy 大响应默认不再整段缓冲**：passthrough proxy 对非 SSE 响应会尽量流式转发；仅在“体积较小”时才会缓冲读取（用于 usage 结算或写入 proxy cache）；即使 upstream 未提供 `content-length`，也只会最多预读到上限，超过上限会切换为流式转发并跳过缓存，降低大文件下载的 OOM 风险。
- **入口请求体上限可配置**：`/v1/*` 默认上限 64MiB，并提供 `--proxy-max-body-bytes` 便于企业按 JSON/multipart/上传策略做分级与收敛。
- **usage 缓冲上限与缓存上限解耦**：通过 `--proxy-usage-max-body-bytes` 单独限制“为解析 `usage` 而缓冲的非 streaming JSON 响应”，避免把 proxy cache 上限调大后导致 usage 缓冲也被动变大（默认 1MiB）。
- **错误响应体截断**：对 provider/backend 的非 2xx 错误体只读取有限字节（默认 64KiB），避免异常/恶意错误体导致 OOM，同时提升错误日志可读性。
- **Bedrock eventstream 有界解码**：对 eventstream 的 `total_len` 与内部缓冲区设置最大 bytes 上限，避免协议错位/恶意长度导致无界累积。
- **Responses shim 有界缓冲**：对非 streaming 的 `/v1/responses` shim（chat/completions → responses）设置最大 body bytes，上游响应超限时返回错误并建议改用 streaming 或直接调用 chat/completions。
- **“默认依赖安全”口径**：YAML 配置支持作为 opt-in（`gateway-config-yaml` feature），避免把不必要的解析依赖变成默认前置。
- **SSE parsing 增加行/事件大小上限**：异常/恶意 SSE 事件不会无限增长。
- **stream fan-out 可更安全使用**：提供 `StreamTextHandle`/`StreamObjectHandle` 与 `into_*_stream`，避免“只消费一条 stream 却保留另一条 receiver”的隐式积压。
- **聚合与缓冲区增加体积上限**：`StreamCollector` 与 `stream_object` 内部缓冲区设定 max bytes，避免“超大输出/异常输出”把进程内存打爆（超限发出 `Warning` 并截断）。

### 3.2 仍建议做（P0）

- **stream fan-out 的背压策略（仍可加强）**：`stream_text`/`stream_object` 已从“无界缓冲”升级为“有界缓冲 + 显式启用”，把慢消费从“内存增长”变成“吞吐降低/等待”；后续建议把 buffer 大小/策略做成可配置，并在 lag/backpressure 时打点或告警。
- **按 endpoint/内容类型细化 body 上限**：`/v1/*` 统一 64MiB 的上限对企业不够细；建议对 JSON/multipart/files/audio 分级限制并配合并发背压。

---

## 4) 推荐路线（M0/M1/M2）

- **M0（企业试点可上线，单租户）**：配置 schema 校验 + 脱敏策略 + 审计 taxonomy + 运维模板 + 内存安全 P0。
- **M1（多副本 + 多租户治理）**：Redis 全局限流（补齐更多分组维度） + tenant 模型 + RBAC-lite + 配置版本化/回滚。
- **M2（合规 + FinOps）**：防篡改审计 + 导出/保留期 + usage/cost 归因导出 + SLO/告警/dashboard 套件。

如果你愿意提供：

- 部署方式（单机/K8s/多 region）
- 峰值 QPS 与 streaming 占比
- 首个企业设计伙伴的 Top3 采购阻塞项

我可以把以上路线拆成可直接落地的 issue DAG（含依赖与验收命令）。

================================================================================
FILE: docs/src/roadmap/superset.md
================================================================================

# Superset Roadmap（对标 AI SDK + LiteLLM 的可执行切片）

本页是对 `docs/src/roadmap/gaps.md` 的“落地版本”：把“差距”翻译成 **可以直接实现/验收** 的切片清单。

约束：

- 不依赖外网文档；以仓库现状为准（`TODO.md`、`COMPARED_TO_LITELLM_AI_SDK.md`、`docs/`）。
- 目标是成为 **LiteLLM Proxy + Vercel AI SDK Core 的能力超集**，但默认构建保持小（通过 feature gating）。
- “无内存泄漏风险”的工程口径：避免**无界增长**与**不可回收的持有**；在需要缓存/队列的地方，必须有上限/TTL/清理路径/背压。

状态：

- 截至 2026-02-05，本页的 P0/P1 多数切片已在仓库内落地；本页保留为“实现位置 + 验收方式”的索引。

---

## P0：企业可上线（替换 LiteLLM 的最低可行超集）

> 关键词：多副本一致性、治理能力、可运维性、默认不炸内存/Redis。

### ✅ P0.1 预算预留的“可回收性”（避免 reserved 泄漏）

**问题**：持久化预算（sqlite/redis）依赖 request reservation（预留→commit/rollback）。在进程崩溃/超时/客户端断连等场景，可能留下“陈旧预留”，导致：

- 配额被永久占用（`reserved_*` 不归零）
- 记录无界增长（尤其是 redis key churn / sqlite 表增长）
- 运维难以自愈

**已实现**：

- 提供 Admin 维护端点：`POST /admin/reservations/reap` 回收陈旧 reservations（支持 dry-run + limit）。
- 对 redis：reservation 信息不再依赖静默过期；可通过 reap 恢复（避免 ledger 长期 wedged）。

**涉及模块**：

- store：`src/gateway/redis_store/budget.rs`、`src/gateway/redis_store/store.rs`（以及后续的 `sqlite_store`）
- admin：`src/gateway/http/*`

**验收/验证**：

- `cargo test -p ditto-llm`（包含 reaper 的单测；redis 部分可用 `DITTO_REDIS_URL` 跑）
- 启用 `gateway-store-redis` 后，通过 `POST /admin/...` dry-run 可看到将回收的数量；非 dry-run 会减少 ledger 的 `reserved_*`。

---

### ✅ P0.2 Tenant 隔离边界（从“归因”走向“隔离”）

**现状**：已支持 `tenant_id/project_id/user_id` 归因 + shared budgets/limits，但 admin 查询仍是“全局视角”。

**已实现**（最小安全边界起步）：

- tenant-scoped admin token：只允许管理/查看某个 tenant 的 keys/ledgers/audit（CLI flags：`--admin-tenant-token*` / `--admin-tenant-read-token*`）。
- 默认拒绝跨 tenant 查询（需要显式使用全局 admin token）。

**涉及模块**：

- admin auth：`src/gateway/http/admin/auth.rs`
- admin handlers：`src/gateway/http/admin/*`
- 配置/启动参数：`src/bin/ditto-gateway.rs`（入口）+ `src/bin/ditto_gateway/cli.rs`（参数解析）+ `src/bin/ditto_gateway/attach.rs`（feature-gated attach）

**验收/验证**：

- tenant-scoped token 对 `/admin/keys?tenant_id=...` 允许；对其他 tenant 返回 403（不是 200+空数组）。

---

### ✅ P0.3 分布式限流的“更强策略”（按 route 分组 + 更强算法）

**现状**：redis store 下 rpm/tpm 已全局一致（按 key + 可选 tenant/project/user）；窗口=分钟。

**已实现**：

- 增加 route 维度：`/v1/chat/completions`、`/v1/responses`、`/v1/embeddings` 等分组限流。
- 算法升级：按 route 的 Redis 加权滑动窗口（60s）限流。

**验收/验证**：

- 多副本下同一路由的限流一致；不同路由互不影响。

---

### ✅ P0.4 审计合规（导出 + 防篡改）

**现状**：sqlite/redis audit log + retention；admin 写操作已纳入审计 taxonomy。

**已实现**：

- audit 导出：`GET /admin/audit/export`（JSONL/CSV）。
- hash-chain：每条记录包含前序哈希；并提供 `ditto-audit-verify` 校验工具。

**验收/验证**：

- 导出可在大规模数据下稳定运行（分页、流式输出、不一次性读入内存）。

---

### ✅ P0.5 运维资产（让“分布式部署”更开箱即用）

**已实现**：

- Helm chart（`deploy/helm/*`）
- PrometheusRule + Grafana dashboard 模板（`deploy/prometheus/*`、`deploy/grafana/*`）
- Docker Compose / K8s manifests（`deploy/docker-compose.yml`、`deploy/k8s/*`）

---

## P1：开发体验超集（对标 AI SDK 的“工程化路径”）

### ✅ P1.1 可复制模板（多语言调用 gateway）

**已实现（MVP）**：

- 最小 multi-language clients：`examples/clients/node/*`、`examples/clients/python/*`、`examples/clients/go/*`。
- 端到端 examples：`examples/*` + docs recipes（仍可继续扩面更多“可复制模板”）。

---

### ✅ P1.2 应用侧缓存与回放（middleware）

**已实现**：

- `LanguageModelLayer` 缓存 middleware：`CacheLayer`（包含流式回放）。

---

### ✅ P1.3 JS/TS client（基于 stream protocol v1）

**口径**：不复刻 AI SDK UI 全套，但提供“最小可用 client + hooks（可选）”，让前端/Node 调用 Ditto 更接近 AI SDK 体验。

**已实现**：

- `packages/ditto-client`（stream protocol v1 client）
- `packages/ditto-react`（React hook）

---

## P2：覆盖面（providers / endpoints / 生态）

- 扩充 providers（平衡 native adapter 与 OpenAI-compatible 兼容层）
- 扩充 translation 端点覆盖
- LangChain/LlamaIndex 等桥接（优先协议级、低耦合）

================================================================================
FILE: docs/src/roadmap/enterprise.md
================================================================================

# 企业与合规能力清单

本页不是“营销列表”，而是一个工程化 checklist：帮助你评估 Ditto-LLM 距离“企业级平台能力”还差哪些积木，以及哪些可以由外部基础设施承接。

> 原则：Ditto 负责 **模型治理与路由控制面**；通用的“身份/网络/合规”尽量交给外层 API gateway / service mesh / IAM。

---

## 1) 当前已具备（可用于生产落地的部分）

### 1.1 多副本所需的共享状态（推荐）

- redis store（`gateway-store-redis` + `--redis`）
  - virtual keys 共享
  - budgets/cost 预留与 ledger 共享
  - audit logs 共享
  - proxy cache 可选 L2 共享
- 可复制部署模板
  - Docker Compose：`deploy/docker-compose.yml`
  - Kubernetes：`deploy/k8s/*`

### 1.2 API key 体系（简化版）

- Virtual Keys：每个 key 带 limits/budgets/guardrails/routing/cache 配置
- Admin API：动态 upsert/delete keys（写操作需 write admin token；只读查询可用 read-only token）

### 1.3 预算与审计（可观测）

- token budgets（可选持久化）
- cost budgets（需要 `gateway-costing` + pricing table）
- audit endpoints（需要 sqlite/redis store）

### 1.4 观测基础

- request id + 响应头（`x-ditto-*`）
- JSON metrics（`GET /metrics`）
- Prometheus（可选）
- OTel tracing（可选）

---

## 2) 企业级常见缺口（建议优先级从高到低）

### 2.1 身份与权限（RBAC/SSO）

目标能力：

- 管理面（Admin API）支持角色权限：只读/写入/审计/运维等
- 支持 SSO（OIDC/SAML）与团队目录同步（SCIM）

当前状态：

- ✅ 已支持（RBAC-lite 切片）：admin token 分为 read-only 与 write 两类（便于把 dashboard/审计查看与写操作分离）
- 仍缺：组织/角色/权限模型（RBAC）、SSO、SCIM、审批流与租户隔离边界

建议承接方式：

- 由外层 API gateway 做 OIDC/mTLS + 路由到 `/admin/*`
- Ditto 内部后续再引入 RBAC 模型（Roadmap）

### 2.2 多租户隔离（Multi-tenancy）

目标能力：

- 租户/项目/用户三级归因与隔离
- 每租户独立预算、独立 keys、独立审计与导出

当前状态：

- `VirtualKeyConfig` 支持 `tenant_id` / `project_id` / `user_id` 字段用于归因与聚合视图（Admin API）
- 支持 tenant/project/user shared budgets & limits（`tenant_budget/tenant_limits` 等）
- 但 tenant 级别的权限与隔离模型仍不完整（tenant 独立 keys 管理、跨 tenant 查询默认拒绝、审计/导出隔离、RBAC/审批流）

### 2.3 分布式限流（全局 rpm/tpm）

目标能力：

- 多副本下的全局 rpm/tpm（按 key / project / user / route 分组）

当前状态：

- 使用 redis store（`gateway-store-redis` + `--redis`）时：`/v1/*` proxy 的 rpm/tpm 已通过 Redis 原子计数实现 **全局一致**（按 virtual key id；窗口=分钟；计数 key 带 TTL），并支持可选的 tenant/project/user shared limits。
- 不使用 redis store 时：仍是进程内计数（单实例可用；多副本不一致）。

建议承接方式：

- 外层 API gateway/service mesh 仍适合承接更复杂维度（IP/route/tenant）与滑窗/令牌桶策略。
- Ditto 后续可补齐：按 route 分组的限流与更强策略（Roadmap）。

### 2.4 安全与合规（审计不可变、脱敏、保留期）

目标能力：

- 不可变审计（append-only + WORM 存储/签名）
- 可配置保留期与导出（S3/GCS）
- 全链路脱敏策略（日志/审计/metrics）

当前状态：

- audit log 可写入 sqlite/redis，并支持基础保留期（`--audit-retention-secs` 按时间戳清理；默认 30 天）。
- 但不可变/导出/签名仍需外部系统承接（或后续 Roadmap 补齐）。

### 2.5 配置中心与发布治理

目标能力：

- 配置版本化、灰度、回滚
- 动态调整路由权重、预算、策略（带审批）

当前状态：

- keys 可通过 Admin API 修改并持久化
- gateway.json 仍以文件分发为主

建议承接方式：

- 用 GitOps/配置中心管理 `gateway.json` 与 `.env`，通过滚动升级发布
- 未来可扩展为“路由/策略也可通过 Admin API 管理”

### 2.6 计费与对账（Billing）

目标能力：

- 以 usage 为准的计费与报表（按 tenant/project/user/key/model/backend）
- 导出到数据仓库（BigQuery/Snowflake）

当前状态：

- Ditto 提供 cost 预算与 ledger（面向配额治理），不是完整 billing 系统

---

## 3) 推荐落地姿势（现实主义）

如果你要在企业里落地，建议把“平台职责”分层：

- 外层（API gateway / IAM / WAF / mesh）：
  - SSO/RBAC
  - 全局限流
  - 网络边界与 TLS/mTLS
  - 配置发布与审计平台
- Ditto（模型治理控制面）：
  - virtual keys（细粒度策略单位）
  - budgets/costing（配额治理）
  - routing/caching（性能与鲁棒性）
  - provider adapters（统一语义与 warnings）

---

## 4) 如果你要我把它拆成里程碑

告诉我三件事，我可以按你的规模拆成可验收任务：

- 部署方式：单机 / K8s / 多 region？
- 调用规模：峰值 QPS、模型种类、是否大量 streaming？
- 治理目标：优先要 budgets、costing、还是审计/SSO？


----- END AUTO-GENERATED DOCS (ditto-llms-txt) -----
